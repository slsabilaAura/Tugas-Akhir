{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/slsabilaAura/Tugas-Akhir/blob/main/topik_pake_30.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aca851f",
        "outputId": "3ea92cc1-c945-4f3e-a028-02d101a931a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ],
      "source": [
        "%pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQIdw0eelk43",
        "outputId": "f1568cba-913d-4c93-ad7f-0c1b1eff0a98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# prompt: import file form drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "V0HTbrGd6ePM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# Save the preprocessed DataFrames to new CSV files\n",
        "proposal_df = pd.read_csv('/content/drive/MyDrive/Skripsi3/Dataset/processed_proposalC.csv')\n",
        "expert_df = pd.read_csv('/content/drive/MyDrive/Skripsi3/Dataset/processed_expertC.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xpxYRgx768uU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gensim\n",
        "from gensim import corpora\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from gensim.models.ldamodel import LdaModel\n",
        "import ast\n",
        "from gensim.models import Phrases\n",
        "from gensim.models.phrases import Phraser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brLAWvZi8CQh"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "G42J8DDSOq0f"
      },
      "outputs": [],
      "source": [
        "def convert_to_list(text):\n",
        "    try:\n",
        "        return ast.literal_eval(text) if isinstance(text, str) else text\n",
        "    except:\n",
        "        return []\n",
        "\n",
        "\n",
        "proposal_df[\"processed\"] = proposal_df[\"stemmed\"].apply(convert_to_list)\n",
        "expert_df[\"processed\"] = expert_df[\"stemmed\"].apply(convert_to_list)\n",
        "\n",
        "# Gabungkan semua dokumen untuk membuat satu kamus bersama\n",
        "documents_all = proposal_df[\"processed\"].tolist() + expert_df[\"processed\"].tolist()\n",
        "dictionary_all = Dictionary(documents_all)\n",
        "\n",
        "dictionary_all.filter_extremes(no_below=5, no_above=0.5)\n",
        "\n",
        "proposal_corpus = [dictionary_all.doc2bow(doc) for doc in proposal_df[\"processed\"]]\n",
        "expert_corpus = [dictionary_all.doc2bow(doc) for doc in expert_df[\"processed\"]]\n",
        "\n",
        "corpus_all= proposal_corpus + expert_corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fx-2C63p6Ma_",
        "outputId": "46832d90-94bf-49cb-cede-97c71efd65a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609\n",
            "609\n",
            "3086\n"
          ]
        }
      ],
      "source": [
        "print(len(documents_all))\n",
        "print(len(corpus_all))\n",
        "print(len(dictionary_all))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me5xyf5Z8OwR"
      },
      "source": [
        "# Model LDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "wYePqiNSxAy5"
      },
      "outputs": [],
      "source": [
        "# import time\n",
        "# import pandas as pd\n",
        "# import pandas as pd\n",
        "# from gensim.models.ldamodel import LdaModel\n",
        "# from gensim.models.coherencemodel import CoherenceModel\n",
        "\n",
        "# # List untuk menyimpan hasil eksperimen\n",
        "# results_lda = []\n",
        "\n",
        "\n",
        "# for num_topics in range(1, 51):\n",
        "#     start_time = time.time()  # Mulai timer\n",
        "\n",
        "#     # Train LDA model\n",
        "#     lda_model_lda = LdaModel(\n",
        "#         corpus=corpus_all,\n",
        "#         id2word=dictionary_all,\n",
        "#         num_topics=num_topics,\n",
        "#         alpha=0.5,   # Bisa diganti dengan nilai tetap\n",
        "#         eta=0.01,     # Bisa diganti dengan nilai tetap\n",
        "#         passes=50,\n",
        "#         random_state=42,\n",
        "#         iterations= 400,\n",
        "#     )\n",
        "\n",
        "#     # Evaluasi dengan coherence score\n",
        "#     coherence_model_lda= CoherenceModel(\n",
        "#         model=lda_model_lda,\n",
        "#         texts=proposal_df['processed'].tolist() + expert_df['processed'].tolist(),\n",
        "#         dictionary=dictionary_all,\n",
        "#         coherence='c_v'\n",
        "#     )\n",
        "#     coherence_score_lda = coherence_model_lda.get_coherence()\n",
        "\n",
        "#     # Evaluasi Topic Diversity\n",
        "#     top_words_per_topic_lda = [lda_model_lda.show_topic(topic_id, topn=20) for topic_id in range(num_topics)]\n",
        "#     unique_words_lda = set([word for topic in top_words_per_topic_lda for word, _ in topic])\n",
        "#     total_words_lda = num_topics * 20  # 10 kata per topik\n",
        "#     topic_diversity_lda = len(unique_words_lda) / total_words_lda if total_words_lda > 0 else 0\n",
        "\n",
        "#     # Hitung waktu eksekusi\n",
        "#     time_taken_lda = time.time() - start_time\n",
        "\n",
        "#     # Simpan hasil dalam list\n",
        "#     results_lda.append([num_topics, coherence_score_lda, topic_diversity_lda, time_taken_lda])\n",
        "#     print(f\"Topics: {num_topics} | Coherence: {coherence_score_lda:.4f} | Diversity: {topic_diversity_lda:.4f} | Time: {time_taken_lda:.2f} sec\")\n",
        "\n",
        "# # Simpan ke DataFrame\n",
        "# results_looping_df = pd.DataFrame(results_lda, columns=['num_topics', 'coherence_score_lda', 'topic_diversity_lda', 'time_taken_lda'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6DYahm2FTpy"
      },
      "outputs": [],
      "source": [
        "# results_looping_df.to_csv('/content/drive/MyDrive/Skripsi4/topik/dictionary/looping_baru.csv', index=False, encoding='utf-8-sig')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OJDKKZUd8Kqz"
      },
      "outputs": [],
      "source": [
        "from itertools import combinations\n",
        "\n",
        "num_topics = 30  # atau optimalisasi via coherence\n",
        "\n",
        "lda_model = LdaModel(\n",
        "    corpus=corpus_all,\n",
        "    id2word=dictionary_all,\n",
        "    num_topics=num_topics,\n",
        "    passes=50,\n",
        "    random_state=42,\n",
        "    iterations= 400,\n",
        "    alpha=0.5,\n",
        "    eta=0.01\n",
        "\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "R5k7jvUSj35x"
      },
      "outputs": [],
      "source": [
        "from gensim.matutils import sparse2full\n",
        "\n",
        "# Fungsi untuk mendapatkan dense topic vector\n",
        "def get_topic_vector(lda_model, dictionary, document, num_topics):\n",
        "    bow = dictionary.doc2bow(document)\n",
        "    topic_dist = lda_model.get_document_topics(bow, minimum_probability=0.00001)\n",
        "    return sparse2full(topic_dist, num_topics)\n",
        "\n",
        "# Ambil jumlah topik dari model LDA\n",
        "num_topics = lda_model.num_topics\n",
        "\n",
        "# Hitung topik vektor dalam bentuk dense array (untuk expert)\n",
        "expert_df[\"topic_vector\"] = [\n",
        "    get_topic_vector(lda_model, dictionary_all, doc, num_topics)\n",
        "    for doc in expert_df[\"processed\"]\n",
        "]\n",
        "\n",
        "# Hitung topik vektor dalam bentuk dense array (untuk proposal)\n",
        "proposal_df[\"topic_vector\"] = [\n",
        "    get_topic_vector(lda_model, dictionary_all, doc, num_topics)\n",
        "    for doc in proposal_df[\"processed\"]\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "tZFE5rntA7F4"
      },
      "outputs": [],
      "source": [
        "proposal_df[\"tahun\"] = proposal_df[\"proposal_year\"].astype(int)\n",
        "expert_df[\"pub_year\"] = expert_df[\"research_pub_year\"].astype(int)\n",
        "\n",
        "\n",
        "def similarity_m_to_d(proposal_vector, expert_vector):\n",
        "    numerator = np.dot(proposal_vector, expert_vector)\n",
        "    denominator = (np.linalg.norm(proposal_vector) + 1e-10)\n",
        "    return numerator / (denominator)\n",
        "\n",
        "\n",
        "def similarity_d_to_m(expert_vector, proposal_vector):\n",
        "    numerator = np.dot(expert_vector, proposal_vector)\n",
        "    denominator = (np.linalg.norm(expert_vector) + 1e-10)\n",
        "    return numerator / (denominator)\n",
        "\n",
        "def time_decay(year_prop, year_ex, t=1, gamma=0.1):\n",
        "    decay = 1 - ((year_prop - year_ex) / t) * gamma\n",
        "    return max(decay, 0.0)  # tidak boleh negatif\n",
        "\n",
        "# mapping Dosen dengan ID Dosen\n",
        "\n",
        "dosen_id_map = pd.read_csv(\"/content/drive/MyDrive/Skripsi3/Dataset/mapping.csv\")  # pastikan kolom: expert_id, expert_name\n",
        "dosen_id_map[\"expert_name\"] = dosen_id_map[\"expert_name\"].str.strip().str.lower()\n",
        "\n",
        "\n",
        "def explode_authors_with_weights(df, dosen_id_map):\n",
        "    rows = []\n",
        "\n",
        "    # Normalisasi nama dosen agar cocok\n",
        "    dosen_id_map = dosen_id_map.copy()\n",
        "    dosen_id_map[\"expert_name\"] = dosen_id_map[\"expert_name\"].str.strip().str.lower()\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        authors = row.get(\"authors\", [])\n",
        "        # Bersihkan nama kosong atau NaN\n",
        "        authors = [a for a in authors if isinstance(a, str) and a.strip() != \"\"]\n",
        "\n",
        "        num_authors = len(authors)\n",
        "        for idx, name in enumerate(authors):\n",
        "            name_clean = name.strip().lower()\n",
        "\n",
        "            if num_authors == 1:\n",
        "                weight = 1.0\n",
        "            else:\n",
        "                weight = 0.6 if idx == 0 else 0.4 / (num_authors - 1)\n",
        "\n",
        "            new_row = row.to_dict()\n",
        "            new_row[\"name\"] = name\n",
        "            new_row[\"author_position\"] = idx + 1\n",
        "            new_row[\"num_authors\"] = num_authors\n",
        "            new_row[\"author_weight\"] = round(weight, 4)\n",
        "\n",
        "            matched = dosen_id_map[dosen_id_map[\"expert_name\"] == name_clean]\n",
        "            new_row[\"expert_id\"] = matched[\"expert_id\"].values[0] if not matched.empty else None\n",
        "\n",
        "            rows.append(new_row)\n",
        "\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "# Gabungkan author_1 sampai author_6 jadi list\n",
        "author_cols = [\"author_1\", \"author_2\", \"author_3\", \"author_4\", \"author_5\", \"author_6\"]\n",
        "expert_df[\"authors\"] = expert_df[author_cols].values.tolist()\n",
        "\n",
        "# Hapus duplikat berdasarkan research_id\n",
        "expert_df = expert_df.drop_duplicates(subset=[\"research_id\"]).copy()\n",
        "\n",
        "# Jalankan explode\n",
        "expert_df = explode_authors_with_weights(expert_df, dosen_id_map)\n",
        "\n",
        "# Opsional: hanya simpan baris dengan expert_id valid\n",
        "expert_df = expert_df[expert_df[\"expert_id\"].notna()]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "id": "WOc8HgLHAzGS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "831aae36-3521-4d21-e4bd-0d6a10483a88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              topic_1   topic_2   topic_3   topic_4   topic_5   topic_6  \\\n",
            "research_id                                                               \n",
            "R1           0.036934  0.087059  0.162502  0.009125  0.007667  0.005118   \n",
            "R1           0.036934  0.087059  0.162502  0.009125  0.007667  0.005118   \n",
            "R2           0.006545  0.471147  0.005548  0.145334  0.008565  0.005310   \n",
            "R3           0.006596  0.006009  0.005173  0.011906  0.006250  0.005892   \n",
            "R3           0.006596  0.006009  0.005173  0.011906  0.006250  0.005892   \n",
            "...               ...       ...       ...       ...       ...       ...   \n",
            "R464         0.007638  0.008468  0.007235  0.007249  0.008771  0.006685   \n",
            "R464         0.007638  0.008468  0.007235  0.007249  0.008771  0.006685   \n",
            "R465         0.007437  0.019320  0.113598  0.007250  0.007641  0.007323   \n",
            "R466         0.007806  0.024004  0.060841  0.006231  0.007779  0.044248   \n",
            "R467         0.035698  0.004191  0.004376  0.031360  0.004495  0.005574   \n",
            "\n",
            "              topic_7   topic_8   topic_9  topic_10  ...  topic_21  topic_22  \\\n",
            "research_id                                          ...                       \n",
            "R1           0.009551  0.005053  0.005928  0.004739  ...  0.081586  0.015830   \n",
            "R1           0.009551  0.005053  0.005928  0.004739  ...  0.081586  0.015830   \n",
            "R2           0.006543  0.038565  0.126235  0.005596  ...  0.007144  0.031732   \n",
            "R3           0.006181  0.006391  0.063485  0.007271  ...  0.142185  0.005525   \n",
            "R3           0.006181  0.006391  0.063485  0.007271  ...  0.142185  0.005525   \n",
            "...               ...       ...       ...       ...  ...       ...       ...   \n",
            "R464         0.008637  0.009914  0.044502  0.007151  ...  0.008549  0.018065   \n",
            "R464         0.008637  0.009914  0.044502  0.007151  ...  0.008549  0.018065   \n",
            "R465         0.008688  0.008386  0.009354  0.053396  ...  0.007754  0.008048   \n",
            "R466         0.007998  0.058005  0.021870  0.071814  ...  0.006546  0.010495   \n",
            "R467         0.006838  0.004902  0.004003  0.060737  ...  0.004580  0.011113   \n",
            "\n",
            "             topic_23  topic_24  topic_25  topic_26  topic_27  topic_28  \\\n",
            "research_id                                                               \n",
            "R1           0.007354  0.004395  0.005182  0.004808  0.005256  0.015108   \n",
            "R1           0.007354  0.004395  0.005182  0.004808  0.005256  0.015108   \n",
            "R2           0.005176  0.005570  0.005305  0.006651  0.006503  0.005951   \n",
            "R3           0.004820  0.005692  0.005154  0.064556  0.513471  0.005968   \n",
            "R3           0.004820  0.005692  0.005154  0.064556  0.513471  0.005968   \n",
            "...               ...       ...       ...       ...       ...       ...   \n",
            "R464         0.008635  0.008771  0.007061  0.008076  0.008223  0.007076   \n",
            "R464         0.008635  0.008771  0.007061  0.008076  0.008223  0.007076   \n",
            "R465         0.127939  0.082473  0.008398  0.011273  0.030422  0.012522   \n",
            "R466         0.291508  0.057444  0.007056  0.024863  0.095874  0.008414   \n",
            "R467         0.004510  0.004388  0.004597  0.009151  0.096884  0.004668   \n",
            "\n",
            "             topic_29  topic_30  \n",
            "research_id                      \n",
            "R1           0.005251  0.009927  \n",
            "R1           0.005251  0.009927  \n",
            "R2           0.015864  0.008093  \n",
            "R3           0.005415  0.005455  \n",
            "R3           0.005415  0.005455  \n",
            "...               ...       ...  \n",
            "R464         0.008694  0.017505  \n",
            "R464         0.008694  0.017505  \n",
            "R465         0.008058  0.008420  \n",
            "R466         0.006455  0.007044  \n",
            "R467         0.005701  0.469570  \n",
            "\n",
            "[760 rows x 30 columns]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "topic_matrix_expert = np.vstack(expert_df[\"topic_vector\"])\n",
        "topic_df = pd.DataFrame(\n",
        "    topic_matrix_expert,\n",
        "    columns=[f\"topic_{i+1}\" for i in range(lda_model.num_topics)]\n",
        ")\n",
        "\n",
        "topic_df[\"research_id\"] = expert_df[\"research_id\"].values\n",
        "\n",
        "topic_df.set_index(\"research_id\", inplace=True)\n",
        "print(topic_df)\n",
        "# topic_df.to_csv('/content/drive/MyDrive/Skripsi4/dictionary/vektorExpert_30.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "4zhzx4doA_MN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57f8972b-f6ea-4ed8-d4a4-53888d7649d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              topic_1   topic_2   topic_3   topic_4   topic_5   topic_6  \\\n",
            "proposal_id                                                               \n",
            "P1           0.000480  0.000403  0.000377  0.000371  0.000397  0.000356   \n",
            "P10          0.000311  0.000315  0.000309  0.000329  0.000339  0.000282   \n",
            "P11          0.000296  0.000328  0.129495  0.000294  0.000330  0.002315   \n",
            "P12          0.000298  0.000340  0.061452  0.000436  0.000404  0.041874   \n",
            "P13          0.000413  0.000604  0.000466  0.000439  0.000457  0.000439   \n",
            "...               ...       ...       ...       ...       ...       ...   \n",
            "P138         0.000549  0.000407  0.000402  0.000414  0.000430  0.000382   \n",
            "P139         0.004678  0.000600  0.000755  0.000581  0.006652  0.013836   \n",
            "P140         0.000468  0.000449  0.000388  0.011474  0.000424  0.000355   \n",
            "P141         0.066119  0.001308  0.001186  0.001534  0.001554  0.001019   \n",
            "P142         0.026073  0.001327  0.050764  0.006353  0.000914  0.000736   \n",
            "\n",
            "              topic_7   topic_8   topic_9  topic_10  ...  topic_21  topic_22  \\\n",
            "proposal_id                                          ...                       \n",
            "P1           0.000432  0.000453  0.000386  0.728977  ...  0.000456  0.000384   \n",
            "P10          0.004284  0.000553  0.016682  0.000329  ...  0.874469  0.000440   \n",
            "P11          0.000484  0.000322  0.000351  0.000332  ...  0.000316  0.000425   \n",
            "P12          0.000365  0.000324  0.000391  0.000448  ...  0.000451  0.000323   \n",
            "P13          0.000433  0.000465  0.000498  0.000511  ...  0.000443  0.000417   \n",
            "...               ...       ...       ...       ...  ...       ...       ...   \n",
            "P138         0.880475  0.000434  0.000402  0.000428  ...  0.000407  0.000550   \n",
            "P139         0.000858  0.000626  0.000777  0.000609  ...  0.000636  0.000679   \n",
            "P140         0.048857  0.001741  0.042597  0.000369  ...  0.014811  0.017183   \n",
            "P141         0.001466  0.013009  0.001998  0.001218  ...  0.001524  0.001320   \n",
            "P142         0.099742  0.000997  0.002155  0.000713  ...  0.000944  0.000768   \n",
            "\n",
            "             topic_23  topic_24  topic_25  topic_26  topic_27  topic_28  \\\n",
            "proposal_id                                                               \n",
            "P1           0.000374  0.000441  0.000508  0.000451  0.000390  0.259237   \n",
            "P10          0.000285  0.001050  0.000313  0.000440  0.000319  0.000299   \n",
            "P11          0.011717  0.000363  0.000298  0.000364  0.000365  0.000314   \n",
            "P12          0.000499  0.000741  0.000335  0.000337  0.124275  0.000319   \n",
            "P13          0.000549  0.000450  0.000414  0.000443  0.000452  0.000523   \n",
            "...               ...       ...       ...       ...       ...       ...   \n",
            "P138         0.000385  0.000384  0.000364  0.000581  0.000449  0.000385   \n",
            "P139         0.000627  0.000579  0.000751  0.000597  0.000785  0.000684   \n",
            "P140         0.000388  0.000352  0.000324  0.000814  0.012310  0.000390   \n",
            "P141         0.001256  0.001071  0.001094  0.145356  0.001716  0.001239   \n",
            "P142         0.000725  0.000819  0.000753  0.012283  0.001344  0.000704   \n",
            "\n",
            "             topic_29  topic_30  \n",
            "proposal_id                      \n",
            "P1           0.000406  0.000442  \n",
            "P10          0.000376  0.000350  \n",
            "P11          0.000330  0.000432  \n",
            "P12          0.001845  0.000359  \n",
            "P13          0.000479  0.000436  \n",
            "...               ...       ...  \n",
            "P138         0.000391  0.000388  \n",
            "P139         0.001164  0.000593  \n",
            "P140         0.008134  0.000431  \n",
            "P141         0.001314  0.001407  \n",
            "P142         0.000843  0.000644  \n",
            "\n",
            "[142 rows x 30 columns]\n"
          ]
        }
      ],
      "source": [
        "topic_matrix_proposal = np.vstack(proposal_df[\"topic_vector\"])\n",
        "topic_proposal_df = pd.DataFrame(topic_matrix_proposal, columns=[f\"topic_{i+1}\" for i in range(lda_model.num_topics)])\n",
        "topic_proposal_df[\"proposal_id\"] = proposal_df[\"proposal_id\"].values\n",
        "\n",
        "# Set kolom id_dosen sebagai index\n",
        "topic_proposal_df.set_index(\"proposal_id\", inplace=True)\n",
        "print(topic_proposal_df)\n",
        "# topic_proposal_df.to_csv('/content/drive/MyDrive/Skripsi4/dictionary/vektorProposal_30.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kktZnb3TBCsE"
      },
      "source": [
        "# Kemiripan"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Skripsi4/dictionary/exploded.csv\")\n",
        "\n",
        "import re\n",
        "import ast\n",
        "\n",
        "def fix_vector(text):\n",
        "    if isinstance(text, str):\n",
        "        # Tambahkan koma antara angka yang dipisah spasi\n",
        "        text_fixed = re.sub(r'(?<=\\d)\\s+(?=\\d)', ', ', text.strip())\n",
        "        try:\n",
        "            return ast.literal_eval(text_fixed)\n",
        "        except:\n",
        "            return []\n",
        "    return text\n",
        "\n",
        "df[\"topic_vector\"] = df[\"topic_vector\"].apply(fix_vector)\n",
        "\n",
        "df[\"topic_vector\"].apply(lambda x: len(x)).value_counts()\n",
        "\n",
        "df.to_csv(\"/content/drive/MyDrive/Skripsi4/dictionary/exploded_clean.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "2YP_SVniKqJ3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pAGdpruELTI"
      },
      "source": [
        "## Directed M->D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "3BwQYxgFDHL6"
      },
      "outputs": [],
      "source": [
        "def compute_od_m_to_d(proposals_df, experts_df):\n",
        "    all_results = []\n",
        "\n",
        "    for _, proposal in proposals_df.iterrows():\n",
        "        proposal_vector = proposal[\"topic_vector\"]\n",
        "        mahasiswa = proposal[\"student_id\"]\n",
        "        id_proposal = proposal[\"proposal_id\"]\n",
        "        tahun_proposal = proposal[\"tahun\"]\n",
        "\n",
        "        for _, expert in expert_df.iterrows():\n",
        "            expert_vector = expert[\"topic_vector\"]\n",
        "            dosen = expert[\"name\"]\n",
        "            id_dosen = expert[\"expert_id\"]\n",
        "            id_penelitian = expert[\"research_id\"]\n",
        "            tahun_penelitian = expert[\"pub_year\"]\n",
        "            weight = expert.get(\"author_weight\")\n",
        "            position= expert[\"author_position\"]\n",
        "\n",
        "            sim_mahasiswa = similarity_m_to_d(proposal_vector, expert_vector)\n",
        "            score = sim_mahasiswa * weight\n",
        "\n",
        "            all_results.append({\n",
        "                \"id_proposal\": id_proposal,\n",
        "                \"id_penelitian\": id_penelitian,\n",
        "                \"mahasiswa\": mahasiswa,\n",
        "                \"dosen\": dosen,\n",
        "                \"id_dosen\": id_dosen,\n",
        "                \"posisi_author\": position,\n",
        "                \"author_weight\":weight,\n",
        "                \"tahun_proposal\": tahun_proposal,\n",
        "                \"tahun_penelitian\": tahun_penelitian,\n",
        "                \"OD(M→D)\": round(score, 4)\n",
        "            })\n",
        "    df_scores = pd.DataFrame(all_results)\n",
        "    df_scores = df_scores.sort_values(by=[\"id_proposal\", \"OD(M→D)\"], ascending=[True, False])\n",
        "    return df_scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "collapsed": true,
        "id": "tc1RIoXLFNaR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01c31f7b-9c12-4efa-e3ca-af3758d36a95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    id_proposal mahasiswa id_penelitian              dosen id_dosen  \\\n",
            "521          P1        S1          R333  Hasan Dwi Cahyono      D13   \n",
            "520          P1        S1          R332  Hasan Dwi Cahyono      D13   \n",
            "420          P1        S1          R253    Bambang Harjito       D1   \n",
            "436          P1        S1          R266        Umi Salamah       D3   \n",
            "741          P1        S1          R456    Bambang Harjito       D1   \n",
            "489          P1        S1          R307            Wiharto      D12   \n",
            "575          P1        S1          R363    Bambang Harjito       D1   \n",
            "163          P1        S1           R97            Wiranto       D2   \n",
            "83           P1        S1           R48    Bambang Harjito       D1   \n",
            "137          P1        S1           R83       Esti Suryani       D8   \n",
            "437          P1        S1          R267        Umi Salamah       D3   \n",
            "270          P1        S1          R158      Heri Prasetyo      D15   \n",
            "416          P1        S1          R251    Bambang Harjito       D1   \n",
            "533          P1        S1          R339    Bambang Harjito       D1   \n",
            "21           P1        S1           R13            Wiharto      D12   \n",
            "742          P1        S1          R456      Heri Prasetyo      D15   \n",
            "91           P1        S1           R53       Esti Suryani       D8   \n",
            "435          P1        S1          R265        Umi Salamah       D3   \n",
            "729          P1        S1          R448       Esti Suryani       D8   \n",
            "164          P1        S1           R97       Esti Suryani       D8   \n",
            "84           P1        S1           R48       Esti Suryani       D8   \n",
            "434          P1        S1          R264        Umi Salamah       D3   \n",
            "545          P1        S1          R345    Bambang Harjito       D1   \n",
            "753          P1        S1          R463    Bambang Harjito       D1   \n",
            "138          P1        S1           R83         Abdul Aziz       D5   \n",
            "56           P1        S1           R33    Bambang Harjito       D1   \n",
            "650          P1        S1          R401        Umi Salamah       D3   \n",
            "681          P1        S1          R422    Ardhi Wijayanto      D16   \n",
            "585          P1        S1          R368    Ardhi Wijayanto      D16   \n",
            "417          P1        S1          R251            Winarno      D11   \n",
            "\n",
            "     posisi_author  author_weight  OD(M→D)  \n",
            "521              1            1.0   0.4137  \n",
            "520              1            1.0   0.3417  \n",
            "420              1            1.0   0.3370  \n",
            "436              1            1.0   0.2212  \n",
            "741              1            0.6   0.2137  \n",
            "489              1            1.0   0.2089  \n",
            "575              1            1.0   0.2035  \n",
            "163              1            0.6   0.1992  \n",
            "83               1            0.6   0.1990  \n",
            "137              1            0.6   0.1832  \n",
            "437              1            1.0   0.1766  \n",
            "270              1            1.0   0.1696  \n",
            "416              1            0.6   0.1606  \n",
            "533              1            0.6   0.1558  \n",
            "21               1            0.6   0.1525  \n",
            "742              2            0.4   0.1425  \n",
            "91               1            0.6   0.1382  \n",
            "435              1            1.0   0.1377  \n",
            "729              1            0.6   0.1340  \n",
            "164              2            0.4   0.1328  \n",
            "84               2            0.4   0.1327  \n",
            "434              1            1.0   0.1305  \n",
            "545              1            0.6   0.1294  \n",
            "753              1            0.6   0.1290  \n",
            "138              2            0.4   0.1222  \n",
            "56               1            1.0   0.1195  \n",
            "650              1            1.0   0.1188  \n",
            "681              1            0.6   0.1127  \n",
            "585              1            1.0   0.1101  \n",
            "417              2            0.4   0.1071  \n"
          ]
        }
      ],
      "source": [
        "od_m2d_df = compute_od_m_to_d(proposal_df, expert_df)\n",
        "print(od_m2d_df[[\"id_proposal\", \"mahasiswa\",\"id_penelitian\",\"dosen\",\"id_dosen\",\"posisi_author\",\"author_weight\", \"OD(M→D)\"]].head(30))\n",
        "\n",
        "# od_m2d_df.to_csv(\"/content/drive/MyDrive/Skripsi4/topik/directed/30/od_m2d_df_topik.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5FkdQdcHvI2"
      },
      "source": [
        "## TOD M->D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "iUx5KCOsFSFm"
      },
      "outputs": [],
      "source": [
        "# Hitung TOD(M→D)\n",
        "def compute_tod_m_to_d(od_df, t=1, gamma=0.1, max_year_diff=5):\n",
        "    od_df = od_df.copy()\n",
        "\n",
        "    # Hitung selisih tahun\n",
        "    od_df[\"selisih_tahun\"] = od_df[\"tahun_proposal\"] - od_df[\"tahun_penelitian\"]\n",
        "\n",
        "    # Filter: proposal harus lebih baru dari publikasi, dan selisih maksimal 5 tahun\n",
        "    od_df = od_df[(od_df[\"selisih_tahun\"] >= 0) & (od_df[\"selisih_tahun\"] <= max_year_diff)].copy()\n",
        "\n",
        "    # Hitung time decay factor\n",
        "    od_df[\"time_decay_factor\"] = od_df.apply(\n",
        "        lambda row: time_decay(row[\"tahun_proposal\"], row[\"tahun_penelitian\"], t=t, gamma=gamma),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # Hitung TOD(M→D)\n",
        "    od_df[\"TOD(M→D)\"] = (od_df[\"OD(M→D)\"] * od_df[\"time_decay_factor\"]).round(4)\n",
        "\n",
        "    return od_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "qMgz9n1VHzFg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afa98d4b-5dfd-4f93-a27a-505841b60f42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id_proposal mahasiswa id_penelitian            dosen id_dosen  OD(M→D)  \\\n",
            "3           P1        S1          R307          Wiharto      D12   0.2089   \n",
            "9           P1        S1          R266      Umi Salamah       D3   0.2212   \n",
            "8           P1        S1           R97          Wiranto       D2   0.1992   \n",
            "0           P1        S1           R48  Bambang Harjito       D1   0.1990   \n",
            "14          P1        S1           R53     Esti Suryani       D8   0.1382   \n",
            "\n",
            "    tahun_proposal  tahun_penelitian  selisih_tahun  time_decay_factor  \\\n",
            "3             2021              2020              1                0.9   \n",
            "9             2021              2018              3                0.7   \n",
            "8             2021              2018              3                0.7   \n",
            "0             2021              2018              3                0.7   \n",
            "14            2021              2021              0                1.0   \n",
            "\n",
            "    TOD(M→D)  \n",
            "3     0.1880  \n",
            "9     0.1548  \n",
            "8     0.1394  \n",
            "0     0.1393  \n",
            "14    0.1382  \n"
          ]
        }
      ],
      "source": [
        "# Hitung TOD(M→D) Disortir\n",
        "tod_m2d_df= compute_tod_m_to_d(od_m2d_df, t=1, gamma=0.1, max_year_diff=5)\n",
        "\n",
        "tod_m2d_df = (\n",
        "    tod_m2d_df\n",
        "    .loc[tod_m2d_df.groupby([\"id_proposal\", \"id_dosen\"])[\"TOD(M→D)\"].idxmax()]\n",
        "    .reset_index(drop=True)\n",
        "    .sort_values(by=[\"id_proposal\", \"TOD(M→D)\"], ascending=[True, False])\n",
        ")\n",
        "\n",
        "\n",
        "# Lihat contoh hasil\n",
        "\n",
        "print(tod_m2d_df[[\"id_proposal\",\"mahasiswa\", \"id_penelitian\",\"dosen\",\"id_dosen\", \"OD(M→D)\", \"tahun_proposal\",\"tahun_penelitian\",\"selisih_tahun\", \"time_decay_factor\", \"TOD(M→D)\"]].head(5))\n",
        "\n",
        "# tod_m2d_df.to_csv(\"/content/drive/MyDrive/Skripsi4/topik/directed/30/tod_m2d_df_topik.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXJRYVfCIx5Z"
      },
      "source": [
        "# OD D->M"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Ql8l9N2zYCoS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7585b4c-fc5e-48d8-faeb-d1b3276ccec3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     id_proposal mahasiswa id_penelitian            dosen id_dosen  \\\n",
            "100         P104      S104          R363  Bambang Harjito       D1   \n",
            "392         P120      S120           R50  Bambang Harjito       D1   \n",
            "1627         P64       S64          R363  Bambang Harjito       D1   \n",
            "1579         P61       S61           R56  Bambang Harjito       D1   \n",
            "1945         P82       S82          R344  Bambang Harjito       D1   \n",
            "\n",
            "      posisi_author  author_weight  OD(D→M)  \n",
            "100               1            1.0   0.9023  \n",
            "392               1            1.0   0.8934  \n",
            "1627              1            1.0   0.7232  \n",
            "1579              1            1.0   0.5444  \n",
            "1945              1            1.0   0.5355  \n"
          ]
        }
      ],
      "source": [
        "def compute_od_d_to_m(proposals_df, experts_df):\n",
        "    results = []\n",
        "\n",
        "    for _, expert in experts_df.iterrows():\n",
        "        expert_vector = expert[\"topic_vector\"]\n",
        "        dosen = expert[\"name\"]\n",
        "        id_dosen = expert[\"expert_id\"]\n",
        "        id_penelitian = expert[\"research_id\"]\n",
        "        weight = expert[\"author_weight\"]\n",
        "        position = expert[\"author_position\"]\n",
        "        tahun_penelitian = expert[\"pub_year\"]\n",
        "\n",
        "        for _, proposal in proposals_df.iterrows():\n",
        "            proposal_vector = proposal[\"topic_vector\"]\n",
        "            mahasiswa = proposal[\"student_id\"]\n",
        "            id_proposal = proposal[\"proposal_id\"]\n",
        "            tahun_proposal = proposal[\"tahun\"]\n",
        "\n",
        "            # # Tambahkan filter tahun\n",
        "            selisih_tahun = tahun_proposal - tahun_penelitian\n",
        "            if 0 < selisih_tahun <= 5 and tahun_penelitian <= tahun_proposal:\n",
        "               sim_dosen = similarity_d_to_m(expert_vector, proposal_vector)\n",
        "               score = sim_dosen * weight\n",
        "               results.append({\n",
        "                    \"id_proposal\": id_proposal,\n",
        "                    \"id_penelitian\": id_penelitian,\n",
        "                    \"mahasiswa\": mahasiswa,\n",
        "                    \"dosen\": dosen,\n",
        "                    \"id_dosen\": id_dosen,\n",
        "                    \"posisi_author\": position,\n",
        "                    \"author_weight\": weight,\n",
        "                    \"tahun_proposal\": tahun_proposal,\n",
        "                    \"tahun_penelitian\": tahun_penelitian,\n",
        "                    \"OD(D→M)\": round(score, 4),\n",
        "                })\n",
        "\n",
        "    df_scores = pd.DataFrame(results)\n",
        "    df_scores = df_scores.loc[df_scores.groupby([\"id_proposal\",\"id_dosen\"])[\"OD(D→M)\"].idxmax()].reset_index(drop=True)\n",
        "    df_scores = df_scores.sort_values(by=[\"id_dosen\", \"OD(D→M)\"], ascending=[True, False])\n",
        "\n",
        "    return df_scores\n",
        "\n",
        "od_d2m_df = compute_od_d_to_m(proposal_df, expert_df)\n",
        "print(od_d2m_df[[\"id_proposal\", \"mahasiswa\",\"id_penelitian\", \"dosen\", \"id_dosen\",\"posisi_author\",\"author_weight\",\"OD(D→M)\"]].head(5))\n",
        "# od_d2m_df.to_csv(\"/content/drive/MyDrive/Skripsi4/topik/directed/30/od_d2m_df_topik.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLs6cYz8NWTv"
      },
      "source": [
        "# Overlap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "iCttVVnEsjV7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13a74d94-df62-409a-e461-fd77786d2f06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id_proposal mahasiswa               dosen id_dosen  TOD(M→D)  OD(D→M)  \\\n",
            "3           P1        S1             Wiharto      D12    0.1880   0.4377   \n",
            "9           P1        S1         Umi Salamah       D3    0.1548   0.4486   \n",
            "14          P1        S1        Esti Suryani       D8    0.1382   0.3555   \n",
            "8           P1        S1             Wiranto       D2    0.1394   0.3501   \n",
            "0           P1        S1     Bambang Harjito       D1    0.1393   0.3053   \n",
            "6           P1        S1       Heri Prasetyo      D15    0.1187   0.2766   \n",
            "11          P1        S1          Abdul Aziz       D5    0.0611   0.2370   \n",
            "7           P1        S1     Ardhi Wijayanto      D16    0.0902   0.1573   \n",
            "13          P1        S1      Wisnu Widiarto       D7    0.0602   0.1489   \n",
            "12          P1        S1       Ristu Saptono       D6    0.0459   0.1313   \n",
            "15          P1        S1    Sari Widya Sihwi       D9    0.0326   0.1380   \n",
            "5           P1        S1     Haryono Setiadi      D14    0.0486   0.1075   \n",
            "1           P1        S1      Afrizal Doewes      D10    0.0317   0.1054   \n",
            "4           P1        S1   Hasan Dwi Cahyono      D13    0.0208   0.0637   \n",
            "10          P1        S1  Dewi Wisnu Wardani       D4    0.0184   0.0371   \n",
            "2           P1        S1             Winarno      D11    0.0091   0.0174   \n",
            "27         P10       S10          Abdul Aziz       D5    0.3292   0.7792   \n",
            "18         P10       S10             Winarno      D11    0.1648   0.4424   \n",
            "25         P10       S10         Umi Salamah       D3    0.0835   0.3600   \n",
            "21         P10       S10     Haryono Setiadi      D14    0.0995   0.2501   \n",
            "30         P10       S10        Esti Suryani       D8    0.0557   0.2400   \n",
            "19         P10       S10             Wiharto      D12    0.0717   0.1906   \n",
            "17         P10       S10      Afrizal Doewes      D10    0.0690   0.1165   \n",
            "31         P10       S10    Sari Widya Sihwi       D9    0.0426   0.1356   \n",
            "28         P10       S10       Ristu Saptono       D6    0.0449   0.0880   \n",
            "16         P10       S10     Bambang Harjito       D1    0.0288   0.0931   \n",
            "29         P10       S10      Wisnu Widiarto       D7    0.0286   0.0835   \n",
            "24         P10       S10             Wiranto       D2    0.0243   0.0758   \n",
            "22         P10       S10       Heri Prasetyo      D15    0.0374   0.0369   \n",
            "23         P10       S10     Ardhi Wijayanto      D16    0.0243   0.0482   \n",
            "\n",
            "    skor_rata2  overlap  \n",
            "3      0.31285     True  \n",
            "9      0.30170     True  \n",
            "14     0.24685     True  \n",
            "8      0.24475     True  \n",
            "0      0.22230     True  \n",
            "6      0.19765     True  \n",
            "11     0.14905     True  \n",
            "7      0.12375     True  \n",
            "13     0.10455     True  \n",
            "12     0.08860     True  \n",
            "15     0.08530     True  \n",
            "5      0.07805     True  \n",
            "1      0.06855     True  \n",
            "4      0.04225     True  \n",
            "10     0.02775     True  \n",
            "2      0.01325     True  \n",
            "27     0.55420     True  \n",
            "18     0.30360     True  \n",
            "25     0.22175     True  \n",
            "21     0.17480     True  \n",
            "30     0.14785     True  \n",
            "19     0.13115     True  \n",
            "17     0.09275     True  \n",
            "31     0.08910     True  \n",
            "28     0.06645     True  \n",
            "16     0.06095     True  \n",
            "29     0.05605     True  \n",
            "24     0.05005     True  \n",
            "22     0.03715     True  \n",
            "23     0.03625     True  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def combine_overlap_scores(df_m2d, df_d2m):\n",
        "    # Ambil semua kolom yang dibutuhkan dari masing-masing arah\n",
        "    top_m2d = df_m2d[[\"id_proposal\", \"mahasiswa\", \"id_dosen\", \"dosen\", \"TOD(M→D)\"]]\n",
        "    top_d2m = df_d2m[[\"id_proposal\", \"mahasiswa\", \"id_dosen\", \"dosen\", \"OD(D→M)\"]]\n",
        "\n",
        "    # Gabungkan kedua dataframe berdasarkan id_proposal dan id_dosen\n",
        "    merged = pd.merge(top_m2d, top_d2m, on=[\"id_proposal\", \"id_dosen\"], how=\"outer\", suffixes=('_m2d', '_d2m'))\n",
        "\n",
        "    # Gabungkan kolom nama mahasiswa dan dosen (dari salah satu sisi)\n",
        "    merged[\"mahasiswa\"] = merged[\"mahasiswa_m2d\"].combine_first(merged[\"mahasiswa_d2m\"])\n",
        "    merged[\"dosen\"] = merged[\"dosen_m2d\"].combine_first(merged[\"dosen_d2m\"])\n",
        "\n",
        "    # Ganti NaN skor dengan 0\n",
        "    merged[\"TOD(M→D)\"] = merged[\"TOD(M→D)\"].fillna(0)\n",
        "    merged[\"OD(D→M)\"] = merged[\"OD(D→M)\"].fillna(0)\n",
        "\n",
        "    # Tandai overlap jika skor dari dua arah ada (lebih dari 0)\n",
        "    merged[\"overlap\"] = (merged[\"TOD(M→D)\"] > 0) & (merged[\"OD(D→M)\"] > 0)\n",
        "\n",
        "    # Hitung skor rata-rata hanya jika overlap, jika tidak maka 0\n",
        "    merged[\"skor_rata2\"] = merged.apply(\n",
        "        lambda row: (row[\"TOD(M→D)\"] + row[\"OD(D→M)\"]) / 2 if row[\"overlap\"] else 0, axis=1\n",
        "    )\n",
        "\n",
        "    # Urutkan berdasarkan skor rata-rata tertinggi untuk setiap proposal\n",
        "    final_scores = merged.sort_values(by=[\"id_proposal\", \"skor_rata2\"], ascending=[True, False])\n",
        "\n",
        "    # Pilih kolom akhir yang relevan\n",
        "    final_scores = final_scores[[\n",
        "        \"id_proposal\", \"mahasiswa\", \"dosen\", \"id_dosen\",\n",
        "        \"TOD(M→D)\", \"OD(D→M)\", \"skor_rata2\", \"overlap\"\n",
        "    ]]\n",
        "\n",
        "    return final_scores\n",
        "\n",
        "# Contoh penggunaan:\n",
        "df_final = combine_overlap_scores(tod_m2d_df, od_d2m_df)\n",
        "print(df_final.head(30))\n",
        "# df_final.to_csv(\"/content/drive/MyDrive/Skripsi4/topik/directed/30/overlap_directed_topik.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65wj7aCgNlf3"
      },
      "source": [
        "# Ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "GsIetvPuNaPV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b7e68d5-6c55-4ae0-97b2-4a3b85afe56b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id_proposal mahasiswa               dosen id_dosen  TOD(M→D)  OD(D→M)  \\\n",
            "3           P1        S1             Wiharto      D12    0.1880   0.4377   \n",
            "9           P1        S1         Umi Salamah       D3    0.1548   0.4486   \n",
            "14          P1        S1        Esti Suryani       D8    0.1382   0.3555   \n",
            "8           P1        S1             Wiranto       D2    0.1394   0.3501   \n",
            "0           P1        S1     Bambang Harjito       D1    0.1393   0.3053   \n",
            "6           P1        S1       Heri Prasetyo      D15    0.1187   0.2766   \n",
            "11          P1        S1          Abdul Aziz       D5    0.0611   0.2370   \n",
            "7           P1        S1     Ardhi Wijayanto      D16    0.0902   0.1573   \n",
            "13          P1        S1      Wisnu Widiarto       D7    0.0602   0.1489   \n",
            "12          P1        S1       Ristu Saptono       D6    0.0459   0.1313   \n",
            "15          P1        S1    Sari Widya Sihwi       D9    0.0326   0.1380   \n",
            "5           P1        S1     Haryono Setiadi      D14    0.0486   0.1075   \n",
            "1           P1        S1      Afrizal Doewes      D10    0.0317   0.1054   \n",
            "4           P1        S1   Hasan Dwi Cahyono      D13    0.0208   0.0637   \n",
            "10          P1        S1  Dewi Wisnu Wardani       D4    0.0184   0.0371   \n",
            "2           P1        S1             Winarno      D11    0.0091   0.0174   \n",
            "27         P10       S10          Abdul Aziz       D5    0.3292   0.7792   \n",
            "18         P10       S10             Winarno      D11    0.1648   0.4424   \n",
            "25         P10       S10         Umi Salamah       D3    0.0835   0.3600   \n",
            "21         P10       S10     Haryono Setiadi      D14    0.0995   0.2501   \n",
            "\n",
            "    skor_rata2  overlap  rank  \n",
            "3      0.31285     True     1  \n",
            "9      0.30170     True     2  \n",
            "14     0.24685     True     3  \n",
            "8      0.24475     True     4  \n",
            "0      0.22230     True     5  \n",
            "6      0.19765     True     6  \n",
            "11     0.14905     True     7  \n",
            "7      0.12375     True     8  \n",
            "13     0.10455     True     9  \n",
            "12     0.08860     True    10  \n",
            "15     0.08530     True    11  \n",
            "5      0.07805     True    12  \n",
            "1      0.06855     True    13  \n",
            "4      0.04225     True    14  \n",
            "10     0.02775     True    15  \n",
            "2      0.01325     True    16  \n",
            "27     0.55420     True     1  \n",
            "18     0.30360     True     2  \n",
            "25     0.22175     True     3  \n",
            "21     0.17480     True     4  \n"
          ]
        }
      ],
      "source": [
        "def combine_overlap_scores_with_ranking(df_m2d, df_d2m):\n",
        "    # Ambil semua skor dari kedua arah\n",
        "    m2d = df_m2d[[\"id_proposal\", \"id_dosen\",\"mahasiswa\", \"dosen\", \"TOD(M→D)\"]]\n",
        "    d2m = df_d2m[[\"id_proposal\",\"id_dosen\",\"mahasiswa\",\"dosen\", \"OD(D→M)\"]]\n",
        "\n",
        "    # Outer join agar semua kombinasi muncul\n",
        "    merged = pd.merge(m2d, d2m, on=[\"id_proposal\", \"id_dosen\"], how=\"outer\")\n",
        "\n",
        "    # Tambahkan kolom nama dosen jika hilang (dari M→D arah saja)\n",
        "    if \"dosen_x\" in merged.columns:\n",
        "        merged[\"dosen\"] = merged[\"dosen_x\"].combine_first(merged.get(\"dosen_y\"))\n",
        "    elif \"dosen\" not in merged.columns:\n",
        "        merged[\"dosen\"] = None\n",
        "\n",
        "    if \"mahasiswa_x\" in merged.columns:\n",
        "        merged[\"mahasiswa\"] = merged[\"mahasiswa_x\"].combine_first(merged.get(\"mahasiswa_y\"))\n",
        "    elif \"mahasiswa\" not in merged.columns:\n",
        "        merged[\"mahasiswa\"] = None\n",
        "\n",
        "    # Isi nilai NaN dengan 0 untuk penggabungan skor\n",
        "    merged[\"TOD(M→D)\"] = merged[\"TOD(M→D)\"].fillna(0)\n",
        "    merged[\"OD(D→M)\"] = merged[\"OD(D→M)\"].fillna(0)\n",
        "\n",
        "    # Overlap = muncul di kedua arah\n",
        "    merged[\"overlap\"] = (merged[\"TOD(M→D)\"] > 0) & (merged[\"OD(D→M)\"] > 0)\n",
        "\n",
        "    # Skor rata-rata jika overlap\n",
        "    merged[\"skor_rata2\"] = merged.apply(\n",
        "        lambda row: (row[\"TOD(M→D)\"] + row[\"OD(D→M)\"]) / 2 if row[\"overlap\"] else 0, axis=1\n",
        "    )\n",
        "\n",
        "       # Hitung ranking per proposal berdasarkan skor rata-rata (tanpa groupby + agg)\n",
        "    merged[\"rank\"] = merged.groupby(\"id_proposal\")[\"skor_rata2\"]\\\n",
        "                           .rank(ascending=False, method=\"dense\")\\\n",
        "                           .astype(int)\n",
        "\n",
        "    # Ambil kolom yang diinginkan dan urutkan\n",
        "    result = merged.sort_values(by=[\"id_proposal\", \"rank\"])[\n",
        "        [\"id_proposal\",\"mahasiswa\", \"dosen\", \"id_dosen\", \"TOD(M→D)\", \"OD(D→M)\", \"skor_rata2\", \"overlap\", \"rank\"]\n",
        "    ]\n",
        "\n",
        "\n",
        "    return result.sort_values(by=[\"id_proposal\", \"rank\"])[\n",
        "        [\"id_proposal\",\"mahasiswa\", \"dosen\", \"id_dosen\", \"TOD(M→D)\", \"OD(D→M)\", \"skor_rata2\", \"overlap\", \"rank\"]\n",
        "    ]\n",
        "\n",
        "\n",
        "df_peringkat = combine_overlap_scores_with_ranking(tod_m2d_df, od_d2m_df)\n",
        "# Filter hanya yang overlap == True\n",
        "df_overlap_true = df_peringkat[df_peringkat[\"overlap\"] == True]\n",
        "print(df_overlap_true.head(20))\n",
        "\n",
        "# df_overlap_true.to_csv(\"/content/drive/MyDrive/Skripsi4/topik/directed/30/rank_overlap_true_kata.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "-CyWBkN1Nohe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d34e4ac3-82b4-4867-fbd7-ecb752c4aecb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     id_proposal mahasiswa            dosen id_dosen  TOD(M→D)  OD(D→M)  \\\n",
            "0             P1        S1          Wiharto      D12    0.1880   0.4377   \n",
            "142           P1        S1      Umi Salamah       D3    0.1548   0.4486   \n",
            "143           P1        S1     Esti Suryani       D8    0.1382   0.3555   \n",
            "144           P1        S1          Wiranto       D2    0.1394   0.3501   \n",
            "145           P1        S1  Bambang Harjito       D1    0.1393   0.3053   \n",
            "...          ...       ...              ...      ...       ...      ...   \n",
            "2243         P99       S99      Umi Salamah       D3    0.0889   0.1747   \n",
            "2244         P99       S99    Heri Prasetyo      D15    0.0633   0.1598   \n",
            "2245         P99       S99  Haryono Setiadi      D14    0.0419   0.0350   \n",
            "2246         P99       S99   Afrizal Doewes      D10    0.0229   0.0463   \n",
            "2247         P99       S99   Wisnu Widiarto       D7    0.0123   0.0361   \n",
            "\n",
            "      skor_rata2  overlap  rank  beban  \n",
            "0        0.31285     True     1      1  \n",
            "142      0.30170     True     2     11  \n",
            "143      0.24685     True     3     14  \n",
            "144      0.24475     True     4      2  \n",
            "145      0.22230     True     5      6  \n",
            "...          ...      ...   ...    ...  \n",
            "2243     0.13180     True    12     11  \n",
            "2244     0.11155     True    13     15  \n",
            "2245     0.03845     True    14      8  \n",
            "2246     0.03460     True    15      1  \n",
            "2247     0.02420     True    16      9  \n",
            "\n",
            "[2248 rows x 10 columns]\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# 1. Inisialisasi count untuk rank 1\n",
        "rank1_count_directed = defaultdict(int)\n",
        "final_assignment_directed = []\n",
        "\n",
        "# 2. Tetapkan rank 1 dengan batas 15 kali per dosen\n",
        "for pid in df_overlap_true[\"id_proposal\"].unique():\n",
        "    candidates = df_overlap_true[df_overlap_true[\"id_proposal\"] == pid]\n",
        "    candidates = candidates.sort_values(by=\"skor_rata2\", ascending=False)\n",
        "\n",
        "    assigned_rank1 = False\n",
        "    for _, row in candidates.iterrows():\n",
        "        dosen_id = row[\"id_dosen\"]\n",
        "        if rank1_count_directed[dosen_id] < 15:\n",
        "            rank1_count_directed[dosen_id] += 1\n",
        "            row_data = row.to_dict()\n",
        "            row_data[\"rank\"] = 1\n",
        "            row_data[\"beban\"] = rank1_count_directed[dosen_id]\n",
        "            final_assignment_directed.append(row_data)\n",
        "            assigned_rank1 = True\n",
        "            break\n",
        "\n",
        "    if not assigned_rank1:\n",
        "        row = candidates.iloc[0].to_dict()\n",
        "        dosen_id = row[\"id_dosen\"]\n",
        "        rank1_count_directed[dosen_id] += 1\n",
        "        row[\"rank\"] = 1\n",
        "        row[\"beban\"] = rank1_count_directed[dosen_id]\n",
        "        final_assignment_directed.append(row)\n",
        "\n",
        "# 3. Buat dataframe dari rank 1\n",
        "rank1_directed = pd.DataFrame(final_assignment_directed)\n",
        "\n",
        "# 4. Tambahkan rank 2–17 berdasarkan similarity, excl. dosen yang sudah dipakai di rank 1 untuk proposal yang sama\n",
        "other_ranks = []\n",
        "\n",
        "for pid in df_overlap_true[\"id_proposal\"].unique():\n",
        "    # Dapatkan dosen yang sudah dipakai sebagai rank 1\n",
        "    used_dosen = rank1_directed[rank1_directed[\"id_proposal\"] == pid][\"id_dosen\"].tolist()\n",
        "\n",
        "    # Ambil kandidat lain untuk proposal ini\n",
        "    candidates = df_overlap_true[(df_overlap_true[\"id_proposal\"] == pid) & (~df_overlap_true[\"id_dosen\"].isin(used_dosen))]\n",
        "    candidates = candidates.sort_values(by=\"skor_rata2\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "    for idx, (_, row) in enumerate(candidates.iterrows(), start=2):\n",
        "        if idx > 17:\n",
        "            break\n",
        "        row_data = row.to_dict()\n",
        "        row_data[\"rank\"] = idx\n",
        "        row_data[\"beban\"] = rank1_count_directed[row_data[\"id_dosen\"]]  # Beban hanya dihitung dari rank 1\n",
        "        other_ranks.append(row_data)\n",
        "\n",
        "# 5. Gabungkan rank1 dan other ranks\n",
        "df_ranked_filtered = pd.concat([rank1_directed, pd.DataFrame(other_ranks)], ignore_index=True)\n",
        "df_ranked_filtered = df_ranked_filtered.sort_values(by=[\"id_proposal\", \"rank\"])\n",
        "df_ranked_filtered = df_ranked_filtered[df_ranked_filtered[\"rank\"] <= 17]\n",
        "\n",
        "# Print the DataFrame\n",
        "print(df_ranked_filtered)\n",
        "# df_ranked_filtered.to_csv(\"/content/drive/MyDrive/Skripsi4/topik/directed/30/beban_directed_topik.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GY5LgnXwOAoi"
      },
      "source": [
        "# Evaluasi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "LWMQJ-jIOM6q"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "# Load the true labels DataFrame\n",
        "true_label_df = pd.read_csv(\"/content/drive/MyDrive/Skripsi3/Dataset/true_labels.csv\")\n",
        "\n",
        "# Ubah kolom author, author2, author3 menjadi lowercase\n",
        "true_label_df[\"author1\"] = true_label_df[\"examiner_1\"].astype(str).str.strip()\n",
        "true_label_df[\"author2\"] = true_label_df[\"examiner_2\"].astype(str).str.strip()\n",
        "true_label_df[\"author3\"] = true_label_df[\"examiner_3\"].astype(str).str.strip()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISliac_wWuZb"
      },
      "source": [
        "coba"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skG7yYjbKUlO"
      },
      "source": [
        "## Evaluasi Baru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Ks2XbNJ-Wt_2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1fa938f-2c9d-443b-8a40-b8fb6849133a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Top-N  Mean_Recall_Existence  Recall_Pos_1_Ordered  Recall_Pos_2_Ordered  \\\n",
            "0      3               0.340376              0.380282              0.056338   \n",
            "1      5               0.511737              0.380282              0.056338   \n",
            "2      7               0.636150              0.380282              0.056338   \n",
            "3     10               0.781690              0.380282              0.056338   \n",
            "\n",
            "   Recall_Pos_3_Ordered  Avg_Normalized_Euclidean  \n",
            "0              0.091549                  0.822388  \n",
            "1              0.091549                  0.710031  \n",
            "2              0.091549                  0.625719  \n",
            "3              0.091549                  0.555407  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def evaluate_ordered_recommendation_directed(rank_all_df, true_label_df, top_ns=[3, 5, 7, 10]):\n",
        "    summary = []\n",
        "\n",
        "    for TOP_N in top_ns:\n",
        "        # Filter Top-N dan urutkan\n",
        "        top_n_df = rank_all_df[rank_all_df[\"rank\"] <= TOP_N]\n",
        "        rec_df = top_n_df.sort_values(by=[\"id_proposal\", \"rank\", \"skor_rata2\"], ascending=[True, True, False])\n",
        "        rec_df = rec_df.drop_duplicates(subset=[\"id_proposal\", \"rank\",\"skor_rata2\"])\n",
        "        rec_pivot = rec_df.pivot(index=\"id_proposal\", columns=\"rank\", values=\"dosen\").reset_index()\n",
        "        rec_pivot.columns.name = None\n",
        "        rec_pivot.columns = [\"id_proposal\"] + [f\"rec_{i}\" for i in range(1, len(rec_pivot.columns))]\n",
        "\n",
        "        # Gabungkan dengan ground truth\n",
        "        merged_df = pd.merge(\n",
        "            rec_pivot,\n",
        "            true_label_df.rename(columns={\"proposal_id\": \"id_proposal\"}),\n",
        "            on=\"id_proposal\",\n",
        "            how=\"left\"\n",
        "        )\n",
        "\n",
        "        # Recall keberadaan (tidak memperhatikan urutan)\n",
        "        def recall_of_existence(row):\n",
        "            true_set = {row.get(\"author1\"), row.get(\"author2\"), row.get(\"author3\")}\n",
        "            pred_set = {row.get(f\"rec_{i}\") for i in range(1, TOP_N + 1) if row.get(f\"rec_{i}\")}\n",
        "            return len(true_set.intersection(pred_set)) / 3\n",
        "\n",
        "        merged_df[f'recall_of_existence@{TOP_N}'] = merged_df.apply(recall_of_existence, axis=1)\n",
        "\n",
        "        # Recall per posisi dengan urutan diperhatikan (rec_i harus sama dengan author_i)\n",
        "        recall_pos = {1: [], 2: [], 3: []}\n",
        "        for _, row in merged_df.iterrows():\n",
        "            for pos in [1, 2, 3]:\n",
        "                examiner = row.get(f'author{pos}')\n",
        "                rec = row.get(f'rec_{pos}') if pos <= TOP_N else None\n",
        "                hit = int(pd.notna(examiner) and pd.notna(rec) and examiner == rec)\n",
        "                recall_pos[pos].append(hit)\n",
        "\n",
        "        # Tambahkan recall ke DataFrame\n",
        "        for pos in [1, 2, 3]:\n",
        "            merged_df[f'recall_pos{pos}_ordered@{TOP_N}'] = recall_pos[pos]\n",
        "\n",
        "        recall_pos_mean = {pos: np.mean(recall_pos[pos]) for pos in [1, 2, 3]}\n",
        "\n",
        "        # Euclidean distance antar posisi (penalti posisi meleset)\n",
        "        distances = []\n",
        "        for _, row in merged_df.iterrows():\n",
        "            true_authors = [row.get(f'author{i}') for i in [1, 2, 3]]\n",
        "            pred_authors = [row.get(f'rec_{i}', None) for i in range(1, TOP_N + 1)]\n",
        "            distance = 0\n",
        "            max_penalty = TOP_N\n",
        "            for i, true_author in enumerate(true_authors):\n",
        "                if pd.isna(true_author) or true_author == '':\n",
        "                    continue\n",
        "                try:\n",
        "                    pred_pos = pred_authors.index(true_author)\n",
        "                    pos_diff = pred_pos - i\n",
        "                    distance += pos_diff ** 2\n",
        "                except ValueError:\n",
        "                    distance += max_penalty ** 2\n",
        "            distances.append(np.sqrt(distance))\n",
        "\n",
        "        scaler = MinMaxScaler()\n",
        "        norm_dists = scaler.fit_transform(np.array(distances).reshape(-1, 1)).flatten()\n",
        "        merged_df[f'norm_euclidean@{TOP_N}'] = norm_dists\n",
        "\n",
        "        # Ringkasan metrik\n",
        "        summary.append({\n",
        "            'Top-N': TOP_N,\n",
        "            'Mean_Recall_Existence': merged_df[f'recall_of_existence@{TOP_N}'].mean(),\n",
        "            'Recall_Pos_1_Ordered': recall_pos_mean[1],\n",
        "            'Recall_Pos_2_Ordered': recall_pos_mean[2],\n",
        "            'Recall_Pos_3_Ordered': recall_pos_mean[3],\n",
        "            'Avg_Normalized_Euclidean': np.mean(norm_dists)\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(summary)\n",
        "\n",
        "result_df_directed = evaluate_ordered_recommendation_directed(df_overlap_true, true_label_df)\n",
        "print(result_df_directed)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YrQO7Qbasqb"
      },
      "source": [
        "## Evaluasi per proposal Baru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "j7h0LFgnasJe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def evaluate_per_proposal_directed(rank_all_df, true_label_df, top_n=3):\n",
        "    # Filter dan urutkan\n",
        "    top_n_df = rank_all_df[rank_all_df[\"rank\"] <= top_n]\n",
        "    rec_df = top_n_df.sort_values(by=[\"id_proposal\", \"rank\", \"skor_rata2\"], ascending=[True, True, False])\n",
        "    rec_df = rec_df.drop_duplicates(subset=[\"id_proposal\", \"rank\",\"skor_rata2\"])\n",
        "    rec_pivot = rec_df.pivot(index=\"id_proposal\", columns=\"rank\", values=\"dosen\").reset_index()\n",
        "    rec_pivot.columns.name = None\n",
        "    rec_pivot.columns = [\"id_proposal\"] + [f\"rec_{i}\" for i in range(1, len(rec_pivot.columns))]\n",
        "\n",
        "    # Gabung dengan label kebenaran\n",
        "    merged_df = pd.merge(\n",
        "        rec_pivot,\n",
        "        true_label_df.rename(columns={\"proposal_id\": \"id_proposal\"}),\n",
        "        on=\"id_proposal\",\n",
        "        how=\"left\"\n",
        "    )\n",
        "\n",
        "    # Recall of existence (abaikan urutan)\n",
        "    def recall_of_existence(row):\n",
        "        true_set = {row.get(\"author1\"), row.get(\"author2\"), row.get(\"author3\")}\n",
        "        pred_set = {row.get(f\"rec_{i}\") for i in range(1, top_n + 1) if row.get(f\"rec_{i}\")}\n",
        "        return len(true_set.intersection(pred_set)) / 3\n",
        "\n",
        "    merged_df[f'recall_of_existence@{top_n}'] = merged_df.apply(recall_of_existence, axis=1)\n",
        "\n",
        "    # Recall berdasarkan posisi (urutan harus sama)\n",
        "    for pos in [1, 2, 3]:\n",
        "        merged_df[f'recall_pos{pos}_ordered@{top_n}'] = merged_df.apply(\n",
        "            lambda row: int(\n",
        "                pd.notna(row.get(f'author{pos}')) and\n",
        "                pd.notna(row.get(f'rec_{pos}')) and\n",
        "                row.get(f'author{pos}') == row.get(f'rec_{pos}')\n",
        "            ) if pos <= top_n else 0,\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "    # Euclidean distance penalti posisi\n",
        "    distances = []\n",
        "    for _, row in merged_df.iterrows():\n",
        "        true_authors = [row.get(f'author{i}') for i in [1, 2, 3]]\n",
        "        pred_authors = [row.get(f'rec_{i}', None) for i in range(1, top_n + 1)]\n",
        "        distance = 0\n",
        "        max_penalty = top_n\n",
        "        for i, true_author in enumerate(true_authors):\n",
        "            if pd.isna(true_author) or true_author == '':\n",
        "                continue\n",
        "            try:\n",
        "                pred_pos = pred_authors.index(true_author)\n",
        "                pos_diff = pred_pos - i\n",
        "                distance += pos_diff ** 2\n",
        "            except ValueError:\n",
        "                distance += max_penalty ** 2\n",
        "        distances.append(np.sqrt(distance))\n",
        "\n",
        "    # Normalisasi jarak\n",
        "    scaler = MinMaxScaler()\n",
        "    norm_dists = scaler.fit_transform(np.array(distances).reshape(-1, 1)).flatten()\n",
        "    merged_df[f'norm_euclidean@{top_n}'] = norm_dists\n",
        "\n",
        "    # Ambil kolom evaluasi\n",
        "    result_df = merged_df[[\"id_proposal\",\n",
        "                           f'recall_of_existence@{top_n}',\n",
        "                           f'recall_pos1_ordered@{top_n}',\n",
        "                           f'recall_pos2_ordered@{top_n}',\n",
        "                           f'recall_pos3_ordered@{top_n}',\n",
        "                           f'norm_euclidean@{top_n}']].copy()\n",
        "\n",
        "    return result_df\n",
        "\n",
        "\n",
        "eval_per_proposal_directed_3 = evaluate_per_proposal_directed(df_overlap_true, true_label_df, top_n=3)\n",
        "eval_per_proposal_directed_5 = evaluate_per_proposal_directed(df_overlap_true, true_label_df, top_n=5)\n",
        "eval_per_proposal_directed_7 = evaluate_per_proposal_directed(df_overlap_true, true_label_df, top_n=7)\n",
        "eval_per_proposal_directed_10 = evaluate_per_proposal_directed(df_overlap_true, true_label_df, top_n=10)\n",
        "\n",
        "# eval_per_proposal_directed_3.to_csv(\"/content/drive/MyDrive/Skripsi4/topik/directed/30/hasil_eval_3_directed.csv\", index=False)\n",
        "# eval_per_proposal_directed_5.to_csv(\"/content/drive/MyDrive/Skripsi4/topik/directed/30/hasil_eval_5_directed.csv\", index=False)\n",
        "# eval_per_proposal_directed_7.to_csv(\"/content/drive/MyDrive/Skripsi4/topik/directed/30/hasil_eval_7_directed.csv\", index=False)\n",
        "# eval_per_proposal_directed_10.to_csv(\"/content/drive/MyDrive/Skripsi4/topik/directed/30/hasil_eval_10_directed.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vzt-RHMSsRw"
      },
      "source": [
        "# Cosine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "_t6VT0-ROwjb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f328e87-58e2-419c-9ca9-3df802d11c2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.02116158 0.19097795 0.1399585  ... 0.02030642 0.02484113 0.05370035]\n",
            " [0.02116158 0.19097795 0.1399585  ... 0.02030642 0.02484113 0.05370035]\n",
            " [0.01516028 0.02125837 0.02516963 ... 0.06561315 0.05264645 0.05729351]\n",
            " ...\n",
            " [0.14608201 0.02545677 0.09075104 ... 0.03309006 0.03286479 0.05853668]\n",
            " [0.20352237 0.02324828 0.07729209 ... 0.03353393 0.0428044  0.05218332]\n",
            " [0.11509452 0.01096047 0.0180661  ... 0.02063077 0.02465363 0.02465597]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Konversi kolom topic_vector menjadi 2D array\n",
        "expert_vectors = np.vstack(expert_df[\"topic_vector\"].values)\n",
        "proposal_vectors = np.vstack(proposal_df[\"topic_vector\"].values)\n",
        "\n",
        "# Hitung similarity\n",
        "similarity_matrix = cosine_similarity(expert_vectors, proposal_vectors)\n",
        "\n",
        "print(similarity_matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "qd3oic5wS5KM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a060eae-3094-4709-e24a-2b8a9027d05a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       id_proposal mahasiswa id_penelitian id_dosen  selisih_tahun  \\\n",
            "3               P1        S1            R3       D5              5   \n",
            "4               P1        S1            R3       D1              5   \n",
            "5               P1        S1            R4       D5              4   \n",
            "6               P1        S1            R4       D8              4   \n",
            "7               P1        S1            R5       D5              3   \n",
            "...            ...       ...           ...      ...            ...   \n",
            "107846        P142      S142          R425       D2              2   \n",
            "107847        P142      S142          R426       D6              2   \n",
            "107849        P142      S142          R428      D14              2   \n",
            "107850        P142      S142          R429      D14              2   \n",
            "107851        P142      S142          R429       D6              2   \n",
            "\n",
            "                  dosen  author_position  similarity_score  \n",
            "3            Abdul Aziz                1          0.017203  \n",
            "4       Bambang Harjito                2          0.017203  \n",
            "5            Abdul Aziz                1          0.261662  \n",
            "6          Esti Suryani                2          0.261662  \n",
            "7            Abdul Aziz                1          0.011078  \n",
            "...                 ...              ...               ...  \n",
            "107846          Wiranto                1          0.113626  \n",
            "107847    Ristu Saptono                1          0.065882  \n",
            "107849  Haryono Setiadi                1          0.023313  \n",
            "107850  Haryono Setiadi                1          0.041413  \n",
            "107851    Ristu Saptono                2          0.041413  \n",
            "\n",
            "[53068 rows x 8 columns]\n"
          ]
        }
      ],
      "source": [
        "similarity_cosine_df = []\n",
        "\n",
        "for i, (_, mahasiswa) in enumerate(proposal_df.iterrows()):\n",
        "    for j, (_, dosen) in enumerate(expert_df.iterrows()):\n",
        "        similarity_cosine_df.append({\n",
        "            \"id_proposal\": mahasiswa[\"proposal_id\"],\n",
        "            \"mahasiswa\": mahasiswa[\"student_id\"],\n",
        "            \"id_dosen\": dosen[\"expert_id\"],\n",
        "            \"id_penelitian\": dosen[\"research_id\"],\n",
        "            \"tahun_proposal\": mahasiswa[\"tahun\"],\n",
        "            \"tahun_penelitian\": dosen[\"pub_year\"],\n",
        "            \"selisih_tahun\": mahasiswa[\"tahun\"] - dosen[\"pub_year\"],\n",
        "            \"dosen\": dosen[\"name\"],\n",
        "           \"author_position\": dosen[\"author_position\"],\n",
        "            \"similarity_score\" : similarity_matrix[j, i]\n",
        "\n",
        "\n",
        "        })\n",
        "\n",
        "similarity_cosine_df = pd.DataFrame(similarity_cosine_df)\n",
        "\n",
        "# Filter sesuai kondisi\n",
        "similarity_cosine_df = similarity_cosine_df[\n",
        "    (similarity_cosine_df[\"tahun_proposal\"] > similarity_cosine_df[\"tahun_penelitian\"]) &\n",
        "    (similarity_cosine_df[\"selisih_tahun\"] <= 5)\n",
        "].copy()\n",
        "\n",
        "\n",
        "# Tampilkan hasil\n",
        "print(similarity_cosine_df[[\"id_proposal\",\"mahasiswa\",\"id_penelitian\", \"id_dosen\",\"selisih_tahun\", \"dosen\",\"author_position\", \"similarity_score\" ,]])\n",
        "# similarity_cosine_df.to_csv(\"/content/drive/MyDrive/Skripsi4/topik/cosine/14/hasil_cosine_topik.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGX5xEtNUpcw"
      },
      "source": [
        "# Pemeringkatan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "7shoY9CES9Tz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6430724-1a32-478a-9576-56361e085daf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      id_proposal mahasiswa  tahun_proposal id_penelitian  tahun_penelitian  \\\n",
            "137            P1        S1            2021           R83              2016   \n",
            "138            P1        S1            2021           R83              2016   \n",
            "163            P1        S1            2021           R97              2018   \n",
            "164            P1        S1            2021           R97              2018   \n",
            "84             P1        S1            2021           R48              2018   \n",
            "...           ...       ...             ...           ...               ...   \n",
            "74550         P99       S99            2024           R42              2023   \n",
            "74815         P99       S99            2024          R202              2023   \n",
            "74816         P99       S99            2024          R202              2023   \n",
            "74685         P99       S99            2024          R116              2021   \n",
            "74686         P99       S99            2024          R116              2021   \n",
            "\n",
            "      id_dosen              dosen  selisih_tahun  author_position  \\\n",
            "137         D8       Esti Suryani              5                1   \n",
            "138         D5         Abdul Aziz              5                2   \n",
            "163         D2            Wiranto              3                1   \n",
            "164         D8       Esti Suryani              3                2   \n",
            "84          D8       Esti Suryani              3                2   \n",
            "...        ...                ...            ...              ...   \n",
            "74550      D11            Winarno              1                2   \n",
            "74815      D11            Winarno              1                1   \n",
            "74816      D13  Hasan Dwi Cahyono              1                2   \n",
            "74685      D12            Wiharto              3                1   \n",
            "74686       D8       Esti Suryani              3                2   \n",
            "\n",
            "       similarity_score  rank  \n",
            "137            0.765764     1  \n",
            "138            0.765764     2  \n",
            "163            0.754174     3  \n",
            "164            0.754174     4  \n",
            "84             0.657577     5  \n",
            "...                 ...   ...  \n",
            "74550          0.563516    13  \n",
            "74815          0.558069    14  \n",
            "74816          0.558069    15  \n",
            "74685          0.416476    16  \n",
            "74686          0.416476    17  \n",
            "\n",
            "[2414 rows x 11 columns]\n"
          ]
        }
      ],
      "source": [
        "# Ambil baris dengan similarity tertinggi untuk kombinasi unik id_proposal dan id_dosen\n",
        "idx = similarity_cosine_df.groupby([\"id_proposal\", \"id_dosen\"])[\"similarity_score\"].idxmax()\n",
        "similarity_cosine = similarity_cosine_df.loc[idx]\n",
        "\n",
        "# Ranking ulang berdasarkan proposal\n",
        "similarity_cosine_df[\"rank\"] = similarity_cosine_df.groupby(\"id_proposal\")[\"similarity_score\"] \\\n",
        "                                     .rank(method=\"first\", ascending=False).astype(int)\n",
        "\n",
        "# Urutkan\n",
        "similarity_cosine_df = similarity_cosine_df.sort_values([\"id_proposal\", \"rank\"])\n",
        "similarity_cosine_df = similarity_cosine_df[similarity_cosine_df[\"rank\"] <= 17]\n",
        "\n",
        "\n",
        "# Tampilkan\n",
        "print(similarity_cosine_df[[\"id_proposal\", \"mahasiswa\",\"tahun_proposal\",\"id_penelitian\", \"tahun_penelitian\", \"id_dosen\", \"dosen\",\"selisih_tahun\", \"author_position\",\"similarity_score\",\"rank\"]])\n",
        "# similarity_cosine_df.to_csv(\"/content/drive/MyDrive/Skripsi4/topik/14/cosine/similarity_cosine_kata_baru_setelah filter.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "4EFjJdmrVV34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f788c8d-3bbc-4b63-ed48-329115d70388"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     id_proposal mahasiswa id_dosen              dosen  author_position  \\\n",
            "0             P1        S1       D8       Esti Suryani                1   \n",
            "142           P1        S1       D5         Abdul Aziz                2   \n",
            "143           P1        S1       D2            Wiranto                1   \n",
            "144           P1        S1       D1    Bambang Harjito                1   \n",
            "145           P1        S1       D3        Umi Salamah                1   \n",
            "...          ...       ...      ...                ...              ...   \n",
            "2009         P99       S99      D11            Winarno                2   \n",
            "2010         P99       S99      D11            Winarno                1   \n",
            "2011         P99       S99      D13  Hasan Dwi Cahyono                2   \n",
            "2012         P99       S99      D12            Wiharto                1   \n",
            "2013         P99       S99       D8       Esti Suryani                2   \n",
            "\n",
            "      similarity_score  rank  beban  \n",
            "0             0.765764     1      1  \n",
            "142           0.765764     2      5  \n",
            "143           0.754174     3     13  \n",
            "144           0.657577     4      6  \n",
            "145           0.579853     5      6  \n",
            "...                ...   ...    ...  \n",
            "2009          0.563516    13     14  \n",
            "2010          0.558069    14     14  \n",
            "2011          0.558069    15      2  \n",
            "2012          0.416476    16     14  \n",
            "2013          0.416476    17     15  \n",
            "\n",
            "[2014 rows x 8 columns]\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# 1. Inisialisasi count untuk rank 1\n",
        "rank1_count = defaultdict(int)\n",
        "final_assignments = []\n",
        "\n",
        "# 2. Tetapkan rank 1 dengan batas 15 kali per dosen\n",
        "for pid in similarity_cosine_df[\"id_proposal\"].unique():\n",
        "    candidates = similarity_cosine_df[similarity_cosine_df[\"id_proposal\"] == pid]\n",
        "    candidates = candidates.sort_values(by=\"similarity_score\", ascending=False)\n",
        "\n",
        "    assigned_rank1 = False\n",
        "    for _, row in candidates.iterrows():\n",
        "        dosen_id = row[\"id_dosen\"]\n",
        "        if rank1_count[dosen_id] < 15:\n",
        "            rank1_count[dosen_id] += 1\n",
        "            row_data = row.to_dict()\n",
        "            row_data[\"rank\"] = 1\n",
        "            row_data[\"beban\"] = rank1_count[dosen_id]\n",
        "            final_assignments.append(row_data)\n",
        "            assigned_rank1 = True\n",
        "            break\n",
        "\n",
        "    if not assigned_rank1:\n",
        "        row = candidates.iloc[0].to_dict()\n",
        "        dosen_id = row[\"id_dosen\"]\n",
        "        rank1_count[dosen_id] += 1\n",
        "        row[\"rank\"] = 1\n",
        "        row[\"beban\"] = rank1_count[dosen_id]\n",
        "        final_assignments.append(row)\n",
        "\n",
        "# 3. Buat dataframe dari rank 1\n",
        "rank1_df = pd.DataFrame(final_assignments)\n",
        "\n",
        "# 4. Tambahkan rank 2–17 berdasarkan similarity, excl. dosen yang sudah dipakai di rank 1 untuk proposal yang sama\n",
        "other_ranks = []\n",
        "\n",
        "for pid in similarity_cosine_df[\"id_proposal\"].unique():\n",
        "    # Dapatkan dosen yang sudah dipakai sebagai rank 1\n",
        "    used_dosen = rank1_df[rank1_df[\"id_proposal\"] == pid][\"id_dosen\"].tolist()\n",
        "\n",
        "    # Ambil kandidat lain untuk proposal ini\n",
        "    candidates = similarity_cosine_df[(similarity_cosine_df[\"id_proposal\"] == pid) & (~similarity_cosine_df[\"id_dosen\"].isin(used_dosen))]\n",
        "    candidates = candidates.sort_values(by=\"similarity_score\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "    for idx, (_, row) in enumerate(candidates.iterrows(), start=2):\n",
        "        if idx > 17:\n",
        "            break\n",
        "        row_data = row.to_dict()\n",
        "        row_data[\"rank\"] = idx\n",
        "        row_data[\"beban\"] = rank1_count[row_data[\"id_dosen\"]]  # Beban hanya dihitung dari rank 1\n",
        "        other_ranks.append(row_data)\n",
        "\n",
        "# 5. Gabungkan rank1 dan other ranks\n",
        "rank_all_df = pd.concat([rank1_df, pd.DataFrame(other_ranks)], ignore_index=True)\n",
        "rank_all_df = rank_all_df.sort_values(by=[\"id_proposal\", \"rank\"])\n",
        "\n",
        "# 6. Tampilkan hasil\n",
        "print(rank_all_df[[\"id_proposal\", \"mahasiswa\", \"id_dosen\", \"dosen\", \"author_position\",\"similarity_score\", \"rank\", \"beban\"]])\n",
        "rank_all_df.to_csv(\"/content/drive/MyDrive/Skripsi4/topik/cosine/30/beban_cosine_topik.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Urutkan berdasarkan id_proposal, similarity_score_akhir (descending), dan author_position (ascending)\n",
        "similarity_cosine_df_baru = rank_all_df.sort_values(\n",
        "    by=[\"id_proposal\", \"similarity_score\", \"author_position\"],\n",
        "    ascending=[True, False, True]\n",
        ")\n",
        "\n",
        "# Tambahkan kolom rank untuk setiap id_proposal\n",
        "similarity_cosine_df_baru[\"rank\"] = similarity_cosine_df_baru.groupby(\"id_proposal\").cumcount() + 1\n",
        "\n",
        "print(similarity_cosine_df_baru[[\"id_proposal\", \"mahasiswa\",\"tahun_proposal\",\"id_penelitian\", \"tahun_penelitian\", \"id_dosen\", \"dosen\",\"selisih_tahun\", \"author_position\",\"similarity_score\",\"rank\",\"beban\"]])\n",
        "similarity_cosine_df_baru.to_csv(\"/content/drive/MyDrive/Skripsi4/topik/cosine/30/beban_cosine_topik_urut_author.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceShjre0jgmF",
        "outputId": "8e5cfc52-4687-42e0-de6c-99e4d9fe1de7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     id_proposal mahasiswa  tahun_proposal id_penelitian  tahun_penelitian  \\\n",
            "0             P1        S1            2021           R83              2016   \n",
            "142           P1        S1            2021           R83              2016   \n",
            "143           P1        S1            2021           R97              2018   \n",
            "144           P1        S1            2021           R48              2018   \n",
            "145           P1        S1            2021          R266              2018   \n",
            "...          ...       ...             ...           ...               ...   \n",
            "2009         P99       S99            2024           R42              2023   \n",
            "2010         P99       S99            2024          R202              2023   \n",
            "2011         P99       S99            2024          R202              2023   \n",
            "2012         P99       S99            2024          R116              2021   \n",
            "2013         P99       S99            2024          R116              2021   \n",
            "\n",
            "     id_dosen              dosen  selisih_tahun  author_position  \\\n",
            "0          D8       Esti Suryani              5                1   \n",
            "142        D5         Abdul Aziz              5                2   \n",
            "143        D2            Wiranto              3                1   \n",
            "144        D1    Bambang Harjito              3                1   \n",
            "145        D3        Umi Salamah              3                1   \n",
            "...       ...                ...            ...              ...   \n",
            "2009      D11            Winarno              1                2   \n",
            "2010      D11            Winarno              1                1   \n",
            "2011      D13  Hasan Dwi Cahyono              1                2   \n",
            "2012      D12            Wiharto              3                1   \n",
            "2013       D8       Esti Suryani              3                2   \n",
            "\n",
            "      similarity_score  rank  beban  \n",
            "0             0.765764     1      1  \n",
            "142           0.765764     2      5  \n",
            "143           0.754174     3     13  \n",
            "144           0.657577     4      6  \n",
            "145           0.579853     5      6  \n",
            "...                ...   ...    ...  \n",
            "2009          0.563516    13     14  \n",
            "2010          0.558069    14     14  \n",
            "2011          0.558069    15      2  \n",
            "2012          0.416476    16     14  \n",
            "2013          0.416476    17     15  \n",
            "\n",
            "[2014 rows x 12 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDpaTPt7VlSU"
      },
      "source": [
        "# Evaluasi Cosine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "RyEdj1o1Szkf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c75a41df-5b9a-4465-9c5b-da9a7b927e86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Top-N  Mean_Recall_Existence  Recall_Pos_1_Ordered  Recall_Pos_2_Ordered  \\\n",
            "0      3               0.244131              0.309859              0.021127   \n",
            "1      5               0.380282              0.309859              0.021127   \n",
            "2      7               0.488263              0.309859              0.021127   \n",
            "3     10               0.551643              0.309859              0.021127   \n",
            "\n",
            "   Recall_Pos_3_Ordered  Avg_Normalized_Euclidean  \n",
            "0              0.070423                  0.710102  \n",
            "1              0.070423                  0.686285  \n",
            "2              0.070423                  0.647736  \n",
            "3              0.070423                  0.616253  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "def evaluate_ordered_recommendation_cosine(rank_all_df, true_label_df, top_ns=[3, 5, 7, 10]):\n",
        "    summary = []\n",
        "\n",
        "    for TOP_N in top_ns:\n",
        "        # Filter Top-N dan urutkan\n",
        "        top_n_df = rank_all_df[rank_all_df[\"rank\"] <= TOP_N]\n",
        "        rec_df = top_n_df.sort_values(by=[\"id_proposal\", \"rank\", \"similarity_score\"], ascending=[True, True, False])\n",
        "        rec_pivot = rec_df.pivot(index=\"id_proposal\", columns=\"rank\", values=\"dosen\").reset_index()\n",
        "        rec_pivot.columns.name = None\n",
        "        rec_pivot.columns = [\"id_proposal\"] + [f\"rec_{i}\" for i in range(1, len(rec_pivot.columns))]\n",
        "\n",
        "        # Gabungkan dengan ground truth\n",
        "        merged_df = pd.merge(\n",
        "            rec_pivot,\n",
        "            true_label_df.rename(columns={\"proposal_id\": \"id_proposal\"}),\n",
        "            on=\"id_proposal\",\n",
        "            how=\"left\"\n",
        "        )\n",
        "\n",
        "        # Recall keberadaan (tidak memperhatikan urutan)\n",
        "        def recall_of_existence(row):\n",
        "            true_set = {row.get(\"author1\"), row.get(\"author2\"), row.get(\"author3\")}\n",
        "            pred_set = {row.get(f\"rec_{i}\") for i in range(1, TOP_N + 1) if row.get(f\"rec_{i}\")}\n",
        "            return len(true_set.intersection(pred_set)) / 3\n",
        "\n",
        "        merged_df[f'recall_of_existence@{TOP_N}'] = merged_df.apply(recall_of_existence, axis=1)\n",
        "\n",
        "        # Recall per posisi dengan urutan diperhatikan (rec_i harus sama dengan author_i)\n",
        "        recall_pos = {1: [], 2: [], 3: []}\n",
        "        for _, row in merged_df.iterrows():\n",
        "            for pos in [1, 2, 3]:\n",
        "                examiner = row.get(f'author{pos}')\n",
        "                rec = row.get(f'rec_{pos}') if pos <= TOP_N else None\n",
        "                hit = int(pd.notna(examiner) and pd.notna(rec) and examiner == rec)\n",
        "                recall_pos[pos].append(hit)\n",
        "\n",
        "        # Tambahkan recall ke DataFrame\n",
        "        for pos in [1, 2, 3]:\n",
        "            merged_df[f'recall_pos{pos}_ordered@{TOP_N}'] = recall_pos[pos]\n",
        "\n",
        "        recall_pos_mean = {pos: np.mean(recall_pos[pos]) for pos in [1, 2, 3]}\n",
        "\n",
        "        # Euclidean distance antar posisi (penalti posisi meleset)\n",
        "        distances = []\n",
        "        for _, row in merged_df.iterrows():\n",
        "            true_authors = [row.get(f'author{i}') for i in [1, 2, 3]]\n",
        "            pred_authors = [row.get(f'rec_{i}', None) for i in range(1, TOP_N + 1)]\n",
        "            distance = 0\n",
        "            max_penalty = TOP_N\n",
        "            for i, true_author in enumerate(true_authors):\n",
        "                if pd.isna(true_author) or true_author == '':\n",
        "                    continue\n",
        "                try:\n",
        "                    pred_pos = pred_authors.index(true_author)\n",
        "                    pos_diff = pred_pos - i\n",
        "                    distance += pos_diff ** 2\n",
        "                except ValueError:\n",
        "                    distance += max_penalty ** 2\n",
        "            distances.append(np.sqrt(distance))\n",
        "\n",
        "        scaler = MinMaxScaler()\n",
        "        norm_dists = scaler.fit_transform(np.array(distances).reshape(-1, 1)).flatten()\n",
        "        merged_df[f'norm_euclidean@{TOP_N}'] = norm_dists\n",
        "\n",
        "        # Ringkasan metrik\n",
        "        summary.append({\n",
        "            'Top-N': TOP_N,\n",
        "            'Mean_Recall_Existence': merged_df[f'recall_of_existence@{TOP_N}'].mean(),\n",
        "            'Recall_Pos_1_Ordered': recall_pos_mean[1],\n",
        "            'Recall_Pos_2_Ordered': recall_pos_mean[2],\n",
        "            'Recall_Pos_3_Ordered': recall_pos_mean[3],\n",
        "            'Avg_Normalized_Euclidean': np.mean(norm_dists)\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(summary)\n",
        "\n",
        "result_df = evaluate_ordered_recommendation_cosine(similarity_cosine_df, true_label_df)\n",
        "print(result_df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiyEGakTZn8P"
      },
      "source": [
        "## per proposal baru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "vZoVKOZGDJFx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def evaluate_per_proposal_cosine(rank_all_df, true_label_df, top_n=3):\n",
        "    # Filter dan urutkan\n",
        "    top_n_df = rank_all_df[rank_all_df[\"rank\"] <= top_n]\n",
        "    rec_df = top_n_df.sort_values(by=[\"id_proposal\", \"rank\", \"similarity_score\"], ascending=[True, True, False])\n",
        "    rec_pivot = rec_df.pivot(index=\"id_proposal\", columns=\"rank\", values=\"dosen\").reset_index()\n",
        "    rec_pivot.columns.name = None\n",
        "    rec_pivot.columns = [\"id_proposal\"] + [f\"rec_{i}\" for i in range(1, len(rec_pivot.columns))]\n",
        "\n",
        "    # Gabung dengan label kebenaran\n",
        "    merged_df = pd.merge(\n",
        "        rec_pivot,\n",
        "        true_label_df.rename(columns={\"proposal_id\": \"id_proposal\"}),\n",
        "        on=\"id_proposal\",\n",
        "        how=\"left\"\n",
        "    )\n",
        "\n",
        "    # Recall of existence (abaikan urutan)\n",
        "    def recall_of_existence(row):\n",
        "        true_set = {row.get(\"author1\"), row.get(\"author2\"), row.get(\"author3\")}\n",
        "        pred_set = {row.get(f\"rec_{i}\") for i in range(1, top_n + 1) if row.get(f\"rec_{i}\")}\n",
        "        return len(true_set.intersection(pred_set)) / 3\n",
        "\n",
        "    merged_df[f'recall_of_existence@{top_n}'] = merged_df.apply(recall_of_existence, axis=1)\n",
        "\n",
        "    # Recall berdasarkan posisi (urutan harus sama)\n",
        "    for pos in [1, 2, 3]:\n",
        "        merged_df[f'recall_pos{pos}_ordered@{top_n}'] = merged_df.apply(\n",
        "            lambda row: int(\n",
        "                pd.notna(row.get(f'author{pos}')) and\n",
        "                pd.notna(row.get(f'rec_{pos}')) and\n",
        "                row.get(f'author{pos}') == row.get(f'rec_{pos}')\n",
        "            ) if pos <= top_n else 0,\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "    # Euclidean distance penalti posisi\n",
        "    distances = []\n",
        "    for _, row in merged_df.iterrows():\n",
        "        true_authors = [row.get(f'author{i}') for i in [1, 2, 3]]\n",
        "        pred_authors = [row.get(f'rec_{i}', None) for i in range(1, top_n + 1)]\n",
        "        distance = 0\n",
        "        max_penalty = top_n\n",
        "        for i, true_author in enumerate(true_authors):\n",
        "            if pd.isna(true_author) or true_author == '':\n",
        "                continue\n",
        "            try:\n",
        "                pred_pos = pred_authors.index(true_author)\n",
        "                pos_diff = pred_pos - i\n",
        "                distance += pos_diff ** 2\n",
        "            except ValueError:\n",
        "                distance += max_penalty ** 2\n",
        "        distances.append(np.sqrt(distance))\n",
        "\n",
        "    # Normalisasi jarak\n",
        "    scaler = MinMaxScaler()\n",
        "    norm_dists = scaler.fit_transform(np.array(distances).reshape(-1, 1)).flatten()\n",
        "    merged_df[f'norm_euclidean@{top_n}'] = norm_dists\n",
        "\n",
        "    # Ambil kolom evaluasi\n",
        "    result_df = merged_df[[\"id_proposal\",\n",
        "                           f'recall_of_existence@{top_n}',\n",
        "                           f'recall_pos1_ordered@{top_n}',\n",
        "                           f'recall_pos2_ordered@{top_n}',\n",
        "                           f'recall_pos3_ordered@{top_n}',\n",
        "                           f'norm_euclidean@{top_n}']].copy()\n",
        "\n",
        "    return result_df\n",
        "\n",
        "\n",
        "eval_per_proposal_cosine_3 = evaluate_per_proposal_cosine(similarity_cosine_df, true_label_df, top_n=3)\n",
        "eval_per_proposal_cosine_5 = evaluate_per_proposal_cosine(similarity_cosine_df, true_label_df, top_n=5)\n",
        "eval_per_proposal_cosine_7 = evaluate_per_proposal_cosine(similarity_cosine_df, true_label_df, top_n=7)\n",
        "eval_per_proposal_cosine_10 = evaluate_per_proposal_cosine(similarity_cosine_df, true_label_df, top_n=10)\n",
        "\n",
        "# eval_per_proposal_cosine_3.to_csv(\"/content/drive/MyDrive/Skripsi4/topik/cosine/30/hasil_eval_3_cosine_topik.csv\", index=False)\n",
        "# eval_per_proposal_cosine_5.to_csv(\"/content/drive/MyDrive/Skripsi4/topik/cosine/30/hasil_eval_5_cosine_topik.csv\", index=False)\n",
        "# eval_per_proposal_cosine_7.to_csv(\"/content/drive/MyDrive/Skripsi4/topik/cosine/30/hasil_eval_7_cosine_topik.csv\", index=False)\n",
        "# eval_per_proposal_cosine_10.to_csv(\"/content/drive/MyDrive/Skripsi4/topik/cosine/30/hasil_eval_10_cosine_topik.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "9pAGdpruELTI",
        "O5FkdQdcHvI2",
        "rXJRYVfCIx5Z"
      ],
      "authorship_tag": "ABX9TyNzUe9HfLZsyj4q+r4qwTjd",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}