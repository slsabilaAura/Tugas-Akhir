{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/slsabilaAura/Tugas-Akhir/blob/main/Model_TFIDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpcD1p73jQRw",
        "outputId": "adea53d7-e99f-4322-9368-f35f059f558a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ],
      "source": [
        "%pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: import file form drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9t0dbzGjWSI",
        "outputId": "d2364740-5e70-4441-a7f1-17f188e13b35"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "proposal_df = pd.read_csv('/content/drive/MyDrive/Skripsi3/Dataset/processed_proposalC.csv')\n",
        "expert_df = pd.read_csv('/content/drive/MyDrive/Skripsi3/Dataset/processed_expertC.csv')\n"
      ],
      "metadata": {
        "id": "kSy3xlzojYty"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gensim\n",
        "from gensim import corpora\n",
        "from gensim.corpora import Dictionary\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from gensim import corpora, models\n",
        "from gensim.matutils import corpus2dense\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models import TfidfModel\n",
        "from gensim.matutils import corpus2dense\n",
        "from gensim.matutils import sparse2full\n",
        "import pandas as pd\n",
        "import ast"
      ],
      "metadata": {
        "id": "U8euBGprjZo4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Corpus dan Dictionary"
      ],
      "metadata": {
        "id": "dh5qIA_vTAR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_list(text):\n",
        "    try:\n",
        "        return ast.literal_eval(text) if isinstance(text, str) else text\n",
        "    except:\n",
        "        return []\n",
        "\n",
        "\n",
        "proposal_df[\"processed\"] = proposal_df[\"stemmed\"].apply(convert_to_list)\n",
        "expert_df[\"processed\"] = expert_df[\"stemmed\"].apply(convert_to_list)\n",
        "\n",
        "proposal_df[\"processed\"] = proposal_df[\"processed\"].apply(lambda x: x[:30])\n",
        "expert_df[\"processed\"] = expert_df[\"processed\"].apply(lambda x: x[:30])\n",
        "\n",
        "# Gabungkan semua dokumen untuk membuat satu kamus bersama\n",
        "documents_all = proposal_df[\"processed\"].tolist() + expert_df[\"processed\"].tolist()\n",
        "dictionary_all = Dictionary(documents_all)\n",
        "\n",
        "\n",
        "dictionary_all.filter_extremes(no_below=5, no_above=0.5)\n",
        "\n",
        "# Buat corpus (Bag of Words)\n",
        "corpus_combined = [dictionary_all.doc2bow(text) for text in documents_all]\n",
        "\n",
        "# Buat model TF-IDF\n",
        "tfidf_model = models.TfidfModel(corpus_combined)\n",
        "\n",
        "# Transformasikan corpus ke TF-IDF\n",
        "tfidf_corpus_combined = tfidf_model[corpus_combined]\n",
        "\n",
        "n_proposals = len(proposal_df)\n",
        "n_experts = len(expert_df)\n",
        "\n",
        "tfidf_proposal = tfidf_corpus_combined[:n_proposals]\n",
        "tfidf_expert = tfidf_corpus_combined[n_proposals:]\n",
        "\n",
        "# Buat matriks dense (dokumen x vocab_size)\n",
        "proposal_dense = corpus2dense(tfidf_proposal, num_terms=len(dictionary_all)).T\n",
        "expert_dense = corpus2dense(tfidf_expert, num_terms=len(dictionary_all)).T"
      ],
      "metadata": {
        "id": "BeBu3-oGjcxZ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Ambil daftar dokumen dari tfidf_corpus_combined\n",
        "tfidf_data = []\n",
        "\n",
        "for doc_index, doc in enumerate(tfidf_corpus_combined):\n",
        "    for term_id, weight in doc:\n",
        "        tfidf_data.append({\n",
        "            \"doc_id\": doc_index,\n",
        "            \"term\": dictionary_all[term_id],\n",
        "            \"term_id\": term_id,\n",
        "            \"tfidf\": weight\n",
        "        })\n",
        "\n",
        "# Ubah ke DataFrame\n",
        "tfidf_df = pd.DataFrame(tfidf_data)\n",
        "\n",
        "doc1_tfidf = tfidf_df[tfidf_df[\"doc_id\"] == 1]\n",
        "print(doc1_tfidf.sort_values(by=\"tfidf\", ascending=False))  # Urut dari tertinggi\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51A2tN9-xKQr",
        "outputId": "132fe799-e74b-4d06-87f4-e46980138aa5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    doc_id      term  term_id     tfidf\n",
            "14       1     cepat       14  0.431814\n",
            "24       1     pikir       24  0.418914\n",
            "25       1      pola       25  0.328399\n",
            "23       1      maju       23  0.324193\n",
            "21       1      kota       21  0.223962\n",
            "29       1  sekarang       29  0.209457\n",
            "28       1    segala       28  0.209457\n",
            "16       1      desa       16  0.198623\n",
            "26       1    sangat       26  0.194969\n",
            "17       1       era       17  0.168742\n",
            "31       1     tidak       31  0.155252\n",
            "22       1      luas       22  0.152889\n",
            "19       1     jalan       19  0.146720\n",
            "27       1     sebar       27  0.142611\n",
            "30       1    sosial       30  0.140075\n",
            "18       1     hanya       18  0.134318\n",
            "13       1    bidang       13  0.133254\n",
            "15       1    dampak       15  0.133254\n",
            "12       1      baik       12  0.108979\n",
            "20       1   kembang       20  0.082849\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Directed M->D"
      ],
      "metadata": {
        "id": "A1DZqu5vm-1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# tfidf_df_proposal_contoh = pd.DataFrame(proposal_dense, columns=[f\"term_{i}\" for i in range(proposal_dense.shape[1])])\n",
        "# print(tfidf_df_proposal_contoh.head())\n",
        "terms = [dictionary_all[i] for i in range(len(dictionary_all))]\n",
        "tfidf_df_proposal_contoh = pd.DataFrame(proposal_dense, columns=terms)\n",
        "# print(tfidf_df_proposal_contoh)\n"
      ],
      "metadata": {
        "id": "-LkAUeKl0b7Y",
        "collapsed": true
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Konversi ke DataFrame\n",
        "proposal_df_tfidf = pd.DataFrame(proposal_dense)\n",
        "expert_df_tfidf = pd.DataFrame(expert_dense)\n",
        "\n",
        "# Simpan ke CSV\n",
        "# proposal_df_tfidf.to_csv('/content/drive/MyDrive/Skripsi4/kata/hasil_TFIDF_proposal_lama.csv', index=False)\n",
        "# expert_df_tfidf.to_csv('/content/drive/MyDrive/Skripsi4/kata/hasil_TFIDF_expert_lama.csv', index=False)"
      ],
      "metadata": {
        "id": "RSGvrFIOcS1Q"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "proposal_df[\"tahun\"] = proposal_df[\"proposal_year\"].astype(int)\n",
        "expert_df[\"pub_year\"] = expert_df[\"research_pub_year\"].astype(int)\n",
        "\n",
        "\n",
        "def similarity_m_to_d(proposal_vector, expert_vector):\n",
        "    numerator = np.dot(proposal_vector, expert_vector)\n",
        "    denominator = (np.linalg.norm(proposal_vector) + 1e-10)\n",
        "    return numerator / (denominator)\n",
        "\n",
        "\n",
        "def similarity_d_to_m(expert_vector, proposal_vector):\n",
        "    numerator = np.dot(expert_vector, proposal_vector)\n",
        "    denominator = (np.linalg.norm(expert_vector) + 1e-10)\n",
        "    return numerator / (denominator)\n",
        "\n",
        " # denominator = np.linalg.norm(expert_vector)\n",
        "\n",
        "def time_decay(year_prop, year_ex, t=1, gamma=0.1):\n",
        "    decay = 1 - ((year_prop - year_ex) / t) * gamma\n",
        "    return max(decay, 0.0)  # tidak boleh negatif\n",
        "\n",
        "# mapping Dosen dengan ID Dosen\n",
        "\n",
        "dosen_id_map = pd.read_csv(\"/content/drive/MyDrive/Skripsi3/Dataset/mapping.csv\")  # pastikan kolom: expert_id, expert_name\n",
        "dosen_id_map[\"expert_name\"] = dosen_id_map[\"expert_name\"].str.strip().str.lower()\n",
        "\n",
        "\n",
        "def attach_dosen_id(df, dosen_id_map):\n",
        "\n",
        "    df = df.copy()\n",
        "    df[\"dosen\"] = df[\"dosen\"].str.strip().str.lower()  # normalisasi agar cocok\n",
        "    dosen_id_map = dosen_id_map.copy()\n",
        "    dosen_id_map[\"dosen\"] = dosen_id_map[\"dosen\"].str.strip().str.lower()\n",
        "\n",
        "    merged_df = df.merge(dosen_id_map, on=\"dosen\", how=\"left\")\n",
        "    return merged_df\n",
        "\n",
        "\n",
        "\n",
        "def explode_authors_with_weights(df, dosen_id_map):\n",
        "    rows = []\n",
        "\n",
        "    # Normalisasi nama dosen agar cocok\n",
        "    dosen_id_map = dosen_id_map.copy()\n",
        "    dosen_id_map[\"expert_name\"] = dosen_id_map[\"expert_name\"].str.strip().str.lower()\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        authors = row.get(\"authors\", [])\n",
        "        # Bersihkan nama kosong atau NaN\n",
        "        authors = [a for a in authors if isinstance(a, str) and a.strip() != \"\"]\n",
        "\n",
        "        num_authors = len(authors)\n",
        "        for idx, name in enumerate(authors):\n",
        "            name_clean = name.strip().lower()\n",
        "\n",
        "            if num_authors == 1:\n",
        "                weight = 1.0\n",
        "            else:\n",
        "                weight = 0.6 if idx == 0 else 0.4 / (num_authors - 1)\n",
        "\n",
        "            new_row = row.to_dict()\n",
        "            new_row[\"name\"] = name\n",
        "            new_row[\"author_position\"] = idx + 1\n",
        "            new_row[\"num_authors\"] = num_authors\n",
        "            new_row[\"author_weight\"] = round(weight, 4)\n",
        "\n",
        "            matched = dosen_id_map[dosen_id_map[\"expert_name\"] == name_clean]\n",
        "            new_row[\"expert_id\"] = matched[\"expert_id\"].values[0] if not matched.empty else None\n",
        "\n",
        "            rows.append(new_row)\n",
        "\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "# Gabungkan author_1 sampai author_6 jadi list\n",
        "author_cols = [\"author_1\", \"author_2\", \"author_3\", \"author_4\", \"author_5\", \"author_6\"]\n",
        "expert_df[\"authors\"] = expert_df[author_cols].values.tolist()\n",
        "\n",
        "# Hapus duplikat berdasarkan research_id\n",
        "expert_df = expert_df.drop_duplicates(subset=[\"research_id\"]).copy()\n",
        "\n",
        "# Jalankan explode\n",
        "expert_df = explode_authors_with_weights(expert_df, dosen_id_map)\n",
        "\n",
        "# Opsional: hanya simpan baris dengan expert_id valid\n",
        "expert_df = expert_df[expert_df[\"expert_id\"].notna()]\n",
        "\n",
        "\n",
        "\n",
        "# expert_df.to_csv(\"/content/drive/MyDrive/Skripsi4/dictionary/expert_df_id_dosen.csv\", index=False)"
      ],
      "metadata": {
        "id": "tDDkfvOAmfwj"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OD M->D"
      ],
      "metadata": {
        "id": "9H2x1IidnImf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_od_m_to_d(tfidf_proposal, tfidf_expert, proposal_df, expert_df):\n",
        "    records = []\n",
        "\n",
        "    for idx_prop, prop_row in proposal_df.iterrows():\n",
        "        prop_id = prop_row[\"proposal_id\"]\n",
        "        prop_vector = tfidf_proposal[idx_prop]\n",
        "        prop_year = prop_row[\"tahun\"]\n",
        "        mahasiswa = prop_row[\"student_id\"]\n",
        "\n",
        "        for idx_expert, exp_row in expert_df.iterrows():\n",
        "            exp_id_dosen = exp_row[\"expert_id\"]\n",
        "            author_position = exp_row[\"author_position\"]\n",
        "            author_weight = exp_row[\"author_weight\"]\n",
        "            pub_year = exp_row[\"pub_year\"]\n",
        "            penelitian_id = exp_row[\"research_id\"]\n",
        "            dosen = exp_row[\"name\"]\n",
        "            exp_vector = tfidf_expert[idx_expert]\n",
        "\n",
        "            sim_m2d = similarity_m_to_d(prop_vector, exp_vector)\n",
        "            od_score = sim_m2d * author_weight\n",
        "\n",
        "            records.append({\n",
        "                \"id_proposal\": prop_id,\n",
        "                \"mahasiswa\": mahasiswa,\n",
        "                \"penelitian_id\": penelitian_id,\n",
        "                \"id_dosen\": exp_id_dosen,\n",
        "                \"dosen\": dosen,\n",
        "                \"author_position\": author_position,\n",
        "                \"tahun_proposal\": prop_year,\n",
        "                \"tahun_penelitian\": pub_year,\n",
        "                \"author_weight\": author_weight,\n",
        "                \"OD(M→D)\": round(od_score, 4)\n",
        "            })\n",
        "\n",
        "    df_scores = pd.DataFrame(records)\n",
        "\n",
        "    # Ambil OD tertinggi untuk tiap pasangan proposal-dosen\n",
        "    df_scores['id_proposal'] = df_scores['id_proposal'].astype(str)\n",
        "    # df_scores = df_scores.loc[df_scores.groupby([\"id_proposal\", \"id_dosen\"])[\"OD(M→D)\"].idxmax()]\n",
        "    df_scores = df_scores[df_scores[\"OD(M→D)\"] > 0.02]\n",
        "    df_scores = df_scores.reset_index(drop=True)\n",
        "\n",
        "    # Urutkan\n",
        "    df_scores = df_scores.sort_values(by=[\"id_proposal\", \"OD(M→D)\"], ascending=[True, False])\n",
        "\n",
        "    return df_scores\n",
        "\n",
        "# Hitung ulang\n",
        "df_od = compute_od_m_to_d(\n",
        "    proposal_dense,\n",
        "    expert_dense,\n",
        "    proposal_df,\n",
        "    expert_df\n",
        ")\n",
        "df_od = df_od[df_od[\"OD(M→D)\"] > 0.02]\n",
        "\n",
        "print(df_od[[\"id_proposal\", \"mahasiswa\", \"id_dosen\", \"dosen\", \"penelitian_id\", \"author_position\", \"author_weight\",\"OD(M→D)\"]].head())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # Lihat hasil\n",
        "print(df_od[[\"id_proposal\",\"mahasiswa\", \"id_dosen\", \"dosen\", \"author_position\", \"penelitian_id\", \"tahun_proposal\",\"tahun_penelitian\", \"OD(M→D)\"]].head(5))\n",
        "# df_od.to_csv(\"/content/drive/MyDrive/Skripsi4/kata/directed/od_m2d_kata.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n25Qyv8WnCg_",
        "outputId": "21f05929-ae97-47a8-cbeb-cab9250bcab2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    id_proposal mahasiswa id_dosen            dosen penelitian_id  \\\n",
            "99           P1        S1       D1  Bambang Harjito          R456   \n",
            "72           P1        S1       D1  Bambang Harjito          R345   \n",
            "3            P1        S1       D1  Bambang Harjito           R32   \n",
            "100          P1        S1      D15    Heri Prasetyo          R456   \n",
            "40           P1        S1      D15    Heri Prasetyo          R186   \n",
            "\n",
            "     author_position  author_weight  OD(M→D)  \n",
            "99                 1            0.6   0.2402  \n",
            "72                 1            0.6   0.1714  \n",
            "3                  1            1.0   0.1683  \n",
            "100                2            0.4   0.1601  \n",
            "40                 1            1.0   0.1294  \n",
            "    id_proposal mahasiswa id_dosen            dosen  author_position  \\\n",
            "99           P1        S1       D1  Bambang Harjito                1   \n",
            "72           P1        S1       D1  Bambang Harjito                1   \n",
            "3            P1        S1       D1  Bambang Harjito                1   \n",
            "100          P1        S1      D15    Heri Prasetyo                2   \n",
            "40           P1        S1      D15    Heri Prasetyo                1   \n",
            "\n",
            "    penelitian_id  tahun_proposal  tahun_penelitian  OD(M→D)  \n",
            "99           R456            2021              2023   0.2402  \n",
            "72           R345            2021              2022   0.1714  \n",
            "3             R32            2021              2015   0.1683  \n",
            "100          R456            2021              2023   0.1601  \n",
            "40           R186            2021              2020   0.1294  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TOD M->D"
      ],
      "metadata": {
        "id": "qU6ML4QXosPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_tod_m2d(od_df, t=1, gamma=0.1, min_year_diff=0, max_year_diff=5):\n",
        "    od_df = od_df.copy()\n",
        "\n",
        "    # Hitung selisih tahun\n",
        "    od_df[\"selisih_tahun\"] = od_df[\"tahun_proposal\"] - od_df[\"tahun_penelitian\"]\n",
        "\n",
        "    # Filter: selisih tahun antara 3 dan 5 tahun\n",
        "    od_df = od_df[\n",
        "        (od_df[\"selisih_tahun\"] >= min_year_diff) &\n",
        "        (od_df[\"selisih_tahun\"] <= max_year_diff)\n",
        "    ].copy()\n",
        "\n",
        "    # Hitung time decay factor\n",
        "    od_df[\"time_decay_factor\"] = od_df.apply(\n",
        "        lambda row: time_decay(row[\"tahun_proposal\"], row[\"tahun_penelitian\"], t=t, gamma=gamma),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # Hitung TOD(M→D)\n",
        "    od_df[\"TOD(M→D)\"] = (od_df[\"OD(M→D)\"] * od_df[\"time_decay_factor\"]).round(4)\n",
        "\n",
        "    return od_df\n",
        "\n",
        "# Panggil fungsi dengan batas selisih tahun antara 3–5\n",
        "tod_m2d_df = compute_tod_m2d(df_od, t=1, gamma=0.1, min_year_diff=0, max_year_diff=5)\n",
        "# Filter nilai TOD(M→D) > 0.04\n",
        "# tod_m2d_df = tod_m2d_df[tod_m2d_df[\"TOD(M→D)\"] > 0.06]\n",
        "\n",
        "# Urutkan berdasarkan skor rekomendasi\n",
        "tod_m2d_df = (\n",
        "    tod_m2d_df\n",
        "    .loc[tod_m2d_df.groupby([\"id_proposal\", \"id_dosen\"])[\"TOD(M→D)\"].idxmax()]\n",
        "    .reset_index(drop=True)\n",
        "    .sort_values(by=[\"id_proposal\", \"TOD(M→D)\"], ascending=[True, False])\n",
        ")\n",
        "\n",
        "# Tampilkan kolom penting\n",
        "print(tod_m2d_df[[\n",
        "    \"id_proposal\", \"mahasiswa\", \"penelitian_id\", \"dosen\", \"id_dosen\",\n",
        "    \"author_position\", \"author_weight\", \"OD(M→D)\", \"tahun_penelitian\",\n",
        "    \"tahun_proposal\", \"selisih_tahun\", \"time_decay_factor\", \"TOD(M→D)\"\n",
        "]].head(5))\n",
        "\n",
        "# Simpan ke CSV\n",
        "# tod_m2d_df.to_csv(\"/content/drive/MyDrive/Skripsi4/kata/directed/tod_m2d_df_kata.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grGd9iKYcZ4u",
        "outputId": "a39c1ccd-a31d-460a-d705-a012a88478f3"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id_proposal mahasiswa penelitian_id            dosen id_dosen  \\\n",
            "4           P1        S1          R186    Heri Prasetyo      D15   \n",
            "0           P1        S1           R48  Bambang Harjito       D1   \n",
            "2           P1        S1          R291          Wiharto      D12   \n",
            "11          P1        S1           R48     Esti Suryani       D8   \n",
            "7           P1        S1          R264      Umi Salamah       D3   \n",
            "\n",
            "    author_position  author_weight  OD(M→D)  tahun_penelitian  tahun_proposal  \\\n",
            "4                 1            1.0   0.1294              2020            2021   \n",
            "0                 1            0.6   0.0882              2018            2021   \n",
            "2                 1            1.0   0.0891              2017            2021   \n",
            "11                2            0.4   0.0588              2018            2021   \n",
            "7                 1            1.0   0.0809              2016            2021   \n",
            "\n",
            "    selisih_tahun  time_decay_factor  TOD(M→D)  \n",
            "4               1                0.9    0.1165  \n",
            "0               3                0.7    0.0617  \n",
            "2               4                0.6    0.0535  \n",
            "11              3                0.7    0.0412  \n",
            "7               5                0.5    0.0404  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Directed D→M"
      ],
      "metadata": {
        "id": "Eo2pqgJBpN57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def compute_od_d_to_m(tfidf_expert, tfidf_proposal, proposal_df, expert_df):\n",
        "    records = []\n",
        "\n",
        "\n",
        "    for idx_expert, exp_row in expert_df.iterrows():\n",
        "        exp_id_dosen = exp_row[\"expert_id\"]\n",
        "        author_position = exp_row[\"author_position\"]\n",
        "        author_weight = exp_row[\"author_weight\"]\n",
        "        pub_year = exp_row[\"pub_year\"]\n",
        "        penelitian_id = exp_row[\"research_id\"]\n",
        "        dosen = exp_row[\"name\"]\n",
        "        exp_vector = tfidf_expert[idx_expert]\n",
        "\n",
        "        for idx_prop, prop_row in proposal_df.iterrows():\n",
        "            prop_id = prop_row[\"proposal_id\"]\n",
        "            prop_vector = tfidf_proposal[idx_prop]\n",
        "            prop_year = prop_row[\"tahun\"]\n",
        "            mahasiswa=prop_row[\"student_id\"]\n",
        "\n",
        "            selisih_tahun = prop_year - pub_year\n",
        "            if 0 <= selisih_tahun <= 5 & pub_year <= prop_year:\n",
        "              sim_d2m = similarity_d_to_m(exp_vector, prop_vector)\n",
        "              od_score = sim_d2m * author_weight\n",
        "\n",
        "              records.append({\n",
        "                  \"id_proposal\": prop_id,\n",
        "                  \"penelitian_id\": penelitian_id,\n",
        "                  \"id_dosen\": exp_id_dosen,\n",
        "                  'mahasiswa': mahasiswa,\n",
        "                  \"dosen\": dosen,\n",
        "                  \"author_position\": author_position,\n",
        "                  \"author_weight\": author_weight,\n",
        "                  \"tahun_penelitian\": pub_year,\n",
        "                  \"tahun_proposal\": prop_year,\n",
        "                  \"OD(D→M)\": round(od_score, 4)\n",
        "              })\n",
        "\n",
        "    df_scores = pd.DataFrame(records)\n",
        "    df_scores = df_scores.loc[df_scores.groupby([\"id_proposal\", \"id_dosen\"])[\"OD(D→M)\"].idxmax()].reset_index(drop=True)\n",
        "    df_scores['id_proposal'] = df_scores['id_proposal'].astype(str)\n",
        "    df_scores = df_scores.sort_values(by=[\"id_dosen\", \"OD(D→M)\"], ascending=[True, False])\n",
        "    return df_scores\n",
        "\n",
        "df_od_d2m = compute_od_d_to_m(\n",
        "    expert_dense,\n",
        "    proposal_dense,\n",
        "    proposal_df, expert_df\n",
        ")\n",
        "\n",
        "# df_od_d2m = df_od_d2m[df_od_d2m[\"OD(D→M)\"] > 0.05]\n",
        "\n",
        "\n",
        "print(df_od_d2m[[\"id_proposal\",\"mahasiswa\", \"id_dosen\", \"dosen\", \"author_position\", \"author_weight\", \"penelitian_id\",\n",
        "                  \"tahun_proposal\", \"tahun_penelitian\", \"OD(D→M)\"]].head(5))\n",
        "\n",
        "# df_od_d2m.to_csv(\"/content/drive/MyDrive/Skripsi4/kata/directed/df_od_d2m_kata.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpApO12TpQyT",
        "outputId": "689e0a3b-53c1-4430-9130-fd8dbe550d67"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     id_proposal mahasiswa id_dosen            dosen  author_position  \\\n",
            "186          P11       S11       D1  Bambang Harjito                1   \n",
            "602         P134      S134       D1  Bambang Harjito                1   \n",
            "264         P114      S114       D1  Bambang Harjito                1   \n",
            "1296         P47       S47       D1  Bambang Harjito                1   \n",
            "248         P113      S113       D1  Bambang Harjito                1   \n",
            "\n",
            "      author_weight penelitian_id  tahun_proposal  tahun_penelitian  OD(D→M)  \n",
            "186             1.0          R253            2023              2023   0.3273  \n",
            "602             1.0           R54            2021              2021   0.3008  \n",
            "264             1.0           R54            2023              2021   0.2761  \n",
            "1296            0.6          R364            2023              2023   0.2729  \n",
            "248             1.0          R363            2023              2023   0.2119  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rekomendasi"
      ],
      "metadata": {
        "id": "FdkW0z-LpyIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_overlap_scores(df_m2d, df_d2m, top_n=17):\n",
        "    # Ambil Top-N dari masing-masing arah\n",
        "    top_m2d = df_m2d.groupby(\"id_proposal\").head(top_n)[[\"id_proposal\", \"id_dosen\",\"mahasiswa\", \"dosen\", \"TOD(M→D)\"]]\n",
        "    top_d2m = df_d2m.groupby(\"id_proposal\").head(top_n)[[\"id_proposal\", \"id_dosen\",\"mahasiswa\", \"dosen\",\"OD(D→M)\"]]\n",
        "\n",
        "    # Outer join untuk semua pasangan top-n\n",
        "    merged = pd.merge(top_m2d, top_d2m, on=[\"id_proposal\", \"id_dosen\"], how=\"outer\")\n",
        "\n",
        "    # Tambahkan kolom nama dosen jika hilang (dari M→D arah saja)\n",
        "    if \"dosen_x\" in merged.columns:\n",
        "        merged[\"dosen\"] = merged[\"dosen_x\"].combine_first(merged.get(\"dosen_y\"))\n",
        "    elif \"dosen\" not in merged.columns:\n",
        "        merged[\"dosen\"] = None\n",
        "\n",
        "    if \"mahasiswa_x\" in merged.columns:\n",
        "        merged[\"mahasiswa\"] = merged[\"mahasiswa_x\"].combine_first(merged.get(\"mahasiswa_y\"))\n",
        "    elif \"mahasiswa\" not in merged.columns:\n",
        "        merged[\"mahasiswa\"] = None\n",
        "\n",
        "    # Ganti NaN skor dengan 0 agar bisa dihitung rata-ratanya\n",
        "    merged[\"TOD(M→D)\"] = merged[\"TOD(M→D)\"].fillna(0)\n",
        "    merged[\"OD(D→M)\"] = merged[\"OD(D→M)\"].fillna(0)\n",
        "\n",
        "    # Tandai overlap jika dosen muncul di kedua arah\n",
        "    merged[\"overlap\"] = (merged[\"TOD(M→D)\"] > 0) & (merged[\"OD(D→M)\"] > 0)\n",
        "\n",
        "    # Hitung skor rata-rata (hanya jika overlap)\n",
        "    merged[\"skor_rata2\"] = merged.apply(\n",
        "        lambda row: (row[\"TOD(M→D)\"] + row[\"OD(D→M)\"]) / 2 if row[\"overlap\"] else 0, axis=1\n",
        "    )\n",
        "\n",
        "    # Ambil skor tertinggi per proposal dan dosen\n",
        "    final_scores = merged[[\"id_proposal\",\"mahasiswa\", \"dosen\", \"id_dosen\", \"TOD(M→D)\",\"OD(D→M)\", \"skor_rata2\", \"overlap\"]]\n",
        "    final_scores = final_scores.sort_values(by=[\"id_proposal\", \"skor_rata2\"], ascending=[True, False])\n",
        "\n",
        "    return final_scores\n",
        "\n",
        "df_final = combine_overlap_scores(tod_m2d_df, df_od_d2m, top_n=17)\n",
        "print(df_final.head(5))\n",
        "\n",
        "# df_final.to_csv(\"/content/drive/MyDrive/Skripsi4/kata/directed/overlap_kombinasi_kata.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzOzfPOvp0Ym",
        "outputId": "083799fe-eafc-4557-f61d-cff0df9e3b8e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id_proposal mahasiswa               dosen id_dosen  TOD(M→D)  OD(D→M)  \\\n",
            "5           P1        S1       Heri Prasetyo      D15    0.1165   0.1294   \n",
            "0           P1        S1     Bambang Harjito       D1    0.0617   0.0376   \n",
            "9           P1        S1  Dewi Wisnu Wardani       D4    0.0394   0.0394   \n",
            "3           P1        S1             Wiharto      D12    0.0535   0.0190   \n",
            "13          P1        S1        Esti Suryani       D8    0.0412   0.0286   \n",
            "\n",
            "    skor_rata2  overlap  \n",
            "5      0.12295     True  \n",
            "0      0.04965     True  \n",
            "9      0.03940     True  \n",
            "3      0.03625     True  \n",
            "13     0.03490     True  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rangking Directed"
      ],
      "metadata": {
        "id": "1uUCgzjip7Y3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_overlap_scores_with_ranking(df_m2d, df_d2m):\n",
        "    # Ambil semua skor dari kedua arah\n",
        "    m2d = df_m2d[[\"id_proposal\", \"id_dosen\",\"mahasiswa\", \"dosen\", \"TOD(M→D)\"]]\n",
        "    d2m = df_d2m[[\"id_proposal\",\"id_dosen\",\"mahasiswa\",\"dosen\", \"OD(D→M)\"]]\n",
        "\n",
        "    # Outer join agar semua kombinasi muncul\n",
        "    merged = pd.merge(m2d, d2m, on=[\"id_proposal\", \"id_dosen\"], how=\"outer\")\n",
        "\n",
        "    # Tambahkan kolom nama dosen jika hilang (dari M→D arah saja)\n",
        "    if \"dosen_x\" in merged.columns:\n",
        "        merged[\"dosen\"] = merged[\"dosen_x\"].combine_first(merged.get(\"dosen_y\"))\n",
        "    elif \"dosen\" not in merged.columns:\n",
        "        merged[\"dosen\"] = None\n",
        "\n",
        "    if \"mahasiswa_x\" in merged.columns:\n",
        "        merged[\"mahasiswa\"] = merged[\"mahasiswa_x\"].combine_first(merged.get(\"mahasiswa_y\"))\n",
        "    elif \"mahasiswa\" not in merged.columns:\n",
        "        merged[\"mahasiswa\"] = None\n",
        "\n",
        "    # Isi nilai NaN dengan 0 untuk penggabungan skor\n",
        "    merged[\"TOD(M→D)\"] = merged[\"TOD(M→D)\"].fillna(0)\n",
        "    merged[\"OD(D→M)\"] = merged[\"OD(D→M)\"].fillna(0)\n",
        "\n",
        "    # Overlap = muncul di kedua arah\n",
        "    merged[\"overlap\"] = (merged[\"TOD(M→D)\"] > 0) & (merged[\"OD(D→M)\"] > 0)\n",
        "\n",
        "    # Skor rata-rata jika overlap\n",
        "    merged[\"skor_rata2\"] = merged.apply(\n",
        "        lambda row: (row[\"TOD(M→D)\"] + row[\"OD(D→M)\"]) / 2 if row[\"overlap\"] else 0, axis=1\n",
        "    )\n",
        "\n",
        "       # Hitung ranking per proposal berdasarkan skor rata-rata (tanpa groupby + agg)\n",
        "    merged[\"rank\"] = merged.groupby(\"id_proposal\")[\"skor_rata2\"]\\\n",
        "                           .rank(ascending=False, method=\"dense\")\\\n",
        "                           .astype(int)\n",
        "\n",
        "    # Ambil kolom yang diinginkan dan urutkan\n",
        "    result = merged.sort_values(by=[\"id_proposal\", \"rank\"])[\n",
        "        [\"id_proposal\",\"mahasiswa\", \"dosen\", \"id_dosen\", \"TOD(M→D)\", \"OD(D→M)\", \"skor_rata2\", \"overlap\", \"rank\"]\n",
        "    ]\n",
        "\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "df_peringkat = combine_overlap_scores_with_ranking(tod_m2d_df, df_od_d2m)\n",
        "# Filter hanya yang overlap == True\n",
        "df_overlap_true = df_peringkat[df_peringkat[\"overlap\"] == True]\n",
        "print(df_overlap_true.head(20))\n",
        "\n",
        "# df_overlap_true.to_csv(\"/content/drive/MyDrive/Skripsi4/kata/directed/rank_overlap_true_kata.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hx_S4r_Qp3Ym",
        "outputId": "828a9903-e25c-4310-ec19-a85f64588c55"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id_proposal mahasiswa               dosen id_dosen  TOD(M→D)  OD(D→M)  \\\n",
            "5           P1        S1       Heri Prasetyo      D15    0.1165   0.1294   \n",
            "0           P1        S1     Bambang Harjito       D1    0.0617   0.0376   \n",
            "9           P1        S1  Dewi Wisnu Wardani       D4    0.0394   0.0394   \n",
            "3           P1        S1             Wiharto      D12    0.0535   0.0190   \n",
            "13          P1        S1        Esti Suryani       D8    0.0412   0.0286   \n",
            "8           P1        S1         Umi Salamah       D3    0.0404   0.0286   \n",
            "2           P1        S1             Winarno      D11    0.0319   0.0354   \n",
            "7           P1        S1             Wiranto       D2    0.0309   0.0309   \n",
            "6           P1        S1     Ardhi Wijayanto      D16    0.0215   0.0179   \n",
            "4           P1        S1     Haryono Setiadi      D14    0.0196   0.0192   \n",
            "14          P1        S1    Sari Widya Sihwi       D9    0.0241   0.0106   \n",
            "23         P10       S10             Wiranto       D2    0.2004   0.2227   \n",
            "15         P10       S10     Bambang Harjito       D1    0.0929   0.0929   \n",
            "20         P10       S10     Haryono Setiadi      D14    0.0878   0.0637   \n",
            "21         P10       S10       Heri Prasetyo      D15    0.0694   0.0771   \n",
            "17         P10       S10             Winarno      D11    0.0711   0.0711   \n",
            "16         P10       S10      Afrizal Doewes      D10    0.0660   0.0660   \n",
            "18         P10       S10             Wiharto      D12    0.0732   0.0581   \n",
            "24         P10       S10         Umi Salamah       D3    0.0483   0.0537   \n",
            "29         P10       S10        Esti Suryani       D8    0.0432   0.0432   \n",
            "\n",
            "    skor_rata2  overlap  rank  \n",
            "5      0.12295     True     1  \n",
            "0      0.04965     True     2  \n",
            "9      0.03940     True     3  \n",
            "3      0.03625     True     4  \n",
            "13     0.03490     True     5  \n",
            "8      0.03450     True     6  \n",
            "2      0.03365     True     7  \n",
            "7      0.03090     True     8  \n",
            "6      0.01970     True     9  \n",
            "4      0.01940     True    10  \n",
            "14     0.01735     True    11  \n",
            "23     0.21155     True     1  \n",
            "15     0.09290     True     2  \n",
            "20     0.07575     True     3  \n",
            "21     0.07325     True     4  \n",
            "17     0.07110     True     5  \n",
            "16     0.06600     True     6  \n",
            "18     0.06565     True     7  \n",
            "24     0.05100     True     8  \n",
            "29     0.04320     True     9  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Beban Kerja"
      ],
      "metadata": {
        "id": "ydn7OewJqDJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# 1. Inisialisasi count untuk rank 1\n",
        "rank1_count_directed = defaultdict(int)\n",
        "final_assignment_directed = []\n",
        "\n",
        "# 2. Tetapkan rank 1 dengan batas 15 kali per dosen\n",
        "for pid in df_overlap_true[\"id_proposal\"].unique():\n",
        "    candidates = df_overlap_true[df_overlap_true[\"id_proposal\"] == pid]\n",
        "    candidates = candidates.sort_values(by=\"skor_rata2\", ascending=False)\n",
        "\n",
        "    assigned_rank1 = False\n",
        "    for _, row in candidates.iterrows():\n",
        "        dosen_id = row[\"id_dosen\"]\n",
        "        if rank1_count_directed[dosen_id] < 15:\n",
        "            rank1_count_directed[dosen_id] += 1\n",
        "            row_data = row.to_dict()\n",
        "            row_data[\"rank\"] = 1\n",
        "            row_data[\"beban\"] = rank1_count_directed[dosen_id]\n",
        "            final_assignment_directed.append(row_data)\n",
        "            assigned_rank1 = True\n",
        "            break\n",
        "\n",
        "    if not assigned_rank1:\n",
        "        row = candidates.iloc[0].to_dict()\n",
        "        dosen_id = row[\"id_dosen\"]\n",
        "        rank1_count_directed[dosen_id] += 1\n",
        "        row[\"rank\"] = 1\n",
        "        row[\"beban\"] = rank1_count_directed[dosen_id]\n",
        "        final_assignment_directed.append(row)\n",
        "\n",
        "# 3. Buat dataframe dari rank 1\n",
        "rank1_directed = pd.DataFrame(final_assignment_directed)\n",
        "\n",
        "# 4. Tambahkan rank 2–17 berdasarkan similarity, excl. dosen yang sudah dipakai di rank 1 untuk proposal yang sama\n",
        "other_ranks = []\n",
        "\n",
        "for pid in df_overlap_true[\"id_proposal\"].unique():\n",
        "    # Dapatkan dosen yang sudah dipakai sebagai rank 1\n",
        "    used_dosen = rank1_directed[rank1_directed[\"id_proposal\"] == pid][\"id_dosen\"].tolist()\n",
        "\n",
        "    # Ambil kandidat lain untuk proposal ini\n",
        "    candidates = df_overlap_true[(df_overlap_true[\"id_proposal\"] == pid) & (~df_overlap_true[\"id_dosen\"].isin(used_dosen))]\n",
        "    candidates = candidates.sort_values(by=\"skor_rata2\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "    for idx, (_, row) in enumerate(candidates.iterrows(), start=2):\n",
        "        if idx > 17:\n",
        "            break\n",
        "        row_data = row.to_dict()\n",
        "        row_data[\"rank\"] = idx\n",
        "        row_data[\"beban\"] = rank1_count_directed[row_data[\"id_dosen\"]]  # Beban hanya dihitung dari rank 1\n",
        "        other_ranks.append(row_data)\n",
        "\n",
        "# 5. Gabungkan rank1 dan other ranks\n",
        "final_df = pd.concat([rank1_directed, pd.DataFrame(other_ranks)], ignore_index=True)\n",
        "final_df = final_df.sort_values(by=[\"id_proposal\", \"rank\"])\n",
        "\n",
        "# 🔟 Filter hanya Top 10 dosen per proposal\n",
        "final_df = final_df[final_df[\"rank\"] <= 17]\n",
        "\n",
        "\n",
        "\n",
        "# 6. Tampilkan hasil\n",
        "print(final_df[[\"id_proposal\", \"mahasiswa\", \"id_dosen\", \"dosen\", \"skor_rata2\", \"rank\", \"beban\"]])\n",
        "\n",
        "# final_df.to_csv(\"/content/drive/MyDrive/Skripsi4/kata/directed/beban_kerja_kata.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnF-h0ZLYuEp",
        "outputId": "17701c40-ab74-4b3a-9d89-16951674309e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     id_proposal mahasiswa id_dosen               dosen  skor_rata2  rank  \\\n",
            "0             P1        S1      D15       Heri Prasetyo     0.12295     1   \n",
            "142           P1        S1       D1     Bambang Harjito     0.04965     2   \n",
            "143           P1        S1       D4  Dewi Wisnu Wardani     0.03940     3   \n",
            "144           P1        S1      D12             Wiharto     0.03625     4   \n",
            "145           P1        S1       D8        Esti Suryani     0.03490     5   \n",
            "...          ...       ...      ...                 ...         ...   ...   \n",
            "2119         P99       S99       D7      Wisnu Widiarto     0.05920    13   \n",
            "2120         P99       S99      D11             Winarno     0.05770    14   \n",
            "2121         P99       S99      D13   Hasan Dwi Cahyono     0.04435    15   \n",
            "2122         P99       S99       D5          Abdul Aziz     0.03265    16   \n",
            "2123         P99       S99       D6       Ristu Saptono     0.01765    17   \n",
            "\n",
            "      beban  \n",
            "0         1  \n",
            "142      13  \n",
            "143      14  \n",
            "144      15  \n",
            "145       9  \n",
            "...     ...  \n",
            "2119      5  \n",
            "2120     13  \n",
            "2121      7  \n",
            "2122      3  \n",
            "2123      2  \n",
            "\n",
            "[2124 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluasi Directed"
      ],
      "metadata": {
        "id": "-zGycLpzqLty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "# Load the true labels DataFrame\n",
        "true_label_df = pd.read_csv(\"/content/drive/MyDrive/Skripsi3/Dataset/true_labels.csv\")\n",
        "\n",
        "\n",
        "# Ubah kolom author, author2, author3 menjadi lowercase\n",
        "true_label_df[\"author1\"] = true_label_df[\"examiner_1\"].astype(str).str.strip()\n",
        "true_label_df[\"author2\"] = true_label_df[\"examiner_2\"].astype(str).str.strip()\n",
        "true_label_df[\"author3\"] = true_label_df[\"examiner_3\"].astype(str).str.strip()\n",
        "\n"
      ],
      "metadata": {
        "id": "eZyklzkzq3eP"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluasi Baru"
      ],
      "metadata": {
        "id": "iDNkVsorTYsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "def evaluate_ordered_recommendation_cosine(rank_all_df, true_label_df, top_ns=[3, 5, 7, 10]):\n",
        "    summary = []\n",
        "\n",
        "    for TOP_N in top_ns:\n",
        "        # Filter Top-N dan urutkan\n",
        "        top_n_df = rank_all_df[rank_all_df[\"rank\"] <= TOP_N]\n",
        "        rec_df = top_n_df.sort_values(by=[\"id_proposal\", \"rank\", \"skor_rata2\"], ascending=[True, True, False])\n",
        "        rec_df = rec_df.drop_duplicates(subset=[\"id_proposal\", \"rank\",\"skor_rata2\"])\n",
        "        rec_pivot = rec_df.pivot(index=\"id_proposal\", columns=\"rank\", values=\"dosen\").reset_index()\n",
        "        rec_pivot.columns.name = None\n",
        "        rec_pivot.columns = [\"id_proposal\"] + [f\"rec_{i}\" for i in range(1, len(rec_pivot.columns))]\n",
        "\n",
        "        # Gabungkan dengan ground truth\n",
        "        merged_df = pd.merge(\n",
        "            rec_pivot,\n",
        "            true_label_df.rename(columns={\"proposal_id\": \"id_proposal\"}),\n",
        "            on=\"id_proposal\",\n",
        "            how=\"left\"\n",
        "        )\n",
        "\n",
        "        # Recall keberadaan (tidak memperhatikan urutan)\n",
        "        def recall_of_existence(row):\n",
        "            true_set = {row.get(\"author1\"), row.get(\"author2\"), row.get(\"author3\")}\n",
        "            pred_set = {row.get(f\"rec_{i}\") for i in range(1, TOP_N + 1) if row.get(f\"rec_{i}\")}\n",
        "            return len(true_set.intersection(pred_set)) / 3\n",
        "\n",
        "        merged_df[f'recall_of_existence@{TOP_N}'] = merged_df.apply(recall_of_existence, axis=1)\n",
        "\n",
        "        # Recall per posisi dengan urutan diperhatikan (rec_i harus sama dengan author_i)\n",
        "        recall_pos = {1: [], 2: [], 3: []}\n",
        "        for _, row in merged_df.iterrows():\n",
        "            for pos in [1, 2, 3]:\n",
        "                examiner = row.get(f'author{pos}')\n",
        "                rec = row.get(f'rec_{pos}') if pos <= TOP_N else None\n",
        "                hit = int(pd.notna(examiner) and pd.notna(rec) and examiner == rec)\n",
        "                recall_pos[pos].append(hit)\n",
        "\n",
        "        # Tambahkan recall ke DataFrame\n",
        "        for pos in [1, 2, 3]:\n",
        "            merged_df[f'recall_pos{pos}_ordered@{TOP_N}'] = recall_pos[pos]\n",
        "\n",
        "        recall_pos_mean = {pos: np.mean(recall_pos[pos]) for pos in [1, 2, 3]}\n",
        "\n",
        "        # Euclidean distance antar posisi (penalti posisi meleset)\n",
        "        distances = []\n",
        "        for _, row in merged_df.iterrows():\n",
        "            true_authors = [row.get(f'author{i}') for i in [1, 2, 3]]\n",
        "            pred_authors = [row.get(f'rec_{i}', None) for i in range(1, TOP_N + 1)]\n",
        "            distance = 0\n",
        "            max_penalty = TOP_N\n",
        "            for i, true_author in enumerate(true_authors):\n",
        "                if pd.isna(true_author) or true_author == '':\n",
        "                    continue\n",
        "                try:\n",
        "                    pred_pos = pred_authors.index(true_author)\n",
        "                    pos_diff = pred_pos - i\n",
        "                    distance += pos_diff ** 2\n",
        "                except ValueError:\n",
        "                    distance += max_penalty ** 2\n",
        "            distances.append(np.sqrt(distance))\n",
        "\n",
        "        scaler = MinMaxScaler()\n",
        "        norm_dists = scaler.fit_transform(np.array(distances).reshape(-1, 1)).flatten()\n",
        "        merged_df[f'norm_euclidean@{TOP_N}'] = norm_dists\n",
        "\n",
        "        # Ringkasan metrik\n",
        "        summary.append({\n",
        "            'Top-N': TOP_N,\n",
        "            'Mean_Recall_Existence': merged_df[f'recall_of_existence@{TOP_N}'].mean(),\n",
        "            'Recall_Pos_1_Ordered': recall_pos_mean[1],\n",
        "            'Recall_Pos_2_Ordered': recall_pos_mean[2],\n",
        "            'Recall_Pos_3_Ordered': recall_pos_mean[3],\n",
        "            'Avg_Normalized_Euclidean': np.mean(norm_dists)\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(summary)\n",
        "\n",
        "result_df = evaluate_ordered_recommendation_cosine(final_df, true_label_df)\n",
        "print(result_df)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQIiCgD_X8am",
        "outputId": "ddc90453-1819-4630-9810-488c708a5cef"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Top-N  Mean_Recall_Existence  Recall_Pos_1_Ordered  Recall_Pos_2_Ordered  \\\n",
            "0      3               0.335681              0.260563              0.098592   \n",
            "1      5               0.462441              0.260563              0.098592   \n",
            "2      7               0.577465              0.260563              0.098592   \n",
            "3     10               0.723005              0.260563              0.098592   \n",
            "\n",
            "   Recall_Pos_3_Ordered  Avg_Normalized_Euclidean  \n",
            "0               0.06338                  0.754492  \n",
            "1               0.06338                  0.695801  \n",
            "2               0.06338                  0.630672  \n",
            "3               0.06338                  0.542393  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def evaluate_per_proposal_directed(rank_all_df, true_label_df, top_n=3):\n",
        "    # Filter dan urutkan\n",
        "    top_n_df = rank_all_df[rank_all_df[\"rank\"] <= top_n]\n",
        "    rec_df = top_n_df.sort_values(by=[\"id_proposal\", \"rank\", \"skor_rata2\"], ascending=[True, True, False])\n",
        "    rec_df = rec_df.drop_duplicates(subset=[\"id_proposal\", \"rank\",\"skor_rata2\"])\n",
        "    rec_pivot = rec_df.pivot(index=\"id_proposal\", columns=\"rank\", values=\"dosen\").reset_index()\n",
        "    rec_pivot.columns.name = None\n",
        "    rec_pivot.columns = [\"id_proposal\"] + [f\"rec_{i}\" for i in range(1, len(rec_pivot.columns))]\n",
        "\n",
        "    # Gabung dengan label kebenaran\n",
        "    merged_df = pd.merge(\n",
        "        rec_pivot,\n",
        "        true_label_df.rename(columns={\"proposal_id\": \"id_proposal\"}),\n",
        "        on=\"id_proposal\",\n",
        "        how=\"left\"\n",
        "    )\n",
        "\n",
        "    # Recall of existence (abaikan urutan)\n",
        "    def recall_of_existence(row):\n",
        "        true_set = {row.get(\"author1\"), row.get(\"author2\"), row.get(\"author3\")}\n",
        "        pred_set = {row.get(f\"rec_{i}\") for i in range(1, top_n + 1) if row.get(f\"rec_{i}\")}\n",
        "        return len(true_set.intersection(pred_set)) / 3\n",
        "\n",
        "    merged_df[f'recall_of_existence@{top_n}'] = merged_df.apply(recall_of_existence, axis=1)\n",
        "\n",
        "    # Recall berdasarkan posisi (urutan harus sama)\n",
        "    for pos in [1, 2, 3]:\n",
        "        merged_df[f'recall_pos{pos}_ordered@{top_n}'] = merged_df.apply(\n",
        "            lambda row: int(\n",
        "                pd.notna(row.get(f'author{pos}')) and\n",
        "                pd.notna(row.get(f'rec_{pos}')) and\n",
        "                row.get(f'author{pos}') == row.get(f'rec_{pos}')\n",
        "            ) if pos <= top_n else 0,\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "    # Euclidean distance penalti posisi\n",
        "    distances = []\n",
        "    for _, row in merged_df.iterrows():\n",
        "        true_authors = [row.get(f'author{i}') for i in [1, 2, 3]]\n",
        "        pred_authors = [row.get(f'rec_{i}', None) for i in range(1, top_n + 1)]\n",
        "        distance = 0\n",
        "        max_penalty = top_n\n",
        "        for i, true_author in enumerate(true_authors):\n",
        "            if pd.isna(true_author) or true_author == '':\n",
        "                continue\n",
        "            try:\n",
        "                pred_pos = pred_authors.index(true_author)\n",
        "                pos_diff = pred_pos - i\n",
        "                distance += pos_diff ** 2\n",
        "            except ValueError:\n",
        "                distance += max_penalty ** 2\n",
        "        distances.append(np.sqrt(distance))\n",
        "\n",
        "    # Normalisasi jarak\n",
        "    scaler = MinMaxScaler()\n",
        "    norm_dists = scaler.fit_transform(np.array(distances).reshape(-1, 1)).flatten()\n",
        "    merged_df[f'norm_euclidean@{top_n}'] = norm_dists\n",
        "\n",
        "    # Ambil kolom evaluasi\n",
        "    result_df = merged_df[[\"id_proposal\",\n",
        "                           f'recall_of_existence@{top_n}',\n",
        "                           f'recall_pos1_ordered@{top_n}',\n",
        "                           f'recall_pos2_ordered@{top_n}',\n",
        "                           f'recall_pos3_ordered@{top_n}',\n",
        "                           f'norm_euclidean@{top_n}']].copy()\n",
        "\n",
        "    return result_df\n",
        "\n",
        "\n",
        "eval_per_proposal_directed_3 = evaluate_per_proposal_directed(final_df, true_label_df, top_n=3)\n",
        "eval_per_proposal_directed_5 = evaluate_per_proposal_directed(final_df, true_label_df, top_n=5)\n",
        "eval_per_proposal_directed_7 = evaluate_per_proposal_directed(final_df, true_label_df, top_n=7)\n",
        "eval_per_proposal_directed_10 = evaluate_per_proposal_directed(final_df, true_label_df, top_n=10)\n",
        "\n",
        "# eval_per_proposal_directed_3.to_csv(\"/content/drive/MyDrive/Skripsi4/kata/directed/hasil_eval_3_kata.csv\", index=False)\n",
        "# eval_per_proposal_directed_5.to_csv(\"/content/drive/MyDrive/Skripsi4/kata/directed/hasil_eval_5_kata.csv\", index=False)\n",
        "# eval_per_proposal_directed_7.to_csv(\"/content/drive/MyDrive/Skripsi4/kata/directed/hasil_eval_7_kata.csv\", index=False)\n",
        "# eval_per_proposal_directed_10.to_csv(\"/content/drive/MyDrive/Skripsi4/kata/directed/hasil_eval_10_kata.csv\", index=False)"
      ],
      "metadata": {
        "id": "emD6Ny3gcKi4"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cosine"
      ],
      "metadata": {
        "id": "dZYcau9mSVeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Hitung similarity\n",
        "similarity_matrix = cosine_similarity(proposal_dense, expert_dense)\n",
        "\n",
        "# Konversi ke DataFrame\n",
        "similarity_df = pd.DataFrame(similarity_matrix)\n",
        "\n",
        "print(similarity_df)\n",
        "\n",
        "# Simpan ke CSV\n",
        "# similarity_df.to_csv(\"/content/drive/MyDrive/Skripsi4/dictionary/similarity_MATRIX_kata_.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e786a28a-45a4-4a41-ac77-05a0d1e098ac",
        "id": "EmUFEcqaSVeV"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          0         1         2         3         4         5         6    \\\n",
            "0    0.025885  0.025885  0.000000  0.016640  0.016640  0.007060  0.007060   \n",
            "1    0.000000  0.000000  0.000000  0.034183  0.034183  0.019044  0.019044   \n",
            "2    0.006330  0.006330  0.043849  0.029157  0.029157  0.011413  0.011413   \n",
            "3    0.000000  0.000000  0.000000  0.036061  0.036061  0.012357  0.012357   \n",
            "4    0.099009  0.099009  0.008426  0.012672  0.012672  0.020999  0.020999   \n",
            "..        ...       ...       ...       ...       ...       ...       ...   \n",
            "137  0.032069  0.032069  0.000000  0.000000  0.000000  0.009633  0.009633   \n",
            "138  0.014635  0.014635  0.037684  0.018834  0.018834  0.006468  0.006468   \n",
            "139  0.055982  0.055982  0.000000  0.000000  0.000000  0.019167  0.019167   \n",
            "140  0.049723  0.049723  0.000000  0.000000  0.000000  0.052787  0.052787   \n",
            "141  0.048280  0.048280  0.003714  0.006355  0.006355  0.009018  0.009018   \n",
            "\n",
            "          7         8         9    ...       750       751       752  \\\n",
            "0    0.000000  0.000000  0.019094  ...  0.000000  0.022878  0.060354   \n",
            "1    0.022905  0.000000  0.012230  ...  0.049187  0.016027  0.027000   \n",
            "2    0.037547  0.009641  0.000000  ...  0.029703  0.052927  0.026461   \n",
            "3    0.000000  0.000000  0.000000  ...  0.025091  0.016907  0.000000   \n",
            "4    0.003996  0.005795  0.008080  ...  0.030471  0.052701  0.000000   \n",
            "..        ...       ...       ...  ...       ...       ...       ...   \n",
            "137  0.000000  0.000000  0.107945  ...  0.004353  0.053003  0.000000   \n",
            "138  0.008392  0.000000  0.009802  ...  0.005377  0.012337  0.000000   \n",
            "139  0.148466  0.000000  0.011246  ...  0.065232  0.002779  0.013986   \n",
            "140  0.000000  0.000000  0.027612  ...  0.072637  0.038942  0.015172   \n",
            "141  0.011333  0.011471  0.033932  ...  0.003301  0.000000  0.000000   \n",
            "\n",
            "          753       754       755       756       757       758       759  \n",
            "0    0.150696  0.150696  0.000000  0.000000  0.043681  0.000000  0.012703  \n",
            "1    0.085163  0.085163  0.016157  0.016157  0.000000  0.000000  0.000000  \n",
            "2    0.000000  0.000000  0.006038  0.006038  0.000000  0.012611  0.012586  \n",
            "3    0.023115  0.023115  0.032661  0.032661  0.122309  0.122783  0.000000  \n",
            "4    0.054400  0.054400  0.025112  0.025112  0.138050  0.175797  0.003783  \n",
            "..        ...       ...       ...       ...       ...       ...       ...  \n",
            "137  0.000000  0.000000  0.029749  0.029749  0.027177  0.013222  0.025865  \n",
            "138  0.000000  0.000000  0.025266  0.025266  0.011051  0.005377  0.013331  \n",
            "139  0.008628  0.008628  0.061185  0.061185  0.009531  0.000000  0.000000  \n",
            "140  0.004680  0.004680  0.024052  0.024052  0.005169  0.000000  0.000000  \n",
            "141  0.033212  0.033212  0.025463  0.025463  0.000000  0.006163  0.000000  \n",
            "\n",
            "[142 rows x 760 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter sesuai kondisi\n",
        "similarity_cosine_df = []\n",
        "\n",
        "for i, (_, mahasiswa) in enumerate(proposal_df.iterrows()):\n",
        "    for j, (_, dosen) in enumerate(expert_df.iterrows()):\n",
        "        # weight = dosen.get(\"author_weight\", 1.0)\n",
        "        # score_akhir = similarity_matrix[i, j] * weight\n",
        "        # score_akhir = similarity_matrix[i, j]\n",
        "        similarity_cosine_df.append({\n",
        "            \"id_proposal\": mahasiswa[\"proposal_id\"],\n",
        "            \"mahasiswa\": mahasiswa[\"student_id\"],\n",
        "            \"id_dosen\": dosen[\"expert_id\"],\n",
        "            \"id_penelitian\": dosen[\"research_id\"],\n",
        "            \"tahun_proposal\": mahasiswa[\"tahun\"],\n",
        "            \"tahun_penelitian\": dosen[\"pub_year\"],\n",
        "            \"selisih_tahun\": mahasiswa[\"tahun\"] - dosen[\"pub_year\"],\n",
        "            \"dosen\": dosen[\"name\"],\n",
        "           \"author_position\": dosen[\"author_position\"],\n",
        "            # \"weight\": weight,\n",
        "            \"similarity_score\" : similarity_matrix[i, j],\n",
        "            # \"similarity_score_akhir\": score_akhir,\n",
        "        })\n",
        "\n",
        "similarity_cosine_df = pd.DataFrame(similarity_cosine_df)\n",
        "\n",
        "\n",
        "similarity_cosine = similarity_cosine_df[\n",
        "    (similarity_cosine_df[\"tahun_proposal\"] > similarity_cosine_df[\"tahun_penelitian\"]) &\n",
        "    (similarity_cosine_df[\"selisih_tahun\"] > 0) &\n",
        "    (similarity_cosine_df[\"selisih_tahun\"] <= 5)\n",
        "].copy()\n",
        "\n",
        "\n",
        "# similarity_cosine.to_csv(\"/content/drive/MyDrive/Skripsi4/kata/cosine/similarity_cosine_kata_baru_sbelumfilter.csv\", index=False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Olpur4CrU61h"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ambil baris dengan similarity tertinggi untuk kombinasi unik id_proposal dan id_dosen\n",
        "idx = similarity_cosine.groupby([\"id_proposal\", \"id_dosen\"])[\"similarity_score\"].idxmax()\n",
        "similarity_cosine = similarity_cosine.loc[idx]\n",
        "\n",
        "# Ranking ulang berdasarkan proposal\n",
        "similarity_cosine[\"rank\"] = similarity_cosine.groupby(\"id_proposal\")[\"similarity_score\"] \\\n",
        "                                     .rank(method=\"first\", ascending=False).astype(int)\n",
        "\n",
        "# Urutkan\n",
        "similarity_cosine = similarity_cosine.sort_values([\"id_proposal\", \"rank\"])\n",
        "similarity_cosine = similarity_cosine[similarity_cosine[\"rank\"] <= 17]\n",
        "\n",
        "\n",
        "# Tampilkan\n",
        "print(similarity_cosine[[\"id_proposal\", \"mahasiswa\",\"tahun_proposal\",\"id_penelitian\", \"tahun_penelitian\", \"id_dosen\", \"dosen\",\"selisih_tahun\", \"author_position\", \"similarity_score\",\"rank\"]])\n",
        "# similarity_cosine.to_csv(\"/content/drive/MyDrive/Skripsi4/kata/cosine/similarity_cosine_kata_baru_setelah filter.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfea7529-1f3c-492e-dfd6-755fcb280f13",
        "id": "ecYp_9r1SVeW"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      id_proposal mahasiswa  tahun_proposal id_penelitian  tahun_penelitian  \\\n",
            "83             P1        S1            2021           R48              2018   \n",
            "84             P1        S1            2021           R48              2018   \n",
            "305            P1        S1            2021          R186              2020   \n",
            "470            P1        S1            2021          R291              2017   \n",
            "434            P1        S1            2021          R264              2016   \n",
            "...           ...       ...             ...           ...               ...   \n",
            "75057         P99       S99            2024          R364              2023   \n",
            "75082         P99       S99            2024          R377              2023   \n",
            "75236         P99       S99            2024          R464              2022   \n",
            "74888         P99       S99            2024          R247              2019   \n",
            "74574         P99       S99            2024           R55              2021   \n",
            "\n",
            "      id_dosen              dosen  selisih_tahun  author_position  \\\n",
            "83          D1    Bambang Harjito              3                1   \n",
            "84          D8       Esti Suryani              3                2   \n",
            "305        D15      Heri Prasetyo              1                1   \n",
            "470        D12            Wiharto              4                1   \n",
            "434         D3        Umi Salamah              5                1   \n",
            "...        ...                ...            ...              ...   \n",
            "75057      D11            Winarno              1                2   \n",
            "75082      D13  Hasan Dwi Cahyono              1                2   \n",
            "75236      D15      Heri Prasetyo              2                2   \n",
            "74888       D6      Ristu Saptono              5                1   \n",
            "74574       D5         Abdul Aziz              3                1   \n",
            "\n",
            "       similarity_score  rank  \n",
            "83             0.146956     1  \n",
            "84             0.146956     2  \n",
            "305            0.129410     3  \n",
            "470            0.089078     4  \n",
            "434            0.080904     5  \n",
            "...                 ...   ...  \n",
            "75057          0.098296    12  \n",
            "75082          0.085260    13  \n",
            "75236          0.083299    14  \n",
            "74888          0.064512    15  \n",
            "74574          0.064071    16  \n",
            "\n",
            "[2248 rows x 11 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# 1. Inisialisasi count untuk rank 1\n",
        "rank1_count = defaultdict(int)\n",
        "final_assignments = []\n",
        "\n",
        "# 2. Tetapkan rank 1 dengan batas 15 kali per dosen\n",
        "for pid in similarity_cosine[\"id_proposal\"].unique():\n",
        "    candidates = similarity_cosine[similarity_cosine[\"id_proposal\"] == pid]\n",
        "    candidates = candidates.sort_values(by=\"similarity_score\", ascending=False)\n",
        "\n",
        "    assigned_rank1 = False\n",
        "    for _, row in candidates.iterrows():\n",
        "        dosen_id = row[\"id_dosen\"]\n",
        "        if rank1_count[dosen_id] < 15:\n",
        "            rank1_count[dosen_id] += 1\n",
        "            row_data = row.to_dict()\n",
        "            row_data[\"rank\"] = 1\n",
        "            row_data[\"beban\"] = rank1_count[dosen_id]\n",
        "            final_assignments.append(row_data)\n",
        "            assigned_rank1 = True\n",
        "            break\n",
        "\n",
        "    if not assigned_rank1:\n",
        "        row = candidates.iloc[0].to_dict()\n",
        "        dosen_id = row[\"id_dosen\"]\n",
        "        rank1_count[dosen_id] += 1\n",
        "        row[\"rank\"] = 1\n",
        "        row[\"beban\"] = rank1_count[dosen_id]\n",
        "        final_assignments.append(row)\n",
        "\n",
        "# 3. Buat dataframe dari rank 1\n",
        "rank1_df = pd.DataFrame(final_assignments)\n",
        "\n",
        "# 4. Tambahkan rank 2–17 berdasarkan similarity, excl. dosen yang sudah dipakai di rank 1 untuk proposal yang sama\n",
        "other_ranks = []\n",
        "\n",
        "for pid in similarity_cosine[\"id_proposal\"].unique():\n",
        "    # Dapatkan dosen yang sudah dipakai sebagai rank 1\n",
        "    used_dosen = rank1_df[rank1_df[\"id_proposal\"] == pid][\"id_dosen\"].tolist()\n",
        "\n",
        "    # Ambil kandidat lain untuk proposal ini\n",
        "    candidates = similarity_cosine[(similarity_cosine[\"id_proposal\"] == pid) & (~similarity_cosine[\"id_dosen\"].isin(used_dosen))]\n",
        "    candidates = candidates.sort_values(by=\"similarity_score\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "    for idx, (_, row) in enumerate(candidates.iterrows(), start=2):\n",
        "        if idx > 17:\n",
        "            break\n",
        "        row_data = row.to_dict()\n",
        "        row_data[\"rank\"] = idx\n",
        "        row_data[\"beban\"] = rank1_count[row_data[\"id_dosen\"]]  # Beban hanya dihitung dari rank 1\n",
        "        other_ranks.append(row_data)\n",
        "\n",
        "# 5. Gabungkan rank1 dan other ranks\n",
        "rank_df = pd.concat([rank1_df, pd.DataFrame(other_ranks)], ignore_index=True)\n",
        "rank_df = rank_df.sort_values(by=[\"id_proposal\", \"rank\"])\n",
        "\n",
        "# 🔟 Filter hanya Top 10 dosen per proposal\n",
        "rank_all_df = rank_df[rank_df[\"rank\"] <= 17]\n",
        "\n",
        "\n",
        "\n",
        "# 6. Tampilkan hasil\n",
        "print(rank_all_df[[\"id_proposal\", \"mahasiswa\", \"id_dosen\", \"dosen\", \"similarity_score\", \"rank\", \"beban\"]])\n",
        "# rank_all_df.to_csv(\"/content/drive/MyDrive/Skripsi4/kata/cosine/beban_kata.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74917511-fc9c-44c9-cb0a-8f74c8a41a0d",
        "id": "p9ZrO_tRSVeW"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     id_proposal mahasiswa id_dosen              dosen  similarity_score  \\\n",
            "0             P1        S1       D1    Bambang Harjito          0.146956   \n",
            "142           P1        S1       D8       Esti Suryani          0.146956   \n",
            "143           P1        S1      D15      Heri Prasetyo          0.129410   \n",
            "144           P1        S1      D12            Wiharto          0.089078   \n",
            "145           P1        S1       D3        Umi Salamah          0.080904   \n",
            "...          ...       ...      ...                ...               ...   \n",
            "2243         P99       S99      D11            Winarno          0.098296   \n",
            "2244         P99       S99      D13  Hasan Dwi Cahyono          0.085260   \n",
            "2245         P99       S99      D15      Heri Prasetyo          0.083299   \n",
            "2246         P99       S99       D6      Ristu Saptono          0.064512   \n",
            "2247         P99       S99       D5         Abdul Aziz          0.064071   \n",
            "\n",
            "      rank  beban  \n",
            "0        1      1  \n",
            "142      2      4  \n",
            "143      3     15  \n",
            "144      4     15  \n",
            "145      5      4  \n",
            "...    ...    ...  \n",
            "2243    12     15  \n",
            "2244    13      5  \n",
            "2245    14     15  \n",
            "2246    15      5  \n",
            "2247    16      9  \n",
            "\n",
            "[2248 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Urutkan berdasarkan id_proposal, similarity_score_akhir (descending), dan author_position (ascending)\n",
        "similarity_cosine_df_baru = rank_all_df.sort_values(\n",
        "    by=[\"id_proposal\", \"similarity_score\", \"author_position\"],\n",
        "    ascending=[True, False, True]\n",
        ")\n",
        "\n",
        "# Tambahkan kolom rank untuk setiap id_proposal\n",
        "similarity_cosine_df_baru[\"rank\"] = similarity_cosine_df_baru.groupby(\"id_proposal\").cumcount() + 1\n",
        "\n",
        "print(similarity_cosine_df_baru[[\"id_proposal\", \"mahasiswa\",\"tahun_proposal\",\"id_penelitian\", \"tahun_penelitian\", \"id_dosen\", \"dosen\",\"selisih_tahun\", \"author_position\",\"similarity_score\",\"rank\",\"beban\"]])\n",
        "similarity_cosine_df_baru.to_csv(\"/content/drive/MyDrive/Skripsi4/kata/cosine/beban_cosine_topik_urut_author.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZ4O27Qx38A-",
        "outputId": "64020a80-4676-4249-9073-d108272b058b"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     id_proposal mahasiswa  tahun_proposal id_penelitian  tahun_penelitian  \\\n",
            "0             P1        S1            2021           R48              2018   \n",
            "142           P1        S1            2021           R48              2018   \n",
            "143           P1        S1            2021          R186              2020   \n",
            "144           P1        S1            2021          R291              2017   \n",
            "145           P1        S1            2021          R264              2016   \n",
            "...          ...       ...             ...           ...               ...   \n",
            "2243         P99       S99            2024          R364              2023   \n",
            "2244         P99       S99            2024          R377              2023   \n",
            "2245         P99       S99            2024          R464              2022   \n",
            "2246         P99       S99            2024          R247              2019   \n",
            "2247         P99       S99            2024           R55              2021   \n",
            "\n",
            "     id_dosen              dosen  selisih_tahun  author_position  \\\n",
            "0          D1    Bambang Harjito              3                1   \n",
            "142        D8       Esti Suryani              3                2   \n",
            "143       D15      Heri Prasetyo              1                1   \n",
            "144       D12            Wiharto              4                1   \n",
            "145        D3        Umi Salamah              5                1   \n",
            "...       ...                ...            ...              ...   \n",
            "2243      D11            Winarno              1                2   \n",
            "2244      D13  Hasan Dwi Cahyono              1                2   \n",
            "2245      D15      Heri Prasetyo              2                2   \n",
            "2246       D6      Ristu Saptono              5                1   \n",
            "2247       D5         Abdul Aziz              3                1   \n",
            "\n",
            "      similarity_score  rank  beban  \n",
            "0             0.146956     1      1  \n",
            "142           0.146956     2      4  \n",
            "143           0.129410     3     15  \n",
            "144           0.089078     4     15  \n",
            "145           0.080904     5      4  \n",
            "...                ...   ...    ...  \n",
            "2243          0.098296    12     15  \n",
            "2244          0.085260    13      5  \n",
            "2245          0.083299    14     15  \n",
            "2246          0.064512    15      5  \n",
            "2247          0.064071    16      9  \n",
            "\n",
            "[2248 rows x 12 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluasi Cosine"
      ],
      "metadata": {
        "id": "8w_Mwi6DDb3c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "coba"
      ],
      "metadata": {
        "id": "BI86uhsrX4dO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluasi Baru"
      ],
      "metadata": {
        "id": "AURg-JbKTew-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "def evaluate_ordered_recommendation_cosine(rank_all_df, true_label_df, top_ns=[3, 5, 7, 10]):\n",
        "    summary = []\n",
        "\n",
        "    for TOP_N in top_ns:\n",
        "        # Filter Top-N dan urutkan\n",
        "        top_n_df = rank_all_df[rank_all_df[\"rank\"] <= TOP_N]\n",
        "        rec_df = top_n_df.sort_values(by=[\"id_proposal\", \"rank\", \"similarity_score\"], ascending=[True, True, False])\n",
        "        rec_pivot = rec_df.pivot(index=\"id_proposal\", columns=\"rank\", values=\"dosen\").reset_index()\n",
        "        rec_pivot.columns.name = None\n",
        "        rec_pivot.columns = [\"id_proposal\"] + [f\"rec_{i}\" for i in range(1, len(rec_pivot.columns))]\n",
        "\n",
        "        # Gabungkan dengan ground truth\n",
        "        merged_df = pd.merge(\n",
        "            rec_pivot,\n",
        "            true_label_df.rename(columns={\"proposal_id\": \"id_proposal\"}),\n",
        "            on=\"id_proposal\",\n",
        "            how=\"left\"\n",
        "        )\n",
        "\n",
        "        # Recall keberadaan (tidak memperhatikan urutan)\n",
        "        def recall_of_existence(row):\n",
        "            true_set = {row.get(\"author1\"), row.get(\"author2\"), row.get(\"author3\")}\n",
        "            pred_set = {row.get(f\"rec_{i}\") for i in range(1, TOP_N + 1) if row.get(f\"rec_{i}\")}\n",
        "            return len(true_set.intersection(pred_set)) / 3\n",
        "\n",
        "        merged_df[f'recall_of_existence@{TOP_N}'] = merged_df.apply(recall_of_existence, axis=1)\n",
        "\n",
        "        # Recall per posisi dengan urutan diperhatikan (rec_i harus sama dengan author_i)\n",
        "        recall_pos = {1: [], 2: [], 3: []}\n",
        "        for _, row in merged_df.iterrows():\n",
        "            for pos in [1, 2, 3]:\n",
        "                examiner = row.get(f'author{pos}')\n",
        "                rec = row.get(f'rec_{pos}') if pos <= TOP_N else None\n",
        "                hit = int(pd.notna(examiner) and pd.notna(rec) and examiner == rec)\n",
        "                recall_pos[pos].append(hit)\n",
        "\n",
        "        # Tambahkan recall ke DataFrame\n",
        "        for pos in [1, 2, 3]:\n",
        "            merged_df[f'recall_pos{pos}_ordered@{TOP_N}'] = recall_pos[pos]\n",
        "\n",
        "        recall_pos_mean = {pos: np.mean(recall_pos[pos]) for pos in [1, 2, 3]}\n",
        "\n",
        "        # Euclidean distance antar posisi (penalti posisi meleset)\n",
        "        distances = []\n",
        "        for _, row in merged_df.iterrows():\n",
        "            true_authors = [row.get(f'author{i}') for i in [1, 2, 3]]\n",
        "            pred_authors = [row.get(f'rec_{i}', None) for i in range(1, TOP_N + 1)]\n",
        "            distance = 0\n",
        "            max_penalty = TOP_N\n",
        "            for i, true_author in enumerate(true_authors):\n",
        "                if pd.isna(true_author) or true_author == '':\n",
        "                    continue\n",
        "                try:\n",
        "                    pred_pos = pred_authors.index(true_author)\n",
        "                    pos_diff = pred_pos - i\n",
        "                    distance += pos_diff ** 2\n",
        "                except ValueError:\n",
        "                    distance += max_penalty ** 2\n",
        "            distances.append(np.sqrt(distance))\n",
        "\n",
        "        scaler = MinMaxScaler()\n",
        "        norm_dists = scaler.fit_transform(np.array(distances).reshape(-1, 1)).flatten()\n",
        "        merged_df[f'norm_euclidean@{TOP_N}'] = norm_dists\n",
        "\n",
        "        # Ringkasan metrik\n",
        "        summary.append({\n",
        "            'Top-N': TOP_N,\n",
        "            'Mean_Recall_Existence': merged_df[f'recall_of_existence@{TOP_N}'].mean(),\n",
        "            'Recall_Pos_1_Ordered': recall_pos_mean[1],\n",
        "            'Recall_Pos_2_Ordered': recall_pos_mean[2],\n",
        "            'Recall_Pos_3_Ordered': recall_pos_mean[3],\n",
        "            'Avg_Normalized_Euclidean': np.mean(norm_dists)\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(summary)\n",
        "\n",
        "result_df = evaluate_ordered_recommendation_cosine(rank_all_df, true_label_df)\n",
        "print(result_df)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKx0VSImXucE",
        "outputId": "a4c49437-3631-4697-a52a-5ec2bf240bba"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Top-N  Mean_Recall_Existence  Recall_Pos_1_Ordered  Recall_Pos_2_Ordered  \\\n",
            "0      3               0.288732              0.204225              0.084507   \n",
            "1      5               0.434272              0.204225              0.084507   \n",
            "2      7               0.556338              0.204225              0.084507   \n",
            "3     10               0.713615              0.204225              0.084507   \n",
            "\n",
            "   Recall_Pos_3_Ordered  Avg_Normalized_Euclidean  \n",
            "0              0.077465                  0.848544  \n",
            "1              0.077465                  0.759507  \n",
            "2              0.077465                  0.687328  \n",
            "3              0.077465                  0.588596  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def evaluate_per_proposal_cosine(rank_all_df, true_label_df, top_n=3):\n",
        "    # Filter dan urutkan\n",
        "    top_n_df = rank_all_df[rank_all_df[\"rank\"] <= top_n]\n",
        "    rec_df = top_n_df.sort_values(by=[\"id_proposal\", \"rank\", \"similarity_score\"], ascending=[True, True, False])\n",
        "    rec_pivot = rec_df.pivot(index=\"id_proposal\", columns=\"rank\", values=\"dosen\").reset_index()\n",
        "    rec_pivot.columns.name = None\n",
        "    rec_pivot.columns = [\"id_proposal\"] + [f\"rec_{i}\" for i in range(1, len(rec_pivot.columns))]\n",
        "\n",
        "    # Gabung dengan label kebenaran\n",
        "    merged_df = pd.merge(\n",
        "        rec_pivot,\n",
        "        true_label_df.rename(columns={\"proposal_id\": \"id_proposal\"}),\n",
        "        on=\"id_proposal\",\n",
        "        how=\"left\"\n",
        "    )\n",
        "\n",
        "    # Recall of existence (abaikan urutan)\n",
        "    def recall_of_existence(row):\n",
        "        true_set = {row.get(\"author1\"), row.get(\"author2\"), row.get(\"author3\")}\n",
        "        pred_set = {row.get(f\"rec_{i}\") for i in range(1, top_n + 1) if row.get(f\"rec_{i}\")}\n",
        "        return len(true_set.intersection(pred_set)) / 3\n",
        "\n",
        "    merged_df[f'recall_of_existence@{top_n}'] = merged_df.apply(recall_of_existence, axis=1)\n",
        "\n",
        "    # Recall berdasarkan posisi (urutan harus sama)\n",
        "    for pos in [1, 2, 3]:\n",
        "        merged_df[f'recall_pos{pos}_ordered@{top_n}'] = merged_df.apply(\n",
        "            lambda row: int(\n",
        "                pd.notna(row.get(f'author{pos}')) and\n",
        "                pd.notna(row.get(f'rec_{pos}')) and\n",
        "                row.get(f'author{pos}') == row.get(f'rec_{pos}')\n",
        "            ) if pos <= top_n else 0,\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "    # Euclidean distance penalti posisi\n",
        "    distances = []\n",
        "    for _, row in merged_df.iterrows():\n",
        "        true_authors = [row.get(f'author{i}') for i in [1, 2, 3]]\n",
        "        pred_authors = [row.get(f'rec_{i}', None) for i in range(1, top_n + 1)]\n",
        "        distance = 0\n",
        "        max_penalty = top_n\n",
        "        for i, true_author in enumerate(true_authors):\n",
        "            if pd.isna(true_author) or true_author == '':\n",
        "                continue\n",
        "            try:\n",
        "                pred_pos = pred_authors.index(true_author)\n",
        "                pos_diff = pred_pos - i\n",
        "                distance += pos_diff ** 2\n",
        "            except ValueError:\n",
        "                distance += max_penalty ** 2\n",
        "        distances.append(np.sqrt(distance))\n",
        "\n",
        "    # Normalisasi jarak\n",
        "    scaler = MinMaxScaler()\n",
        "    norm_dists = scaler.fit_transform(np.array(distances).reshape(-1, 1)).flatten()\n",
        "    merged_df[f'norm_euclidean@{top_n}'] = norm_dists\n",
        "\n",
        "    # Ambil kolom evaluasi\n",
        "    result_df = merged_df[[\"id_proposal\",\n",
        "                           f'recall_of_existence@{top_n}',\n",
        "                           f'recall_pos1_ordered@{top_n}',\n",
        "                           f'recall_pos2_ordered@{top_n}',\n",
        "                           f'recall_pos3_ordered@{top_n}',\n",
        "                           f'norm_euclidean@{top_n}']].copy()\n",
        "\n",
        "    return result_df\n",
        "\n",
        "\n",
        "eval_per_proposal_cosine_3 = evaluate_per_proposal_cosine(rank_all_df, true_label_df, top_n=3)\n",
        "eval_per_proposal_cosine_5 = evaluate_per_proposal_cosine(rank_all_df, true_label_df, top_n=5)\n",
        "eval_per_proposal_cosine_7 = evaluate_per_proposal_cosine(rank_all_df, true_label_df, top_n=7)\n",
        "eval_per_proposal_cosine_10 = evaluate_per_proposal_cosine(rank_all_df, true_label_df, top_n=10)\n",
        "\n",
        "# eval_per_proposal_cosine_3.to_csv(\"/content/drive/MyDrive/Skripsi4/kata/cosine/hasil_eval_3_kata.csv\", index=False)\n",
        "# eval_per_proposal_cosine_5.to_csv(\"/content/drive/MyDrive/Skripsi4/kata/cosine/hasil_eval_5_kata.csv\", index=False)\n",
        "# eval_per_proposal_cosine_7.to_csv(\"/content/drive/MyDrive/Skripsi4/kata/cosine/hasil_eval_7_kata.csv\", index=False)\n",
        "# eval_per_proposal_cosine_10.to_csv(\"/content/drive/MyDrive/Skripsi4/kata/cosine/hasil_eval_10_kata.csv\", index=False)"
      ],
      "metadata": {
        "id": "h9feziiLcYP0"
      },
      "execution_count": 51,
      "outputs": []
    }
  ]
}