{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/slsabilaAura/Tugas-Akhir/blob/main/LDA_Topik_14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aca851f",
        "outputId": "4fbe6676-1a1e-4724-d2b4-bf9d1421af5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.3.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ],
      "source": [
        "%pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQIdw0eelk43",
        "outputId": "bef062f2-988d-4238-d4cf-e0ee5838562d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# prompt: import file form drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "V0HTbrGd6ePM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# Save the preprocessed DataFrames to new CSV files\n",
        "proposal_df = pd.read_csv('/content/drive/MyDrive/Skripsi3/Dataset/processed_proposalC.csv')\n",
        "expert_df = pd.read_csv('/content/drive/MyDrive/Skripsi3/Dataset/processed_expertC.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xpxYRgx768uU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gensim\n",
        "from gensim import corpora\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from gensim.models.ldamodel import LdaModel\n",
        "import ast\n",
        "from gensim.models import Phrases\n",
        "from gensim.models.phrases import Phraser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brLAWvZi8CQh"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "G42J8DDSOq0f"
      },
      "outputs": [],
      "source": [
        "def convert_to_list(text):\n",
        "    try:\n",
        "        return ast.literal_eval(text) if isinstance(text, str) else text\n",
        "    except:\n",
        "        return []\n",
        "\n",
        "\n",
        "proposal_df[\"processed\"] = proposal_df[\"stemmed\"].apply(convert_to_list)\n",
        "expert_df[\"processed\"] = expert_df[\"stemmed\"].apply(convert_to_list)\n",
        "\n",
        "# Gabungkan semua dokumen untuk membuat satu kamus bersama\n",
        "documents_all = proposal_df[\"processed\"].tolist() + expert_df[\"processed\"].tolist()\n",
        "dictionary_all = Dictionary(documents_all)\n",
        "\n",
        "dictionary_all.filter_extremes(no_below=5, no_above=0.5)\n",
        "\n",
        "proposal_corpus = [dictionary_all.doc2bow(doc) for doc in proposal_df[\"processed\"]]\n",
        "expert_corpus = [dictionary_all.doc2bow(doc) for doc in expert_df[\"processed\"]]\n",
        "\n",
        "corpus_all= proposal_corpus + expert_corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me5xyf5Z8OwR"
      },
      "source": [
        "# Model LDA"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import time\n",
        "# import pandas as pd\n",
        "# import pandas as pd\n",
        "# from gensim.models.ldamodel import LdaModel\n",
        "# from gensim.models.coherencemodel import CoherenceModel\n",
        "\n",
        "# # List untuk menyimpan hasil eksperimen\n",
        "# results_lda = []\n",
        "\n",
        "\n",
        "# for num_topics in range(1, 51):\n",
        "#     start_time = time.time()  # Mulai timer\n",
        "\n",
        "#     # Train LDA model\n",
        "#     lda_model_lda = LdaModel(\n",
        "#         corpus=corpus_all,\n",
        "#         id2word=dictionary_all,\n",
        "#         num_topics=num_topics,\n",
        "#         alpha=0.5,   # Bisa diganti dengan nilai tetap\n",
        "#         eta=0.01,     # Bisa diganti dengan nilai tetap\n",
        "#         passes=50,\n",
        "#         random_state=42,\n",
        "#         iterations= 400,\n",
        "#     )\n",
        "\n",
        "#     # Evaluasi dengan coherence score\n",
        "#     coherence_model_lda= CoherenceModel(\n",
        "#         model=lda_model_lda,\n",
        "#         texts=proposal_df['processed'].tolist() + expert_df['processed'].tolist(),\n",
        "#         dictionary=dictionary_all,\n",
        "#         coherence='c_v'\n",
        "#     )\n",
        "#     coherence_score_lda = coherence_model_lda.get_coherence()\n",
        "\n",
        "#     # Evaluasi Topic Diversity\n",
        "#     top_words_per_topic_lda = [lda_model_lda.show_topic(topic_id, topn=20) for topic_id in range(num_topics)]\n",
        "#     unique_words_lda = set([word for topic in top_words_per_topic_lda for word, _ in topic])\n",
        "#     total_words_lda = num_topics * 20  # 10 kata per topik\n",
        "#     topic_diversity_lda = len(unique_words_lda) / total_words_lda if total_words_lda > 0 else 0\n",
        "\n",
        "#     # Hitung waktu eksekusi\n",
        "#     time_taken_lda = time.time() - start_time\n",
        "\n",
        "#     # Simpan hasil dalam list\n",
        "#     results_lda.append([num_topics, coherence_score_lda, topic_diversity_lda, time_taken_lda])\n",
        "#     print(f\"Topics: {num_topics} | Coherence: {coherence_score_lda:.4f} | Diversity: {topic_diversity_lda:.4f} | Time: {time_taken_lda:.2f} sec\")\n",
        "\n",
        "# # Simpan ke DataFrame\n",
        "# results_looping_df = pd.DataFrame(results_lda, columns=['num_topics', 'coherence_score_lda', 'topic_diversity_lda', 'time_taken_lda'])"
      ],
      "metadata": {
        "id": "YTwBDjBv_WZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "OJDKKZUd8Kqz"
      },
      "outputs": [],
      "source": [
        "from itertools import combinations\n",
        "\n",
        "num_topics = 14  # atau optimalisasi via coherence\n",
        "\n",
        "lda_model = LdaModel(\n",
        "    corpus=corpus_all,\n",
        "    id2word=dictionary_all,\n",
        "    num_topics=num_topics,\n",
        "    passes=50,\n",
        "    random_state=42,\n",
        "    iterations= 400,\n",
        "    alpha=0.5,\n",
        "    eta=0.01\n",
        "\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "9FQqm9YGikDW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = []\n",
        "\n",
        "for topic_id in range(num_topics):\n",
        "    top_words = lda_model.show_topic(topic_id, topn=25)\n",
        "    words = [word for word, prob in top_words]\n",
        "    probs = [round(prob, 4) for word, prob in top_words]\n",
        "\n",
        "    data.append({\n",
        "        'Topik': topic_id + 1,\n",
        "        'Kata Kunci': ', '.join(words),\n",
        "        'Probabilitas': ', '.join(map(str, probs))\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Tampilkan hasil\n",
        "# print(df)\n",
        "\n",
        "# Simpan ke CSV jika diinginkan\n",
        "# df.to_csv('/content/drive/MyDrive/Skripsi4/dictionary/topik_kata_dan_probabilitas_14_baru_top25word.csv', index=False, encoding='utf-8-sig')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "R5k7jvUSj35x"
      },
      "outputs": [],
      "source": [
        "from gensim.matutils import sparse2full\n",
        "\n",
        "# Fungsi untuk mendapatkan dense topic vector\n",
        "def get_topic_vector(lda_model, dictionary, document, num_topics):\n",
        "    bow = dictionary.doc2bow(document)\n",
        "    topic_dist = lda_model.get_document_topics(bow, minimum_probability=0.00001)\n",
        "    return sparse2full(topic_dist, num_topics)\n",
        "\n",
        "# Ambil jumlah topik dari model LDA\n",
        "num_topics = lda_model.num_topics\n",
        "\n",
        "# Hitung topik vektor dalam bentuk dense array (untuk expert)\n",
        "expert_df[\"topic_vector\"] = [\n",
        "    get_topic_vector(lda_model, dictionary_all, doc, num_topics)\n",
        "    for doc in expert_df[\"processed\"]\n",
        "]\n",
        "\n",
        "# Hitung topik vektor dalam bentuk dense array (untuk proposal)\n",
        "proposal_df[\"topic_vector\"] = [\n",
        "    get_topic_vector(lda_model, dictionary_all, doc, num_topics)\n",
        "    for doc in proposal_df[\"processed\"]\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "tZFE5rntA7F4"
      },
      "outputs": [],
      "source": [
        "proposal_df[\"tahun\"] = proposal_df[\"proposal_year\"].astype(int)\n",
        "expert_df[\"pub_year\"] = expert_df[\"research_pub_year\"].astype(int)\n",
        "\n",
        "\n",
        "def similarity_m_to_d(proposal_vector, expert_vector):\n",
        "    numerator = np.dot(proposal_vector, expert_vector)\n",
        "    denominator = (np.linalg.norm(proposal_vector) + 1e-10)\n",
        "    return numerator / (denominator)\n",
        "\n",
        "\n",
        "def similarity_d_to_m(expert_vector, proposal_vector):\n",
        "    numerator = np.dot(expert_vector, proposal_vector)\n",
        "    denominator = (np.linalg.norm(expert_vector) + 1e-10)\n",
        "    return numerator / (denominator)\n",
        "\n",
        " # denominator = np.linalg.norm(expert_vector)\n",
        "\n",
        "def time_decay(year_prop, year_ex, t=1, gamma=0.1):\n",
        "    decay = 1 - ((year_prop - year_ex) / t) * gamma\n",
        "    return max(decay, 0.0)  # tidak boleh negatif\n",
        "\n",
        "# mapping Dosen dengan ID Dosen\n",
        "\n",
        "dosen_id_map = pd.read_csv(\"/content/drive/MyDrive/Skripsi3/Dataset/mapping.csv\")  # pastikan kolom: expert_id, expert_name\n",
        "dosen_id_map[\"expert_name\"] = dosen_id_map[\"expert_name\"].str.strip().str.lower()\n",
        "\n",
        "\n",
        "def explode_authors_with_weights(df, dosen_id_map):\n",
        "    rows = []\n",
        "\n",
        "    # Normalisasi nama dosen agar cocok\n",
        "    dosen_id_map = dosen_id_map.copy()\n",
        "    dosen_id_map[\"expert_name\"] = dosen_id_map[\"expert_name\"].str.strip().str.lower()\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        authors = row.get(\"authors\", [])\n",
        "        # Bersihkan nama kosong atau NaN\n",
        "        authors = [a for a in authors if isinstance(a, str) and a.strip() != \"\"]\n",
        "\n",
        "        num_authors = len(authors)\n",
        "        for idx, name in enumerate(authors):\n",
        "            name_clean = name.strip().lower()\n",
        "\n",
        "            if num_authors == 1:\n",
        "                weight = 1.0\n",
        "            else:\n",
        "                weight = 0.6 if idx == 0 else 0.4 / (num_authors - 1)\n",
        "\n",
        "            new_row = row.to_dict()\n",
        "            new_row[\"name\"] = name\n",
        "            new_row[\"author_position\"] = idx + 1\n",
        "            new_row[\"num_authors\"] = num_authors\n",
        "            new_row[\"author_weight\"] = round(weight, 4)\n",
        "\n",
        "            matched = dosen_id_map[dosen_id_map[\"expert_name\"] == name_clean]\n",
        "            new_row[\"expert_id\"] = matched[\"expert_id\"].values[0] if not matched.empty else None\n",
        "\n",
        "            rows.append(new_row)\n",
        "\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "# Gabungkan author_1 sampai author_6 jadi list\n",
        "author_cols = [\"author_1\", \"author_2\", \"author_3\", \"author_4\", \"author_5\", \"author_6\"]\n",
        "expert_df[\"authors\"] = expert_df[author_cols].values.tolist()\n",
        "\n",
        "# Hapus duplikat berdasarkan research_id\n",
        "expert_df = expert_df.drop_duplicates(subset=[\"research_id\"]).copy()\n",
        "\n",
        "# Jalankan explode\n",
        "expert_df = explode_authors_with_weights(expert_df, dosen_id_map)\n",
        "\n",
        "# Opsional: hanya simpan baris dengan expert_id valid\n",
        "expert_df = expert_df[expert_df[\"expert_id\"].notna()]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "collapsed": true,
        "id": "WOc8HgLHAzGS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8ae6296-bcd7-4c8a-b01a-e5427aa21048"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              topic_1   topic_2   topic_3   topic_4   topic_5   topic_6  \\\n",
            "research_id                                                               \n",
            "R1           0.005264  0.044919  0.005749  0.005661  0.159443  0.048705   \n",
            "R1           0.005264  0.044919  0.005749  0.005661  0.159443  0.048705   \n",
            "R2           0.006275  0.006679  0.344286  0.005781  0.006000  0.274839   \n",
            "R3           0.004788  0.004560  0.382559  0.004312  0.010355  0.004713   \n",
            "R3           0.004788  0.004560  0.382559  0.004312  0.010355  0.004713   \n",
            "\n",
            "              topic_7   topic_8   topic_9  topic_10  topic_11  topic_12  \\\n",
            "research_id                                                               \n",
            "R1           0.376329  0.005356  0.005144  0.297490  0.005534  0.005274   \n",
            "R1           0.376329  0.005356  0.005144  0.297490  0.005534  0.005274   \n",
            "R2           0.041040  0.134105  0.006468  0.006391  0.007006  0.006133   \n",
            "R3           0.546399  0.004910  0.005227  0.005206  0.005002  0.011567   \n",
            "R3           0.546399  0.004910  0.005227  0.005206  0.005002  0.011567   \n",
            "\n",
            "             topic_13  topic_14             name expert_id  \n",
            "research_id                                                 \n",
            "R1           0.005611  0.029520          Wiharto       D12  \n",
            "R1           0.005611  0.029520       Abdul Aziz        D5  \n",
            "R2           0.006814  0.148182       Abdul Aziz        D5  \n",
            "R3           0.005654  0.004749       Abdul Aziz        D5  \n",
            "R3           0.005654  0.004749  Bambang Harjito        D1  \n",
            "              topic_1   topic_2   topic_3   topic_4   topic_5   topic_6  \\\n",
            "research_id                                                               \n",
            "R1           0.005264  0.044919  0.005749  0.005661  0.159443  0.048705   \n",
            "R1           0.005264  0.044919  0.005749  0.005661  0.159443  0.048705   \n",
            "R2           0.006275  0.006679  0.344286  0.005781  0.006000  0.274839   \n",
            "R3           0.004788  0.004560  0.382559  0.004312  0.010355  0.004713   \n",
            "R3           0.004788  0.004560  0.382559  0.004312  0.010355  0.004713   \n",
            "...               ...       ...       ...       ...       ...       ...   \n",
            "R464         0.007189  0.008371  0.162188  0.007595  0.007124  0.008232   \n",
            "R464         0.007189  0.008371  0.162188  0.007595  0.007124  0.008232   \n",
            "R465         0.015919  0.506961  0.008327  0.010724  0.009715  0.008700   \n",
            "R466         0.009654  0.577703  0.009328  0.009430  0.055998  0.008599   \n",
            "R467         0.061120  0.005716  0.004869  0.004651  0.006086  0.004703   \n",
            "\n",
            "              topic_7   topic_8   topic_9  topic_10  topic_11  topic_12  \\\n",
            "research_id                                                               \n",
            "R1           0.376329  0.005356  0.005144  0.297490  0.005534  0.005274   \n",
            "R1           0.376329  0.005356  0.005144  0.297490  0.005534  0.005274   \n",
            "R2           0.041040  0.134105  0.006468  0.006391  0.007006  0.006133   \n",
            "R3           0.546399  0.004910  0.005227  0.005206  0.005002  0.011567   \n",
            "R3           0.546399  0.004910  0.005227  0.005206  0.005002  0.011567   \n",
            "...               ...       ...       ...       ...       ...       ...   \n",
            "R464         0.011052  0.008086  0.140938  0.440529  0.008203  0.007086   \n",
            "R464         0.011052  0.008086  0.140938  0.440529  0.008203  0.007086   \n",
            "R465         0.008295  0.062701  0.008496  0.009020  0.011397  0.103555   \n",
            "R466         0.007772  0.008125  0.007713  0.010960  0.103812  0.173408   \n",
            "R467         0.004438  0.005935  0.004608  0.005837  0.450375  0.138259   \n",
            "\n",
            "             topic_13  topic_14             name expert_id  \n",
            "research_id                                                 \n",
            "R1           0.005611  0.029520          Wiharto       D12  \n",
            "R1           0.005611  0.029520       Abdul Aziz        D5  \n",
            "R2           0.006814  0.148182       Abdul Aziz        D5  \n",
            "R3           0.005654  0.004749       Abdul Aziz        D5  \n",
            "R3           0.005654  0.004749  Bambang Harjito        D1  \n",
            "...               ...       ...              ...       ...  \n",
            "R464         0.176436  0.006972      Umi Salamah        D3  \n",
            "R464         0.176436  0.006972    Heri Prasetyo       D15  \n",
            "R465         0.008779  0.227410    Heri Prasetyo       D15  \n",
            "R466         0.007434  0.010065    Heri Prasetyo       D15  \n",
            "R467         0.298831  0.004572    Heri Prasetyo       D15  \n",
            "\n",
            "[760 rows x 16 columns]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "topic_matrix_expert = np.vstack(expert_df[\"topic_vector\"])\n",
        "topic_df = pd.DataFrame(\n",
        "    topic_matrix_expert,\n",
        "    columns=[f\"topic_{i+1}\" for i in range(lda_model.num_topics)]\n",
        ")\n",
        "\n",
        "topic_df[\"research_id\"] = expert_df[\"research_id\"].values\n",
        "topic_df[\"name\"] = expert_df[\"name\"].values\n",
        "topic_df[\"expert_id\"] = expert_df[\"expert_id\"].values\n",
        "\n",
        "# Set kolom id_dosen sebagai index\n",
        "topic_df.set_index(\"research_id\", inplace=True)\n",
        "# topic_df = topic_df[~topic_df.index.duplicated(keep=\"first\")]\n",
        "\n",
        "# (Opsional) Tampilkan 5 baris pertama untuk verifikasi\n",
        "print(topic_df.head())\n",
        "\n",
        "print(topic_df)\n",
        "# topic_df.to_csv('/content/drive/MyDrive/Skripsi4/dictionary/vektorExpert_14_baru.csv', index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Buat dataframe dari vektor topik dosen\n",
        "topic_matrix_expert = np.vstack(expert_df[\"topic_vector\"])\n",
        "topic_df = pd.DataFrame(topic_matrix_expert, columns=[f\"topic_{i+1}\" for i in range(topic_matrix_expert.shape[1])])\n",
        "\n",
        "# Gabungkan dengan nama dosen\n",
        "topic_df[\"name\"] = expert_df[\"name\"].values\n",
        "topic_df[\"research_id\"] = expert_df[\"research_id\"].values\n",
        "topic_df[\"expert_id\"] = expert_df[\"expert_id\"].values\n",
        "topic_df[\"author_position\"] = expert_df[\"author_position\"].values\n",
        "topic_df[\"author_weight\"] = expert_df[\"author_weight\"].values\n",
        "topic_df[\"pub_year\"] = expert_df[\"pub_year\"].values\n",
        "\n",
        "# Tambahkan kolom topik dominan\n",
        "topic_df[\"topik_dominan\"] = topic_df[[f\"topic_{i+1}\" for i in range(topic_matrix_expert.shape[1])]].idxmax(axis=1)\n",
        "topic_df[\"nilai_topik_dominan\"] = topic_df[[f\"topic_{i+1}\" for i in range(topic_matrix_expert.shape[1])]].max(axis=1)\n",
        "\n",
        "# Tampilkan contoh\n",
        "print(topic_df[[\"research_id\",\"pub_year\", \"expert_id\",\"name\",\"author_position\", \"author_weight\", \"topik_dominan\", \"nilai_topik_dominan\"]].head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmiy9Qyn-iPe",
        "outputId": "e85fccff-981a-4421-9fc6-b5e2513a114e"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  research_id  pub_year expert_id             name  author_position  \\\n",
            "0          R1      2015       D12          Wiharto                1   \n",
            "1          R1      2015        D5       Abdul Aziz                2   \n",
            "2          R2      2015        D5       Abdul Aziz                1   \n",
            "3          R3      2016        D5       Abdul Aziz                1   \n",
            "4          R3      2016        D1  Bambang Harjito                2   \n",
            "5          R4      2017        D5       Abdul Aziz                1   \n",
            "6          R4      2017        D8     Esti Suryani                2   \n",
            "7          R5      2018        D5       Abdul Aziz                1   \n",
            "8          R6      2018        D5       Abdul Aziz                1   \n",
            "9          R7      2018        D2          Wiranto                1   \n",
            "\n",
            "   author_weight topik_dominan  nilai_topik_dominan  \n",
            "0            0.6       topic_7             0.376329  \n",
            "1            0.4       topic_7             0.376329  \n",
            "2            1.0       topic_3             0.344286  \n",
            "3            0.6       topic_7             0.546399  \n",
            "4            0.4       topic_7             0.546399  \n",
            "5            0.6       topic_8             0.664380  \n",
            "6            0.4       topic_8             0.664380  \n",
            "7            1.0       topic_3             0.844152  \n",
            "8            1.0       topic_8             0.302608  \n",
            "9            0.6      topic_11             0.409660  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topik_label = {\n",
        "    \"topic_1\":  \"Pengolahan Citra dan Transformasi Digital\",\n",
        "    \"topic_2\":  \"Clustering Citra dan Ekstraksi Fitur\",\n",
        "    \"topic_3\":  \"Data Mining untuk E-Commerce dan Rekomendasi\",\n",
        "    \"topic_4\":  \"Deteksi dan Klasifikasi Penyakit dari Citra Medis\",\n",
        "    \"topic_5\":  \"Deep Learning CNN untuk Citra dan Segmentasi\",\n",
        "    \"topic_6\":  \"IoT dan Pemantauan Lingkungan Berbasis Sensor\",\n",
        "    \"topic_7\":  \"Diagnosis Penyakit Menggunakan Machine Learning\",\n",
        "    \"topic_8\":  \"Sistem Pendukung Keputusan dalam Dunia Pendidikan\",\n",
        "    \"topic_9\":  \"Analisis Sentimen dan Teks di Media Sosial\",\n",
        "    \"topic_10\": \"Klasifikasi Data Akademik dengan Metode Machine Learning\",\n",
        "    \"topic_11\": \"Pemrosesan Bahasa Alami dan Representasi Teks\",\n",
        "    \"topic_12\": \"Restorasi Citra dan Denoising dengan Deep Learning\",\n",
        "    \"topic_13\": \"Sistem Rekomendasi dan Klasifikasi Naive Bayes\",\n",
        "    \"topic_14\": \"Kriptografi, Keamanan Data, dan Enkripsi\"\n",
        "}\n",
        "\n",
        "topic_df[\"label_topik_dominan\"] = topic_df[\"topik_dominan\"].map(topik_label)\n",
        "print(topic_df[[\"research_id\",\"pub_year\", \"expert_id\",\"name\",\"author_position\", \"author_weight\", \"topik_dominan\", \"nilai_topik_dominan\"]].head(10))\n",
        "\n",
        "# topic_df.to_csv('/content/drive/MyDrive/Skripsi4/dictionary/labeltopik14.csv', index=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MrMYhYt-6ib",
        "outputId": "f2cbfa89-67e3-4b62-b7a9-236690025f4d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  research_id  pub_year expert_id             name  author_position  \\\n",
            "0          R1      2015       D12          Wiharto                1   \n",
            "1          R1      2015        D5       Abdul Aziz                2   \n",
            "2          R2      2015        D5       Abdul Aziz                1   \n",
            "3          R3      2016        D5       Abdul Aziz                1   \n",
            "4          R3      2016        D1  Bambang Harjito                2   \n",
            "5          R4      2017        D5       Abdul Aziz                1   \n",
            "6          R4      2017        D8     Esti Suryani                2   \n",
            "7          R5      2018        D5       Abdul Aziz                1   \n",
            "8          R6      2018        D5       Abdul Aziz                1   \n",
            "9          R7      2018        D2          Wiranto                1   \n",
            "\n",
            "   author_weight topik_dominan  nilai_topik_dominan  \n",
            "0            0.6       topic_7             0.376329  \n",
            "1            0.4       topic_7             0.376329  \n",
            "2            1.0       topic_3             0.344286  \n",
            "3            0.6       topic_7             0.546399  \n",
            "4            0.4       topic_7             0.546399  \n",
            "5            0.6       topic_8             0.664380  \n",
            "6            0.4       topic_8             0.664380  \n",
            "7            1.0       topic_3             0.844152  \n",
            "8            1.0       topic_8             0.302608  \n",
            "9            0.6      topic_11             0.409660  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Buat list nama kolom topik\n",
        "topic_cols = [f\"topic_{i+1}\" for i in range(topic_matrix_expert.shape[1])]\n",
        "\n",
        "# Ambil top-3 topik per baris\n",
        "top3_topics = topic_df[topic_cols].apply(lambda row: row.sort_values(ascending=False).index[:3].tolist(), axis=1)\n",
        "top3_values = topic_df[topic_cols].apply(lambda row: row.sort_values(ascending=False).values[:3].tolist(), axis=1)\n",
        "\n",
        "# Masukkan ke dataframe\n",
        "topic_df[\"topik_1\"] = top3_topics.str[0]\n",
        "topic_df[\"topik_2\"] = top3_topics.str[1]\n",
        "topic_df[\"topik_3\"] = top3_topics.str[2]\n",
        "\n",
        "topic_df[\"nilai_1\"] = top3_values.str[0]\n",
        "topic_df[\"nilai_2\"] = top3_values.str[1]\n",
        "topic_df[\"nilai_3\"] = top3_values.str[2]\n",
        "\n",
        "# Tambahkan labelnya dari topik_label\n",
        "topic_df[\"label_1\"] = topic_df[\"topik_1\"].map(topik_label)\n",
        "topic_df[\"label_2\"] = topic_df[\"topik_2\"].map(topik_label)\n",
        "topic_df[\"label_3\"] = topic_df[\"topik_3\"].map(topik_label)\n",
        "\n",
        "print(topic_df[[\n",
        "    \"name\", \"expert_id\",\n",
        "    \"topik_1\", \"nilai_1\", \"label_1\",\n",
        "    \"topik_2\", \"nilai_2\", \"label_2\",\n",
        "    \"topik_3\", \"nilai_3\", \"label_3\"\n",
        "]].head(10))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqI8CDAoMS0Y",
        "outputId": "64b274a7-b994-45fb-b1bd-b362506d7d11"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              name expert_id   topik_1   nilai_1  \\\n",
            "0          Wiharto       D12   topic_7  0.376329   \n",
            "1       Abdul Aziz        D5   topic_7  0.376329   \n",
            "2       Abdul Aziz        D5   topic_3  0.344286   \n",
            "3       Abdul Aziz        D5   topic_7  0.546399   \n",
            "4  Bambang Harjito        D1   topic_7  0.546399   \n",
            "5       Abdul Aziz        D5   topic_8  0.664380   \n",
            "6     Esti Suryani        D8   topic_8  0.664380   \n",
            "7       Abdul Aziz        D5   topic_3  0.844152   \n",
            "8       Abdul Aziz        D5   topic_8  0.302608   \n",
            "9          Wiranto        D2  topic_11  0.409660   \n",
            "\n",
            "                                             label_1   topik_2   nilai_2  \\\n",
            "0    Diagnosis Penyakit Menggunakan Machine Learning  topic_10  0.297490   \n",
            "1    Diagnosis Penyakit Menggunakan Machine Learning  topic_10  0.297490   \n",
            "2       Data Mining untuk E-Commerce dan Rekomendasi   topic_6  0.274839   \n",
            "3    Diagnosis Penyakit Menggunakan Machine Learning   topic_3  0.382559   \n",
            "4    Diagnosis Penyakit Menggunakan Machine Learning   topic_3  0.382559   \n",
            "5  Sistem Pendukung Keputusan dalam Dunia Pendidikan  topic_14  0.126645   \n",
            "6  Sistem Pendukung Keputusan dalam Dunia Pendidikan  topic_14  0.126645   \n",
            "7       Data Mining untuk E-Commerce dan Rekomendasi   topic_7  0.071210   \n",
            "8  Sistem Pendukung Keputusan dalam Dunia Pendidikan   topic_3  0.246787   \n",
            "9      Pemrosesan Bahasa Alami dan Representasi Teks   topic_3  0.210144   \n",
            "\n",
            "                                             label_2   topik_3   nilai_3  \\\n",
            "0  Klasifikasi Data Akademik dengan Metode Machin...   topic_5  0.159443   \n",
            "1  Klasifikasi Data Akademik dengan Metode Machin...   topic_5  0.159443   \n",
            "2      IoT dan Pemantauan Lingkungan Berbasis Sensor  topic_14  0.148182   \n",
            "3       Data Mining untuk E-Commerce dan Rekomendasi  topic_12  0.011567   \n",
            "4       Data Mining untuk E-Commerce dan Rekomendasi  topic_12  0.011567   \n",
            "5           Kriptografi, Keamanan Data, dan Enkripsi   topic_6  0.085052   \n",
            "6           Kriptografi, Keamanan Data, dan Enkripsi   topic_6  0.085052   \n",
            "7    Diagnosis Penyakit Menggunakan Machine Learning   topic_9  0.026365   \n",
            "8       Data Mining untuk E-Commerce dan Rekomendasi  topic_14  0.238001   \n",
            "9       Data Mining untuk E-Commerce dan Rekomendasi   topic_2  0.190508   \n",
            "\n",
            "                                             label_3  \n",
            "0       Deep Learning CNN untuk Citra dan Segmentasi  \n",
            "1       Deep Learning CNN untuk Citra dan Segmentasi  \n",
            "2           Kriptografi, Keamanan Data, dan Enkripsi  \n",
            "3  Restorasi Citra dan Denoising dengan Deep Lear...  \n",
            "4  Restorasi Citra dan Denoising dengan Deep Lear...  \n",
            "5      IoT dan Pemantauan Lingkungan Berbasis Sensor  \n",
            "6      IoT dan Pemantauan Lingkungan Berbasis Sensor  \n",
            "7         Analisis Sentimen dan Teks di Media Sosial  \n",
            "8           Kriptografi, Keamanan Data, dan Enkripsi  \n",
            "9               Clustering Citra dan Ekstraksi Fitur  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "4zhzx4doA_MN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd26a6cf-4e06-4caf-ea96-29f787dc5f25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              topic_1   topic_2   topic_3   topic_4   topic_5   topic_6  \\\n",
            "proposal_id                                                               \n",
            "P1           0.000580  0.000521  0.000403  0.001298  0.000521  0.000451   \n",
            "P10          0.000347  0.703296  0.089274  0.000321  0.000346  0.001877   \n",
            "P11          0.751460  0.000321  0.005268  0.000265  0.160344  0.000319   \n",
            "P12          0.037477  0.000466  0.000384  0.000409  0.069484  0.002810   \n",
            "P13          0.001201  0.000586  0.000490  0.000477  0.000512  0.000465   \n",
            "\n",
            "              topic_7   topic_8   topic_9  topic_10  topic_11  topic_12  \\\n",
            "proposal_id                                                               \n",
            "P1           0.000380  0.000501  0.000876  0.000609  0.010455  0.000578   \n",
            "P10          0.000502  0.130369  0.000378  0.000491  0.000416  0.000290   \n",
            "P11          0.000353  0.003129  0.000395  0.004616  0.000436  0.072385   \n",
            "P12          0.000346  0.000331  0.000339  0.000364  0.000427  0.886446   \n",
            "P13          0.000497  0.004814  0.000442  0.000476  0.261691  0.465200   \n",
            "\n",
            "             topic_13  topic_14  \n",
            "proposal_id                      \n",
            "P1           0.000542  0.982284  \n",
            "P10          0.071745  0.000349  \n",
            "P11          0.000367  0.000342  \n",
            "P12          0.000395  0.000321  \n",
            "P13          0.000488  0.262661  \n"
          ]
        }
      ],
      "source": [
        "topic_matrix_proposal = np.vstack(proposal_df[\"topic_vector\"])\n",
        "topic_proposal_df = pd.DataFrame(topic_matrix_proposal, columns=[f\"topic_{i+1}\" for i in range(lda_model.num_topics)])\n",
        "topic_proposal_df[\"proposal_id\"] = proposal_df[\"proposal_id\"].values\n",
        "\n",
        "# Set kolom id_dosen sebagai index\n",
        "topic_proposal_df.set_index(\"proposal_id\", inplace=True)\n",
        "print(topic_proposal_df.head())\n",
        "\n",
        "# print(topic_proposal_df)\n",
        "# topic_proposal_df.to_csv('/content/drive/MyDrive/Skripsi4/dictionary/vektorProposal_14_baru.csv', index=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Buat kolom topik dominan dan nilainya\n",
        "topic_proposal_df[\"topik_dominan\"] = topic_proposal_df[[f\"topic_{i+1}\" for i in range(lda_model.num_topics)]].idxmax(axis=1)\n",
        "topic_proposal_df[\"nilai_topik_dominan\"] = topic_proposal_df[[f\"topic_{i+1}\" for i in range(lda_model.num_topics)]].max(axis=1)\n",
        "topic_proposal_df[\"label_topik_dominan\"] = topic_proposal_df[\"topik_dominan\"].map(topik_label)\n",
        "print(topic_proposal_df.head())\n",
        "topic_proposal_df.to_csv('/content/drive/MyDrive/Skripsi4/dictionary/vektorProposal_topikdominan_14_baru.csv', index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_NGyNpCZ2Jg",
        "outputId": "11a1dc16-db5c-4a5c-c523-00b5d2ed8d48"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              topic_1   topic_2   topic_3   topic_4   topic_5   topic_6  \\\n",
            "proposal_id                                                               \n",
            "P1           0.000580  0.000521  0.000403  0.001298  0.000521  0.000451   \n",
            "P10          0.000347  0.703296  0.089274  0.000321  0.000346  0.001877   \n",
            "P11          0.751460  0.000321  0.005268  0.000265  0.160344  0.000319   \n",
            "P12          0.037477  0.000466  0.000384  0.000409  0.069484  0.002810   \n",
            "P13          0.001201  0.000586  0.000490  0.000477  0.000512  0.000465   \n",
            "\n",
            "              topic_7   topic_8   topic_9  topic_10  topic_11  topic_12  \\\n",
            "proposal_id                                                               \n",
            "P1           0.000380  0.000501  0.000876  0.000609  0.010455  0.000578   \n",
            "P10          0.000502  0.130369  0.000378  0.000491  0.000416  0.000290   \n",
            "P11          0.000353  0.003129  0.000395  0.004616  0.000436  0.072385   \n",
            "P12          0.000346  0.000331  0.000339  0.000364  0.000427  0.886446   \n",
            "P13          0.000497  0.004814  0.000442  0.000476  0.261691  0.465200   \n",
            "\n",
            "             topic_13  topic_14 topik_dominan  nilai_topik_dominan  \\\n",
            "proposal_id                                                          \n",
            "P1           0.000542  0.982284      topic_14             0.982284   \n",
            "P10          0.071745  0.000349       topic_2             0.703296   \n",
            "P11          0.000367  0.000342       topic_1             0.751460   \n",
            "P12          0.000395  0.000321      topic_12             0.886446   \n",
            "P13          0.000488  0.262661      topic_12             0.465200   \n",
            "\n",
            "                                           label_topik_dominan  \n",
            "proposal_id                                                     \n",
            "P1                    Kriptografi, Keamanan Data, dan Enkripsi  \n",
            "P10                       Clustering Citra dan Ekstraksi Fitur  \n",
            "P11                  Pengolahan Citra dan Transformasi Digital  \n",
            "P12          Restorasi Citra dan Denoising dengan Deep Lear...  \n",
            "P13          Restorasi Citra dan Denoising dengan Deep Lear...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kktZnb3TBCsE"
      },
      "source": [
        "# Kemiripan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pAGdpruELTI"
      },
      "source": [
        "## Directed M->D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "3BwQYxgFDHL6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76d732e5-75ed-418d-b0fc-ece0a013f4fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    id_proposal mahasiswa id_penelitian              dosen id_dosen  \\\n",
            "638          P1        S1          R392      Ristu Saptono       D6   \n",
            "297          P1        S1          R179      Heri Prasetyo      D15   \n",
            "295          P1        S1          R177      Heri Prasetyo      D15   \n",
            "323          P1        S1          R197  Hasan Dwi Cahyono      D13   \n",
            "741          P1        S1          R456    Bambang Harjito       D1   \n",
            "346          P1        S1          R209      Ristu Saptono       D6   \n",
            "411          P1        S1          R249      Ristu Saptono       D6   \n",
            "537          P1        S1          R341  Hasan Dwi Cahyono      D13   \n",
            "381          P1        S1          R232      Ristu Saptono       D6   \n",
            "56           P1        S1           R33    Bambang Harjito       D1   \n",
            "420          P1        S1          R253    Bambang Harjito       D1   \n",
            "53           P1        S1           R30     Afrizal Doewes      D10   \n",
            "753          P1        S1          R463    Bambang Harjito       D1   \n",
            "45           P1        S1           R26   Sari Widya Sihwi       D9   \n",
            "344          P1        S1          R207      Ristu Saptono       D6   \n",
            "243          P1        S1          R139      Ristu Saptono       D6   \n",
            "280          P1        S1          R166      Heri Prasetyo      D15   \n",
            "745          P1        S1          R459      Heri Prasetyo      D15   \n",
            "83           P1        S1           R48    Bambang Harjito       D1   \n",
            "507          P1        S1          R323     Wisnu Widiarto       D7   \n",
            "637          P1        S1          R391    Bambang Harjito       D1   \n",
            "73           P1        S1           R44    Bambang Harjito       D1   \n",
            "31           P1        S1           R18            Wiranto       D2   \n",
            "490          P1        S1          R308            Wiranto       D2   \n",
            "163          P1        S1           R97            Wiranto       D2   \n",
            "246          P1        S1          R141      Heri Prasetyo      D15   \n",
            "575          P1        S1          R363    Bambang Harjito       D1   \n",
            "742          P1        S1          R456      Heri Prasetyo      D15   \n",
            "412          P1        S1          R249    Haryono Setiadi      D14   \n",
            "58           P1        S1           R35    Bambang Harjito       D1   \n",
            "\n",
            "     posisi_author  author_weight  OD(M→D)  \n",
            "638              1            1.0   0.6667  \n",
            "297              1            1.0   0.5695  \n",
            "295              1            1.0   0.5664  \n",
            "323              1            0.6   0.5588  \n",
            "741              1            0.6   0.5156  \n",
            "346              1            1.0   0.5114  \n",
            "411              1            0.6   0.5092  \n",
            "537              1            0.6   0.4876  \n",
            "381              1            0.6   0.4801  \n",
            "56               1            1.0   0.4755  \n",
            "420              1            1.0   0.4526  \n",
            "53               1            1.0   0.4522  \n",
            "753              1            0.6   0.4484  \n",
            "45               1            0.6   0.4477  \n",
            "344              1            1.0   0.4271  \n",
            "243              1            0.6   0.4117  \n",
            "280              1            1.0   0.4053  \n",
            "745              1            1.0   0.3993  \n",
            "83               1            0.6   0.3902  \n",
            "507              1            1.0   0.3899  \n",
            "637              1            1.0   0.3740  \n",
            "73               1            1.0   0.3692  \n",
            "31               1            0.6   0.3667  \n",
            "490              1            0.6   0.3667  \n",
            "163              1            0.6   0.3600  \n",
            "246              1            1.0   0.3474  \n",
            "575              1            1.0   0.3451  \n",
            "742              2            0.4   0.3438  \n",
            "412              2            0.4   0.3394  \n",
            "58               1            0.6   0.3374  \n"
          ]
        }
      ],
      "source": [
        "def compute_od_m_to_d(proposals_df, experts_df):\n",
        "    all_results = []\n",
        "\n",
        "    for _, proposal in proposals_df.iterrows():\n",
        "        proposal_vector = proposal[\"topic_vector\"]\n",
        "        mahasiswa = proposal[\"student_id\"]\n",
        "        id_proposal = proposal[\"proposal_id\"]\n",
        "        tahun_proposal = proposal[\"tahun\"]\n",
        "\n",
        "        for _, expert in expert_df.iterrows():\n",
        "            expert_vector = expert[\"topic_vector\"]\n",
        "            dosen = expert[\"name\"]\n",
        "            id_dosen = expert[\"expert_id\"]\n",
        "            id_penelitian = expert[\"research_id\"]\n",
        "            tahun_penelitian = expert[\"pub_year\"]\n",
        "            weight = expert.get(\"author_weight\")\n",
        "            position= expert[\"author_position\"]\n",
        "\n",
        "            sim_mahasiswa = similarity_m_to_d(proposal_vector, expert_vector)\n",
        "            score = sim_mahasiswa * weight\n",
        "\n",
        "            all_results.append({\n",
        "                \"id_proposal\": id_proposal,\n",
        "                \"id_penelitian\": id_penelitian,\n",
        "                \"mahasiswa\": mahasiswa,\n",
        "                \"dosen\": dosen,\n",
        "                \"id_dosen\": id_dosen,\n",
        "                \"posisi_author\": position,\n",
        "                \"author_weight\":weight,\n",
        "                \"tahun_proposal\": tahun_proposal,\n",
        "                \"tahun_penelitian\": tahun_penelitian,\n",
        "                \"OD(M→D)\": round(score, 4)\n",
        "            })\n",
        "    df_scores = pd.DataFrame(all_results)\n",
        "    df_scores = df_scores.sort_values(by=[\"id_proposal\", \"OD(M→D)\"], ascending=[True, False])\n",
        "    return df_scores\n",
        "\n",
        "od_m2d_df = compute_od_m_to_d(proposal_df, expert_df)\n",
        "print(od_m2d_df[[\"id_proposal\", \"mahasiswa\",\"id_penelitian\",\"dosen\",\"id_dosen\",\"posisi_author\",\"author_weight\", \"OD(M→D)\"]].head(30))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5FkdQdcHvI2"
      },
      "source": [
        "## TOD M->D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "iUx5KCOsFSFm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21aba912-1e22-4b9f-f644-7af6663af3de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id_proposal mahasiswa id_penelitian             dosen id_dosen  OD(M→D)  \\\n",
            "6           P1        S1          R179     Heri Prasetyo      D15   0.5695   \n",
            "1           P1        S1           R30    Afrizal Doewes      D10   0.4522   \n",
            "12          P1        S1          R249     Ristu Saptono       D6   0.5092   \n",
            "15          P1        S1           R26  Sari Widya Sihwi       D9   0.4477   \n",
            "0           P1        S1           R48   Bambang Harjito       D1   0.3902   \n",
            "5           P1        S1          R249   Haryono Setiadi      D14   0.3394   \n",
            "8           P1        S1           R97           Wiranto       D2   0.3600   \n",
            "2           P1        S1          R273           Winarno      D11   0.2452   \n",
            "14          P1        S1           R48      Esti Suryani       D8   0.2602   \n",
            "11          P1        S1            R6        Abdul Aziz       D5   0.2391   \n",
            "\n",
            "    tahun_proposal  tahun_penelitian  selisih_tahun  time_decay_factor  \\\n",
            "6             2021              2020              1                0.9   \n",
            "1             2021              2021              0                1.0   \n",
            "12            2021              2019              2                0.8   \n",
            "15            2021              2018              3                0.7   \n",
            "0             2021              2018              3                0.7   \n",
            "5             2021              2019              2                0.8   \n",
            "8             2021              2018              3                0.7   \n",
            "2             2021              2020              1                0.9   \n",
            "14            2021              2018              3                0.7   \n",
            "11            2021              2018              3                0.7   \n",
            "\n",
            "    TOD(M→D)  \n",
            "6     0.5126  \n",
            "1     0.4522  \n",
            "12    0.4074  \n",
            "15    0.3134  \n",
            "0     0.2731  \n",
            "5     0.2715  \n",
            "8     0.2520  \n",
            "2     0.2207  \n",
            "14    0.1821  \n",
            "11    0.1674  \n"
          ]
        }
      ],
      "source": [
        "# Hitung TOD(M→D)\n",
        "def compute_tod_m_to_d(od_df, t=1, gamma=0.1, max_year_diff=5):\n",
        "    od_df = od_df.copy()\n",
        "\n",
        "    # Hitung selisih tahun\n",
        "    od_df[\"selisih_tahun\"] = od_df[\"tahun_proposal\"] - od_df[\"tahun_penelitian\"]\n",
        "\n",
        "    # Filter: proposal harus lebih baru dari publikasi, dan selisih maksimal 5 tahun\n",
        "    od_df = od_df[(od_df[\"selisih_tahun\"] >= 0) & (od_df[\"selisih_tahun\"] <= max_year_diff)].copy()\n",
        "\n",
        "    # Hitung time decay factor\n",
        "    od_df[\"time_decay_factor\"] = od_df.apply(\n",
        "        lambda row: time_decay(row[\"tahun_proposal\"], row[\"tahun_penelitian\"], t=t, gamma=gamma),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # Hitung TOD(M→D)\n",
        "    od_df[\"TOD(M→D)\"] = (od_df[\"OD(M→D)\"] * od_df[\"time_decay_factor\"]).round(4)\n",
        "\n",
        "    return od_df\n",
        "\n",
        "tod_m2d_df= compute_tod_m_to_d(od_m2d_df, t=1, gamma=0.1, max_year_diff=5)\n",
        "\n",
        "tod_m2d_df = (\n",
        "    tod_m2d_df\n",
        "    .loc[tod_m2d_df.groupby([\"id_proposal\", \"id_dosen\"])[\"TOD(M→D)\"].idxmax()]\n",
        "    .reset_index(drop=True)\n",
        "    .sort_values(by=[\"id_proposal\", \"TOD(M→D)\"], ascending=[True, False])\n",
        ")\n",
        "\n",
        "print(tod_m2d_df[[\"id_proposal\",\"mahasiswa\", \"id_penelitian\",\"dosen\",\"id_dosen\", \"OD(M→D)\", \"tahun_proposal\",\"tahun_penelitian\",\"selisih_tahun\", \"time_decay_factor\", \"TOD(M→D)\"]].head(10))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXJRYVfCIx5Z"
      },
      "source": [
        "# OD D->M"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "Ql8l9N2zYCoS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa1c09fd-9582-474d-e940-0a9b13237877"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     id_proposal mahasiswa id_penelitian            dosen id_dosen  \\\n",
            "878          P20       S20           R49  Bambang Harjito       D1   \n",
            "973          P26       S26           R49  Bambang Harjito       D1   \n",
            "597         P132      S132           R36  Bambang Harjito       D1   \n",
            "216         P110      S110           R49  Bambang Harjito       D1   \n",
            "455         P124      S124           R44  Bambang Harjito       D1   \n",
            "1205          P4        S4           R44  Bambang Harjito       D1   \n",
            "1516         P58       S58           R44  Bambang Harjito       D1   \n",
            "1531         P59       S59           R49  Bambang Harjito       D1   \n",
            "1454         P54       S54           R49  Bambang Harjito       D1   \n",
            "0             P1        S1           R44  Bambang Harjito       D1   \n",
            "\n",
            "      posisi_author  author_weight  OD(D→M)  \n",
            "878               1            1.0   0.8469  \n",
            "973               1            1.0   0.8251  \n",
            "597               1            1.0   0.7955  \n",
            "216               1            1.0   0.7745  \n",
            "455               1            1.0   0.7383  \n",
            "1205              1            1.0   0.7201  \n",
            "1516              1            1.0   0.7033  \n",
            "1531              1            1.0   0.6879  \n",
            "1454              1            1.0   0.6630  \n",
            "0                 1            1.0   0.6390  \n"
          ]
        }
      ],
      "source": [
        "def compute_od_d_to_m(proposals_df, experts_df):\n",
        "    results = []\n",
        "\n",
        "    for _, expert in experts_df.iterrows():\n",
        "        expert_vector = expert[\"topic_vector\"]\n",
        "        dosen = expert[\"name\"]\n",
        "        id_dosen = expert[\"expert_id\"]\n",
        "        id_penelitian = expert[\"research_id\"]\n",
        "        weight = expert[\"author_weight\"]\n",
        "        position = expert[\"author_position\"]\n",
        "        tahun_penelitian = expert[\"pub_year\"]\n",
        "\n",
        "        for _, proposal in proposals_df.iterrows():\n",
        "            proposal_vector = proposal[\"topic_vector\"]\n",
        "            mahasiswa = proposal[\"student_id\"]\n",
        "            id_proposal = proposal[\"proposal_id\"]\n",
        "            tahun_proposal = proposal[\"tahun\"]\n",
        "\n",
        "            # # Tambahkan filter tahun\n",
        "            selisih_tahun = tahun_proposal - tahun_penelitian\n",
        "            if 0 < selisih_tahun <= 5 and tahun_penelitian <= tahun_proposal:\n",
        "               sim_dosen = similarity_d_to_m(expert_vector, proposal_vector)\n",
        "               score = sim_dosen * weight\n",
        "               results.append({\n",
        "                    \"id_proposal\": id_proposal,\n",
        "                    \"id_penelitian\": id_penelitian,\n",
        "                    \"mahasiswa\": mahasiswa,\n",
        "                    \"dosen\": dosen,\n",
        "                    \"id_dosen\": id_dosen,\n",
        "                    \"posisi_author\": position,\n",
        "                    \"author_weight\": weight,\n",
        "                    \"tahun_proposal\": tahun_proposal,\n",
        "                    \"tahun_penelitian\": tahun_penelitian,\n",
        "                    \"OD(D→M)\": round(score, 4),\n",
        "                })\n",
        "\n",
        "    df_scores = pd.DataFrame(results)\n",
        "    df_scores = df_scores.loc[df_scores.groupby([\"id_proposal\",\"id_dosen\"])[\"OD(D→M)\"].idxmax()].reset_index(drop=True)\n",
        "    df_scores = df_scores.sort_values(by=[\"id_dosen\", \"OD(D→M)\"], ascending=[True, False])\n",
        "\n",
        "    return df_scores\n",
        "od_d2m_df = compute_od_d_to_m(proposal_df, expert_df)\n",
        "print(od_d2m_df[[\"id_proposal\", \"mahasiswa\",\"id_penelitian\", \"dosen\", \"id_dosen\",\"posisi_author\",\"author_weight\",\"OD(D→M)\"]].head(10))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLs6cYz8NWTv"
      },
      "source": [
        "# Overlap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "iCttVVnEsjV7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c2d72fa-6bc2-47a4-d69d-d0deb73868c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id_proposal mahasiswa             dosen id_dosen  TOD(M→D)  OD(D→M)  \\\n",
            "6           P1        S1     Heri Prasetyo      D15    0.5126   0.9350   \n",
            "12          P1        S1     Ristu Saptono       D6    0.4074   0.9604   \n",
            "1           P1        S1    Afrizal Doewes      D10    0.4522   0.5245   \n",
            "0           P1        S1   Bambang Harjito       D1    0.2731   0.6390   \n",
            "15          P1        S1  Sari Widya Sihwi       D9    0.3134   0.5740   \n",
            "5           P1        S1   Haryono Setiadi      D14    0.2715   0.5801   \n",
            "8           P1        S1           Wiranto       D2    0.2520   0.5523   \n",
            "11          P1        S1        Abdul Aziz       D5    0.1674   0.4951   \n",
            "2           P1        S1           Winarno      D11    0.2207   0.4240   \n",
            "14          P1        S1      Esti Suryani       D8    0.1821   0.3695   \n",
            "\n",
            "    skor_rata2  overlap  \n",
            "6      0.72380     True  \n",
            "12     0.68390     True  \n",
            "1      0.48835     True  \n",
            "0      0.45605     True  \n",
            "15     0.44370     True  \n",
            "5      0.42580     True  \n",
            "8      0.40215     True  \n",
            "11     0.33125     True  \n",
            "2      0.32235     True  \n",
            "14     0.27580     True  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def combine_overlap_scores(df_m2d, df_d2m):\n",
        "    # Ambil semua kolom yang dibutuhkan dari masing-masing arah\n",
        "    top_m2d = df_m2d[[\"id_proposal\", \"mahasiswa\", \"id_dosen\", \"dosen\", \"TOD(M→D)\"]]\n",
        "    top_d2m = df_d2m[[\"id_proposal\", \"mahasiswa\", \"id_dosen\", \"dosen\", \"OD(D→M)\"]]\n",
        "\n",
        "    # Gabungkan kedua dataframe berdasarkan id_proposal dan id_dosen\n",
        "    merged = pd.merge(top_m2d, top_d2m, on=[\"id_proposal\", \"id_dosen\"], how=\"outer\", suffixes=('_m2d', '_d2m'))\n",
        "\n",
        "    # Gabungkan kolom nama mahasiswa dan dosen (dari salah satu sisi)\n",
        "    merged[\"mahasiswa\"] = merged[\"mahasiswa_m2d\"].combine_first(merged[\"mahasiswa_d2m\"])\n",
        "    merged[\"dosen\"] = merged[\"dosen_m2d\"].combine_first(merged[\"dosen_d2m\"])\n",
        "\n",
        "    # Ganti NaN skor dengan 0\n",
        "    merged[\"TOD(M→D)\"] = merged[\"TOD(M→D)\"].fillna(0)\n",
        "    merged[\"OD(D→M)\"] = merged[\"OD(D→M)\"].fillna(0)\n",
        "\n",
        "    # Tandai overlap jika skor dari dua arah ada (lebih dari 0)\n",
        "    merged[\"overlap\"] = (merged[\"TOD(M→D)\"] > 0) & (merged[\"OD(D→M)\"] > 0)\n",
        "\n",
        "    # Hitung skor rata-rata hanya jika overlap, jika tidak maka 0\n",
        "    merged[\"skor_rata2\"] = merged.apply(\n",
        "        lambda row: (row[\"TOD(M→D)\"] + row[\"OD(D→M)\"]) / 2 if row[\"overlap\"] else 0, axis=1\n",
        "    )\n",
        "\n",
        "    # Urutkan berdasarkan skor rata-rata tertinggi untuk setiap proposal\n",
        "    final_scores = merged.sort_values(by=[\"id_proposal\", \"skor_rata2\"], ascending=[True, False])\n",
        "\n",
        "    # Pilih kolom akhir yang relevan\n",
        "    final_scores = final_scores[[\n",
        "        \"id_proposal\", \"mahasiswa\", \"dosen\", \"id_dosen\",\n",
        "        \"TOD(M→D)\", \"OD(D→M)\", \"skor_rata2\", \"overlap\"\n",
        "    ]]\n",
        "\n",
        "    return final_scores\n",
        "\n",
        "# Contoh penggunaan:\n",
        "df_final = combine_overlap_scores(tod_m2d_df, od_d2m_df)\n",
        "print(df_final.head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65wj7aCgNlf3"
      },
      "source": [
        "# Ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "GsIetvPuNaPV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93a5bbd8-dfee-4dd3-d564-61debc335753"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id_proposal mahasiswa               dosen id_dosen  TOD(M→D)  OD(D→M)  \\\n",
            "6           P1        S1       Heri Prasetyo      D15    0.5126   0.9350   \n",
            "12          P1        S1       Ristu Saptono       D6    0.4074   0.9604   \n",
            "1           P1        S1      Afrizal Doewes      D10    0.4522   0.5245   \n",
            "0           P1        S1     Bambang Harjito       D1    0.2731   0.6390   \n",
            "15          P1        S1    Sari Widya Sihwi       D9    0.3134   0.5740   \n",
            "5           P1        S1     Haryono Setiadi      D14    0.2715   0.5801   \n",
            "8           P1        S1             Wiranto       D2    0.2520   0.5523   \n",
            "11          P1        S1          Abdul Aziz       D5    0.1674   0.4951   \n",
            "2           P1        S1             Winarno      D11    0.2207   0.4240   \n",
            "14          P1        S1        Esti Suryani       D8    0.1821   0.3695   \n",
            "13          P1        S1      Wisnu Widiarto       D7    0.0915   0.2646   \n",
            "10          P1        S1  Dewi Wisnu Wardani       D4    0.1215   0.1925   \n",
            "3           P1        S1             Wiharto      D12    0.0709   0.1141   \n",
            "7           P1        S1     Ardhi Wijayanto      D16    0.0553   0.1166   \n",
            "9           P1        S1         Umi Salamah       D3    0.0143   0.0224   \n",
            "4           P1        S1   Hasan Dwi Cahyono      D13    0.0058   0.0218   \n",
            "22         P10       S10       Heri Prasetyo      D15    0.7485   0.7052   \n",
            "29         P10       S10      Wisnu Widiarto       D7    0.3078   0.6564   \n",
            "16         P10       S10     Bambang Harjito       D1    0.2996   0.4220   \n",
            "21         P10       S10     Haryono Setiadi      D14    0.2699   0.4330   \n",
            "\n",
            "    skor_rata2  overlap  rank  \n",
            "6      0.72380     True     1  \n",
            "12     0.68390     True     2  \n",
            "1      0.48835     True     3  \n",
            "0      0.45605     True     4  \n",
            "15     0.44370     True     5  \n",
            "5      0.42580     True     6  \n",
            "8      0.40215     True     7  \n",
            "11     0.33125     True     8  \n",
            "2      0.32235     True     9  \n",
            "14     0.27580     True    10  \n",
            "13     0.17805     True    11  \n",
            "10     0.15700     True    12  \n",
            "3      0.09250     True    13  \n",
            "7      0.08595     True    14  \n",
            "9      0.01835     True    15  \n",
            "4      0.01380     True    16  \n",
            "22     0.72685     True     1  \n",
            "29     0.48210     True     2  \n",
            "16     0.36080     True     3  \n",
            "21     0.35145     True     4  \n"
          ]
        }
      ],
      "source": [
        "def combine_overlap_scores_with_ranking(df_m2d, df_d2m):\n",
        "    # Ambil semua skor dari kedua arah\n",
        "    m2d = df_m2d[[\"id_proposal\", \"id_dosen\",\"mahasiswa\", \"dosen\", \"TOD(M→D)\"]]\n",
        "    d2m = df_d2m[[\"id_proposal\",\"id_dosen\",\"mahasiswa\",\"dosen\", \"OD(D→M)\"]]\n",
        "\n",
        "    # Outer join agar semua kombinasi muncul\n",
        "    merged = pd.merge(m2d, d2m, on=[\"id_proposal\", \"id_dosen\"], how=\"outer\")\n",
        "\n",
        "    # Tambahkan kolom nama dosen jika hilang (dari M→D arah saja)\n",
        "    if \"dosen_x\" in merged.columns:\n",
        "        merged[\"dosen\"] = merged[\"dosen_x\"].combine_first(merged.get(\"dosen_y\"))\n",
        "    elif \"dosen\" not in merged.columns:\n",
        "        merged[\"dosen\"] = None\n",
        "\n",
        "    if \"mahasiswa_x\" in merged.columns:\n",
        "        merged[\"mahasiswa\"] = merged[\"mahasiswa_x\"].combine_first(merged.get(\"mahasiswa_y\"))\n",
        "    elif \"mahasiswa\" not in merged.columns:\n",
        "        merged[\"mahasiswa\"] = None\n",
        "\n",
        "    # Isi nilai NaN dengan 0 untuk penggabungan skor\n",
        "    merged[\"TOD(M→D)\"] = merged[\"TOD(M→D)\"].fillna(0)\n",
        "    merged[\"OD(D→M)\"] = merged[\"OD(D→M)\"].fillna(0)\n",
        "\n",
        "    # Overlap = muncul di kedua arah\n",
        "    merged[\"overlap\"] = (merged[\"TOD(M→D)\"] > 0) & (merged[\"OD(D→M)\"] > 0)\n",
        "\n",
        "    # Skor rata-rata jika overlap\n",
        "    merged[\"skor_rata2\"] = merged.apply(\n",
        "        lambda row: (row[\"TOD(M→D)\"] + row[\"OD(D→M)\"]) / 2 if row[\"overlap\"] else 0, axis=1\n",
        "    )\n",
        "\n",
        "       # Hitung ranking per proposal berdasarkan skor rata-rata (tanpa groupby + agg)\n",
        "    merged[\"rank\"] = merged.groupby(\"id_proposal\")[\"skor_rata2\"]\\\n",
        "                           .rank(ascending=False, method=\"dense\")\\\n",
        "                           .astype(int)\n",
        "\n",
        "    # Ambil kolom yang diinginkan dan urutkan\n",
        "    result = merged.sort_values(by=[\"id_proposal\", \"rank\"])[\n",
        "        [\"id_proposal\",\"mahasiswa\", \"dosen\", \"id_dosen\", \"TOD(M→D)\", \"OD(D→M)\", \"skor_rata2\", \"overlap\", \"rank\"]\n",
        "    ]\n",
        "\n",
        "\n",
        "    return result.sort_values(by=[\"id_proposal\", \"rank\"])[\n",
        "        [\"id_proposal\",\"mahasiswa\", \"dosen\", \"id_dosen\", \"TOD(M→D)\", \"OD(D→M)\", \"skor_rata2\", \"overlap\", \"rank\"]\n",
        "    ]\n",
        "\n",
        "\n",
        "df_peringkat = combine_overlap_scores_with_ranking(tod_m2d_df, od_d2m_df)\n",
        "# Filter hanya yang overlap == True\n",
        "df_overlap_true = df_peringkat[df_peringkat[\"overlap\"] == True]\n",
        "print(df_overlap_true.head(20))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "-CyWBkN1Nohe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f643c72-d1c4-4721-d399-b5692db8b439"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     id_proposal mahasiswa               dosen id_dosen  TOD(M→D)  OD(D→M)  \\\n",
            "0             P1        S1       Heri Prasetyo      D15    0.5126   0.9350   \n",
            "142           P1        S1       Ristu Saptono       D6    0.4074   0.9604   \n",
            "143           P1        S1      Afrizal Doewes      D10    0.4522   0.5245   \n",
            "144           P1        S1     Bambang Harjito       D1    0.2731   0.6390   \n",
            "145           P1        S1    Sari Widya Sihwi       D9    0.3134   0.5740   \n",
            "...          ...       ...                 ...      ...       ...      ...   \n",
            "2243         P99       S99       Heri Prasetyo      D15    0.0754   0.2336   \n",
            "2244         P99       S99  Dewi Wisnu Wardani       D4    0.1322   0.1256   \n",
            "2245         P99       S99         Umi Salamah       D3    0.0848   0.1545   \n",
            "2246         P99       S99      Wisnu Widiarto       D7    0.0818   0.1562   \n",
            "2247         P99       S99      Afrizal Doewes      D10    0.0598   0.1214   \n",
            "\n",
            "      skor_rata2  overlap  rank  beban  \n",
            "0        0.72380     True     1      1  \n",
            "142      0.68390     True     2     15  \n",
            "143      0.48835     True     3      3  \n",
            "144      0.45605     True     4      9  \n",
            "145      0.44370     True     5     15  \n",
            "...          ...      ...   ...    ...  \n",
            "2243     0.15450     True    12     15  \n",
            "2244     0.12890     True    13     15  \n",
            "2245     0.11965     True    14     15  \n",
            "2246     0.11900     True    15     15  \n",
            "2247     0.09060     True    16      3  \n",
            "\n",
            "[2248 rows x 10 columns]\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "# 1. Inisialisasi count untuk rank 1\n",
        "rank1_count_directed = defaultdict(int)\n",
        "final_assignment_directed = []\n",
        "\n",
        "# 2. Tetapkan rank 1 dengan batas 15 kali per dosen\n",
        "for pid in df_overlap_true[\"id_proposal\"].unique():\n",
        "    candidates = df_overlap_true[df_overlap_true[\"id_proposal\"] == pid]\n",
        "    candidates = candidates.sort_values(by=\"skor_rata2\", ascending=False)\n",
        "\n",
        "    assigned_rank1 = False\n",
        "    for _, row in candidates.iterrows():\n",
        "        dosen_id = row[\"id_dosen\"]\n",
        "        if rank1_count_directed[dosen_id] < 15:\n",
        "            rank1_count_directed[dosen_id] += 1\n",
        "            row_data = row.to_dict()\n",
        "            row_data[\"rank\"] = 1\n",
        "            row_data[\"beban\"] = rank1_count_directed[dosen_id]\n",
        "            final_assignment_directed.append(row_data)\n",
        "            assigned_rank1 = True\n",
        "            break\n",
        "\n",
        "    if not assigned_rank1:\n",
        "        row = candidates.iloc[0].to_dict()\n",
        "        dosen_id = row[\"id_dosen\"]\n",
        "        rank1_count_directed[dosen_id] += 1\n",
        "        row[\"rank\"] = 1\n",
        "        row[\"beban\"] = rank1_count_directed[dosen_id]\n",
        "        final_assignment_directed.append(row)\n",
        "\n",
        "# 3. Buat dataframe dari rank 1\n",
        "rank1_directed = pd.DataFrame(final_assignment_directed)\n",
        "\n",
        "# 4. Tambahkan rank 2–17 berdasarkan similarity, excl. dosen yang sudah dipakai di rank 1 untuk proposal yang sama\n",
        "other_ranks = []\n",
        "\n",
        "for pid in df_overlap_true[\"id_proposal\"].unique():\n",
        "    # Dapatkan dosen yang sudah dipakai sebagai rank 1\n",
        "    used_dosen = rank1_directed[rank1_directed[\"id_proposal\"] == pid][\"id_dosen\"].tolist()\n",
        "\n",
        "    # Ambil kandidat lain untuk proposal ini\n",
        "    candidates = df_overlap_true[(df_overlap_true[\"id_proposal\"] == pid) & (~df_overlap_true[\"id_dosen\"].isin(used_dosen))]\n",
        "    candidates = candidates.sort_values(by=\"skor_rata2\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "    for idx, (_, row) in enumerate(candidates.iterrows(), start=2):\n",
        "        if idx > 17:\n",
        "            break\n",
        "        row_data = row.to_dict()\n",
        "        row_data[\"rank\"] = idx\n",
        "        row_data[\"beban\"] = rank1_count_directed[row_data[\"id_dosen\"]]  # Beban hanya dihitung dari rank 1\n",
        "        other_ranks.append(row_data)\n",
        "\n",
        "# 5. Gabungkan rank1 dan other ranks\n",
        "df_ranked_filtered = pd.concat([rank1_directed, pd.DataFrame(other_ranks)], ignore_index=True)\n",
        "df_ranked_filtered = df_ranked_filtered.sort_values(by=[\"id_proposal\", \"rank\"])\n",
        "\n",
        "# 🔟 Filter hanya Top 10 dosen per proposal\n",
        "df_ranked_filtered = df_ranked_filtered[df_ranked_filtered[\"rank\"] <= 17]\n",
        "print(df_ranked_filtered)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GY5LgnXwOAoi"
      },
      "source": [
        "# Evaluasi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "LWMQJ-jIOM6q"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "# Load the true labels DataFrame\n",
        "true_label_df = pd.read_csv(\"/content/drive/MyDrive/Skripsi3/Dataset/true_labels.csv\")\n",
        "\n",
        "# Ubah kolom author, author2, author3 menjadi lowercase\n",
        "true_label_df[\"author1\"] = true_label_df[\"examiner_1\"].astype(str).str.strip()\n",
        "true_label_df[\"author2\"] = true_label_df[\"examiner_2\"].astype(str).str.strip()\n",
        "true_label_df[\"author3\"] = true_label_df[\"examiner_3\"].astype(str).str.strip()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISliac_wWuZb"
      },
      "source": [
        "coba"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skG7yYjbKUlO"
      },
      "source": [
        "## Evaluasi Baru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "Ks2XbNJ-Wt_2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "839fe5a9-bf25-4eed-b742-0e45f679473d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Top-N  Mean_Recall_Existence  Recall_Pos_1_Ordered  Recall_Pos_2_Ordered  \\\n",
            "0      3               0.302817               0.34507              0.056338   \n",
            "1      5               0.443662               0.34507              0.056338   \n",
            "2      7               0.605634               0.34507              0.056338   \n",
            "3     10               0.774648               0.34507              0.056338   \n",
            "\n",
            "   Recall_Pos_3_Ordered  Avg_Normalized_Euclidean  \n",
            "0              0.091549                  0.842481  \n",
            "1              0.091549                  0.757989  \n",
            "2              0.091549                  0.668262  \n",
            "3              0.091549                  0.551565  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def evaluate_ordered_recommendation_directed(rank_all_df, true_label_df, top_ns=[3, 5, 7, 10]):\n",
        "    summary = []\n",
        "\n",
        "    for TOP_N in top_ns:\n",
        "        # Filter Top-N dan urutkan\n",
        "        top_n_df = rank_all_df[rank_all_df[\"rank\"] <= TOP_N]\n",
        "        rec_df = top_n_df.sort_values(by=[\"id_proposal\", \"rank\", \"skor_rata2\"], ascending=[True, True, False])\n",
        "        rec_df = rec_df.drop_duplicates(subset=[\"id_proposal\", \"rank\",\"skor_rata2\"])\n",
        "        rec_pivot = rec_df.pivot(index=\"id_proposal\", columns=\"rank\", values=\"dosen\").reset_index()\n",
        "        rec_pivot.columns.name = None\n",
        "        rec_pivot.columns = [\"id_proposal\"] + [f\"rec_{i}\" for i in range(1, len(rec_pivot.columns))]\n",
        "\n",
        "        # Gabungkan dengan ground truth\n",
        "        merged_df = pd.merge(\n",
        "            rec_pivot,\n",
        "            true_label_df.rename(columns={\"proposal_id\": \"id_proposal\"}),\n",
        "            on=\"id_proposal\",\n",
        "            how=\"left\"\n",
        "        )\n",
        "\n",
        "        # Recall keberadaan (tidak memperhatikan urutan)\n",
        "        def recall_of_existence(row):\n",
        "            true_set = {row.get(\"author1\"), row.get(\"author2\"), row.get(\"author3\")}\n",
        "            pred_set = {row.get(f\"rec_{i}\") for i in range(1, TOP_N + 1) if row.get(f\"rec_{i}\")}\n",
        "            return len(true_set.intersection(pred_set)) / 3\n",
        "\n",
        "        merged_df[f'recall_of_existence@{TOP_N}'] = merged_df.apply(recall_of_existence, axis=1)\n",
        "\n",
        "        # Recall per posisi dengan urutan diperhatikan (rec_i harus sama dengan author_i)\n",
        "        recall_pos = {1: [], 2: [], 3: []}\n",
        "        for _, row in merged_df.iterrows():\n",
        "            for pos in [1, 2, 3]:\n",
        "                examiner = row.get(f'author{pos}')\n",
        "                rec = row.get(f'rec_{pos}') if pos <= TOP_N else None\n",
        "                hit = int(pd.notna(examiner) and pd.notna(rec) and examiner == rec)\n",
        "                recall_pos[pos].append(hit)\n",
        "\n",
        "        # Tambahkan recall ke DataFrame\n",
        "        for pos in [1, 2, 3]:\n",
        "            merged_df[f'recall_pos{pos}_ordered@{TOP_N}'] = recall_pos[pos]\n",
        "\n",
        "        recall_pos_mean = {pos: np.mean(recall_pos[pos]) for pos in [1, 2, 3]}\n",
        "\n",
        "        # Euclidean distance antar posisi (penalti posisi meleset)\n",
        "        distances = []\n",
        "        for _, row in merged_df.iterrows():\n",
        "            true_authors = [row.get(f'author{i}') for i in [1, 2, 3]]\n",
        "            pred_authors = [row.get(f'rec_{i}', None) for i in range(1, TOP_N + 1)]\n",
        "            distance = 0\n",
        "            max_penalty = TOP_N\n",
        "            for i, true_author in enumerate(true_authors):\n",
        "                if pd.isna(true_author) or true_author == '':\n",
        "                    continue\n",
        "                try:\n",
        "                    pred_pos = pred_authors.index(true_author)\n",
        "                    pos_diff = pred_pos - i\n",
        "                    distance += pos_diff ** 2\n",
        "                except ValueError:\n",
        "                    distance += max_penalty ** 2\n",
        "            distances.append(np.sqrt(distance))\n",
        "\n",
        "        scaler = MinMaxScaler()\n",
        "        norm_dists = scaler.fit_transform(np.array(distances).reshape(-1, 1)).flatten()\n",
        "        merged_df[f'norm_euclidean@{TOP_N}'] = norm_dists\n",
        "\n",
        "        # Ringkasan metrik\n",
        "        summary.append({\n",
        "            'Top-N': TOP_N,\n",
        "            'Mean_Recall_Existence': merged_df[f'recall_of_existence@{TOP_N}'].mean(),\n",
        "            'Recall_Pos_1_Ordered': recall_pos_mean[1],\n",
        "            'Recall_Pos_2_Ordered': recall_pos_mean[2],\n",
        "            'Recall_Pos_3_Ordered': recall_pos_mean[3],\n",
        "            'Avg_Normalized_Euclidean': np.mean(norm_dists)\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(summary)\n",
        "\n",
        "result_df_directed = evaluate_ordered_recommendation_directed(df_overlap_true, true_label_df)\n",
        "print(result_df_directed)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YrQO7Qbasqb"
      },
      "source": [
        "## Evaluasi per proposal Baru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "j7h0LFgnasJe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def evaluate_per_proposal_directed(rank_all_df, true_label_df, top_n=3):\n",
        "    # Filter dan urutkan\n",
        "    top_n_df = rank_all_df[rank_all_df[\"rank\"] <= top_n]\n",
        "    rec_df = top_n_df.sort_values(by=[\"id_proposal\", \"rank\", \"skor_rata2\"], ascending=[True, True, False])\n",
        "    rec_df = rec_df.drop_duplicates(subset=[\"id_proposal\", \"rank\",\"skor_rata2\"])\n",
        "    rec_pivot = rec_df.pivot(index=\"id_proposal\", columns=\"rank\", values=\"dosen\").reset_index()\n",
        "    rec_pivot.columns.name = None\n",
        "    rec_pivot.columns = [\"id_proposal\"] + [f\"rec_{i}\" for i in range(1, len(rec_pivot.columns))]\n",
        "\n",
        "    # Gabung dengan label kebenaran\n",
        "    merged_df = pd.merge(\n",
        "        rec_pivot,\n",
        "        true_label_df.rename(columns={\"proposal_id\": \"id_proposal\"}),\n",
        "        on=\"id_proposal\",\n",
        "        how=\"left\"\n",
        "    )\n",
        "\n",
        "    # Recall of existence (abaikan urutan)\n",
        "    def recall_of_existence(row):\n",
        "        true_set = {row.get(\"author1\"), row.get(\"author2\"), row.get(\"author3\")}\n",
        "        pred_set = {row.get(f\"rec_{i}\") for i in range(1, top_n + 1) if row.get(f\"rec_{i}\")}\n",
        "        return len(true_set.intersection(pred_set)) / 3\n",
        "\n",
        "    merged_df[f'recall_of_existence@{top_n}'] = merged_df.apply(recall_of_existence, axis=1)\n",
        "\n",
        "    # Recall berdasarkan posisi (urutan harus sama)\n",
        "    for pos in [1, 2, 3]:\n",
        "        merged_df[f'recall_pos{pos}_ordered@{top_n}'] = merged_df.apply(\n",
        "            lambda row: int(\n",
        "                pd.notna(row.get(f'author{pos}')) and\n",
        "                pd.notna(row.get(f'rec_{pos}')) and\n",
        "                row.get(f'author{pos}') == row.get(f'rec_{pos}')\n",
        "            ) if pos <= top_n else 0,\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "    # Euclidean distance penalti posisi\n",
        "    distances = []\n",
        "    for _, row in merged_df.iterrows():\n",
        "        true_authors = [row.get(f'author{i}') for i in [1, 2, 3]]\n",
        "        pred_authors = [row.get(f'rec_{i}', None) for i in range(1, top_n + 1)]\n",
        "        distance = 0\n",
        "        max_penalty = top_n\n",
        "        for i, true_author in enumerate(true_authors):\n",
        "            if pd.isna(true_author) or true_author == '':\n",
        "                continue\n",
        "            try:\n",
        "                pred_pos = pred_authors.index(true_author)\n",
        "                pos_diff = pred_pos - i\n",
        "                distance += pos_diff ** 2\n",
        "            except ValueError:\n",
        "                distance += max_penalty ** 2\n",
        "        distances.append(np.sqrt(distance))\n",
        "\n",
        "    # Normalisasi jarak\n",
        "    scaler = MinMaxScaler()\n",
        "    norm_dists = scaler.fit_transform(np.array(distances).reshape(-1, 1)).flatten()\n",
        "    merged_df[f'norm_euclidean@{top_n}'] = norm_dists\n",
        "\n",
        "    # Ambil kolom evaluasi\n",
        "    result_df = merged_df[[\"id_proposal\",\n",
        "                           f'recall_of_existence@{top_n}',\n",
        "                           f'recall_pos1_ordered@{top_n}',\n",
        "                           f'recall_pos2_ordered@{top_n}',\n",
        "                           f'recall_pos3_ordered@{top_n}',\n",
        "                           f'norm_euclidean@{top_n}']].copy()\n",
        "\n",
        "    return result_df\n",
        "\n",
        "\n",
        "eval_per_proposal_directed_3 = evaluate_per_proposal_directed(df_overlap_true, true_label_df, top_n=3)\n",
        "eval_per_proposal_directed_5 = evaluate_per_proposal_directed(df_overlap_true, true_label_df, top_n=5)\n",
        "eval_per_proposal_directed_7 = evaluate_per_proposal_directed(df_overlap_true, true_label_df, top_n=7)\n",
        "eval_per_proposal_directed_10 = evaluate_per_proposal_directed(df_overlap_true, true_label_df, top_n=10)\n",
        "\n",
        "# eval_per_proposal_directed_3.to_csv(\"/content/drive/MyDrive/Skripsi4/topik/directed/14_baru/hasil_eval_3_directed.csv\", index=False)\n",
        "# eval_per_proposal_directed_5.to_csv(\"/content/drive/MyDrive/Skripsi4/topik/directed/14_baru/hasil_eval_5_directed.csv\", index=False)\n",
        "# eval_per_proposal_directed_7.to_csv(\"/content/drive/MyDrive/Skripsi4/topik/directed/14_baru/hasil_eval_7_directed.csv\", index=False)\n",
        "# eval_per_proposal_directed_10.to_csv(\"/content/drive/MyDrive/Skripsi4/topik/directed/14_baru/hasil_eval_10_directed.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vzt-RHMSsRw"
      },
      "source": [
        "# Cosine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "_t6VT0-ROwjb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7e019f8-9a41-491d-9b11-d675aa110a81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                 P1       P10       P11       P12       P13  \\\n",
            "Wiharto (D12, R1)          0.058843  0.091072  0.079892  0.036000  0.039997   \n",
            "Abdul Aziz (D5, R1)        0.058843  0.091072  0.079892  0.036000  0.039997   \n",
            "Abdul Aziz (D5, R2)        0.305917  0.153456  0.022797  0.016454  0.154291   \n",
            "Abdul Aziz (D5, R3)        0.007805  0.080065  0.016221  0.019391  0.021273   \n",
            "Bambang Harjito (D1, R3)   0.007805  0.080065  0.016221  0.019391  0.021273   \n",
            "...                             ...       ...       ...       ...       ...   \n",
            "Umi Salamah (D3, R464)     0.014687  0.091011  0.025110  0.016003  0.025077   \n",
            "Heri Prasetyo (D15, R464)  0.014687  0.091011  0.025110  0.016003  0.025077   \n",
            "Heri Prasetyo (D15, R465)  0.400188  0.887661  0.049040  0.184351  0.329181   \n",
            "Heri Prasetyo (D15, R466)  0.018948  0.917412  0.061406  0.289169  0.303068   \n",
            "Heri Prasetyo (D15, R467)  0.017235  0.066230  0.132222  0.251377  0.549798   \n",
            "\n",
            "                                P14       P15       P16       P17       P18  \\\n",
            "Wiharto (D12, R1)          0.012600  0.312805  0.313236  0.053349  0.027127   \n",
            "Abdul Aziz (D5, R1)        0.012600  0.312805  0.313236  0.053349  0.027127   \n",
            "Abdul Aziz (D5, R2)        0.013487  0.013317  0.014213  0.160872  0.014108   \n",
            "Abdul Aziz (D5, R3)        0.017964  0.016155  0.016830  0.015101  0.018707   \n",
            "Bambang Harjito (D1, R3)   0.017964  0.016155  0.016830  0.015101  0.018707   \n",
            "...                             ...       ...       ...       ...       ...   \n",
            "Umi Salamah (D3, R464)     0.014334  0.014562  0.015898  0.028416  0.015198   \n",
            "Heri Prasetyo (D15, R464)  0.014334  0.014562  0.015898  0.028416  0.015198   \n",
            "Heri Prasetyo (D15, R465)  0.182524  0.018171  0.024445  0.103912  0.183101   \n",
            "Heri Prasetyo (D15, R466)  0.282882  0.091963  0.101298  0.056338  0.286700   \n",
            "Heri Prasetyo (D15, R467)  0.246883  0.012701  0.022220  0.102534  0.247200   \n",
            "\n",
            "                           ...      P133      P134      P135      P136  \\\n",
            "Wiharto (D12, R1)          ...  0.069208  0.011526  0.080033  0.080596   \n",
            "Abdul Aziz (D5, R1)        ...  0.069208  0.011526  0.080033  0.080596   \n",
            "Abdul Aziz (D5, R2)        ...  0.670916  0.276910  0.022841  0.045833   \n",
            "Abdul Aziz (D5, R3)        ...  0.129736  0.008108  0.011729  0.012407   \n",
            "Bambang Harjito (D1, R3)   ...  0.129736  0.008108  0.011729  0.012407   \n",
            "...                        ...       ...       ...       ...       ...   \n",
            "Umi Salamah (D3, R464)     ...  0.112787  0.016580  0.168551  0.173314   \n",
            "Heri Prasetyo (D15, R464)  ...  0.112787  0.016580  0.168551  0.173314   \n",
            "Heri Prasetyo (D15, R465)  ...  0.111872  0.110928  0.741140  0.741387   \n",
            "Heri Prasetyo (D15, R466)  ...  0.031694  0.014053  0.792918  0.775076   \n",
            "Heri Prasetyo (D15, R467)  ...  0.051097  0.011582  0.087493  0.038558   \n",
            "\n",
            "                               P137      P138      P139      P140      P141  \\\n",
            "Wiharto (D12, R1)          0.249310  0.287749  0.015917  0.017883  0.029559   \n",
            "Abdul Aziz (D5, R1)        0.249310  0.287749  0.015917  0.017883  0.029559   \n",
            "Abdul Aziz (D5, R2)        0.107777  0.019952  0.018604  0.085817  0.075170   \n",
            "Abdul Aziz (D5, R3)        0.020900  0.012380  0.018948  0.055123  0.013526   \n",
            "Bambang Harjito (D1, R3)   0.020900  0.012380  0.018948  0.055123  0.013526   \n",
            "...                             ...       ...       ...       ...       ...   \n",
            "Umi Salamah (D3, R464)     0.048789  0.695180  0.019990  0.443976  0.283930   \n",
            "Heri Prasetyo (D15, R464)  0.048789  0.695180  0.019990  0.443976  0.283930   \n",
            "Heri Prasetyo (D15, R465)  0.039200  0.022346  0.183566  0.028932  0.049585   \n",
            "Heri Prasetyo (D15, R466)  0.089199  0.021392  0.284035  0.025492  0.078752   \n",
            "Heri Prasetyo (D15, R467)  0.149976  0.476212  0.255293  0.356563  0.199046   \n",
            "\n",
            "                               P142  \n",
            "Wiharto (D12, R1)          0.127512  \n",
            "Abdul Aziz (D5, R1)        0.127512  \n",
            "Abdul Aziz (D5, R2)        0.119626  \n",
            "Abdul Aziz (D5, R3)        0.021120  \n",
            "Bambang Harjito (D1, R3)   0.021120  \n",
            "...                             ...  \n",
            "Umi Salamah (D3, R464)     0.311934  \n",
            "Heri Prasetyo (D15, R464)  0.311934  \n",
            "Heri Prasetyo (D15, R465)  0.045204  \n",
            "Heri Prasetyo (D15, R466)  0.142670  \n",
            "Heri Prasetyo (D15, R467)  0.580643  \n",
            "\n",
            "[760 rows x 142 columns]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "\n",
        "# Ubah list topic_vector menjadi array 2D\n",
        "expert_vectors = np.vstack(expert_df[\"topic_vector\"].values)\n",
        "proposal_vectors = np.vstack(proposal_df[\"topic_vector\"].values)\n",
        "\n",
        "# Hitung similarity\n",
        "similarity_matrix = cosine_similarity(expert_vectors, proposal_vectors)\n",
        "\n",
        "# Buat label baris dari dosen: gabungkan name, expert_id, research_id\n",
        "expert_labels = expert_df.apply(\n",
        "    lambda row: f\"{row['name']} ({row['expert_id']}, {row['research_id']})\", axis=1\n",
        ")\n",
        "\n",
        "# Buat label kolom dari proposal\n",
        "proposal_labels = proposal_df[\"proposal_id\"].values\n",
        "\n",
        "# Buat DataFrame dari similarity matrix\n",
        "similarity_matrix_df = pd.DataFrame(\n",
        "    similarity_matrix,\n",
        "    index=expert_labels,\n",
        "    columns=proposal_labels\n",
        ")\n",
        "print(similarity_matrix_df)\n",
        "\n",
        "# Simpan ke CSV\n",
        "# similarity_matrix_df.to_csv(\"/content/drive/MyDrive/Skripsi4/dictionary/hasil_cosine_matriks_14.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "qd3oic5wS5KM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ee9d1f3-58b8-4f58-e1cb-3e21f3cdbb09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       id_proposal mahasiswa id_penelitian id_dosen  selisih_tahun  \\\n",
            "3               P1        S1            R3       D5              5   \n",
            "4               P1        S1            R3       D1              5   \n",
            "5               P1        S1            R4       D5              4   \n",
            "6               P1        S1            R4       D8              4   \n",
            "7               P1        S1            R5       D5              3   \n",
            "...            ...       ...           ...      ...            ...   \n",
            "107846        P142      S142          R425       D2              2   \n",
            "107847        P142      S142          R426       D6              2   \n",
            "107849        P142      S142          R428      D14              2   \n",
            "107850        P142      S142          R429      D14              2   \n",
            "107851        P142      S142          R429       D6              2   \n",
            "\n",
            "                  dosen  similarity_score  \n",
            "3            Abdul Aziz          0.007805  \n",
            "4       Bambang Harjito          0.007805  \n",
            "5            Abdul Aziz          0.186007  \n",
            "6          Esti Suryani          0.186007  \n",
            "7            Abdul Aziz          0.005797  \n",
            "...                 ...               ...  \n",
            "107846          Wiranto          0.716899  \n",
            "107847    Ristu Saptono          0.118139  \n",
            "107849  Haryono Setiadi          0.137791  \n",
            "107850  Haryono Setiadi          0.548977  \n",
            "107851    Ristu Saptono          0.548977  \n",
            "\n",
            "[53068 rows x 7 columns]\n"
          ]
        }
      ],
      "source": [
        "similarity_cosine_df = []\n",
        "\n",
        "for i, (_, mahasiswa) in enumerate(proposal_df.iterrows()):\n",
        "    for j, (_, dosen) in enumerate(expert_df.iterrows()):\n",
        "\n",
        "        score_akhir = similarity_matrix[j, i]\n",
        "        similarity_cosine_df.append({\n",
        "            \"id_proposal\": mahasiswa[\"proposal_id\"],\n",
        "            \"mahasiswa\": mahasiswa[\"student_id\"],\n",
        "            \"id_dosen\": dosen[\"expert_id\"],\n",
        "            \"id_penelitian\": dosen[\"research_id\"],\n",
        "            \"tahun_proposal\": mahasiswa[\"tahun\"],\n",
        "            \"tahun_penelitian\": dosen[\"pub_year\"],\n",
        "            \"selisih_tahun\": mahasiswa[\"tahun\"] - dosen[\"pub_year\"],\n",
        "            \"dosen\": dosen[\"name\"],\n",
        "           \"author_position\": dosen[\"author_position\"],\n",
        "            # \"weight\": weight,\n",
        "            \"similarity_score\" : similarity_matrix[j, i],\n",
        "\n",
        "        })\n",
        "\n",
        "similarity_cosine_df = pd.DataFrame(similarity_cosine_df)\n",
        "\n",
        "# Filter sesuai kondisi\n",
        "similarity_cosine_df = similarity_cosine_df[\n",
        "    (similarity_cosine_df[\"tahun_proposal\"] > similarity_cosine_df[\"tahun_penelitian\"]) &\n",
        "    (similarity_cosine_df[\"selisih_tahun\"] <= 5)\n",
        "].copy()\n",
        "\n",
        "\n",
        "# Tampilkan hasil\n",
        "print(similarity_cosine_df[[\"id_proposal\",\"mahasiswa\",\"id_penelitian\", \"id_dosen\",\"selisih_tahun\", \"dosen\", \"similarity_score\" ]])\n",
        "# similarity_cosine_df.to_csv(\"/content/drive/MyDrive/Skripsi4/topik/cosine/14_baru/hasil_cosine_topik.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGX5xEtNUpcw"
      },
      "source": [
        "# Pemeringkatan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "7shoY9CES9Tz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9694aa7a-2122-4962-a574-3faad5b7cb12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      id_proposal mahasiswa id_dosen               dosen  similarity_score  \\\n",
            "412            P1        S1      D14     Haryono Setiadi          0.998706   \n",
            "411            P1        S1       D6       Ristu Saptono          0.998706   \n",
            "382            P1        S1       D2             Wiranto          0.994274   \n",
            "46             P1        S1      D10      Afrizal Doewes          0.973844   \n",
            "45             P1        S1       D9    Sari Widya Sihwi          0.973844   \n",
            "...           ...       ...      ...                 ...               ...   \n",
            "74794         P99       S99      D15       Heri Prasetyo          0.518658   \n",
            "75121         P99       S99       D7      Wisnu Widiarto          0.513496   \n",
            "75235         P99       S99       D3         Umi Salamah          0.338699   \n",
            "75076         P99       S99       D4  Dewi Wisnu Wardani          0.165232   \n",
            "75004         P99       S99      D10      Afrizal Doewes          0.159676   \n",
            "\n",
            "       rank  \n",
            "412       1  \n",
            "411       2  \n",
            "382       3  \n",
            "46        4  \n",
            "45        5  \n",
            "...     ...  \n",
            "74794    12  \n",
            "75121    13  \n",
            "75235    14  \n",
            "75076    15  \n",
            "75004    16  \n",
            "\n",
            "[2248 rows x 6 columns]\n"
          ]
        }
      ],
      "source": [
        "# Ambil baris dengan similarity tertinggi untuk kombinasi unik id_proposal dan id_dosen\n",
        "idx = similarity_cosine_df.groupby([\"id_proposal\", \"id_dosen\"])[\"similarity_score\"].idxmax()\n",
        "similarity_cosine_df = similarity_cosine_df.loc[idx]\n",
        "\n",
        "# Ranking ulang berdasarkan proposal\n",
        "similarity_cosine_df[\"rank\"] = similarity_cosine_df.groupby(\"id_proposal\")[\"similarity_score\"] \\\n",
        "                                     .rank(method=\"first\", ascending=False).astype(int)\n",
        "\n",
        "# Urutkan\n",
        "similarity_cosine_df = similarity_cosine_df.sort_values([\"id_proposal\", \"rank\"])\n",
        "similarity_cosine_df = similarity_cosine_df[similarity_cosine_df[\"rank\"] <= 17]\n",
        "\n",
        "\n",
        "# Tampilkan\n",
        "print(similarity_cosine_df[[\"id_proposal\", \"mahasiswa\", \"id_dosen\", \"dosen\", \"similarity_score\", \"rank\"]])\n",
        "# similarity_cosine_df.to_csv(\"/content/drive/MyDrive/Skripsi4/topik/cosine/14_baru/hasil_rank_cosine_topik.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "4EFjJdmrVV34"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# 1. Inisialisasi count untuk rank 1\n",
        "rank1_count = defaultdict(int)\n",
        "final_assignments = []\n",
        "\n",
        "# 2. Tetapkan rank 1 dengan batas 15 kali per dosen\n",
        "for pid in similarity_cosine_df[\"id_proposal\"].unique():\n",
        "    candidates = similarity_cosine_df[similarity_cosine_df[\"id_proposal\"] == pid]\n",
        "    candidates = candidates.sort_values(by=\"similarity_score\", ascending=False)\n",
        "\n",
        "    assigned_rank1 = False\n",
        "    for _, row in candidates.iterrows():\n",
        "        dosen_id = row[\"id_dosen\"]\n",
        "        if rank1_count[dosen_id] < 15:\n",
        "            rank1_count[dosen_id] += 1\n",
        "            row_data = row.to_dict()\n",
        "            row_data[\"rank\"] = 1\n",
        "            row_data[\"beban\"] = rank1_count[dosen_id]\n",
        "            final_assignments.append(row_data)\n",
        "            assigned_rank1 = True\n",
        "            break\n",
        "\n",
        "    if not assigned_rank1:\n",
        "        row = candidates.iloc[0].to_dict()\n",
        "        dosen_id = row[\"id_dosen\"]\n",
        "        rank1_count[dosen_id] += 1\n",
        "        row[\"rank\"] = 1\n",
        "        row[\"beban\"] = rank1_count[dosen_id]\n",
        "        final_assignments.append(row)\n",
        "\n",
        "# 3. Buat dataframe dari rank 1\n",
        "rank1_df = pd.DataFrame(final_assignments)\n",
        "\n",
        "# 4. Tambahkan rank 2–17 berdasarkan similarity, excl. dosen yang sudah dipakai di rank 1 untuk proposal yang sama\n",
        "other_ranks = []\n",
        "\n",
        "for pid in similarity_cosine_df[\"id_proposal\"].unique():\n",
        "    # Dapatkan dosen yang sudah dipakai sebagai rank 1\n",
        "    used_dosen = rank1_df[rank1_df[\"id_proposal\"] == pid][\"id_dosen\"].tolist()\n",
        "\n",
        "    # Ambil kandidat lain untuk proposal ini\n",
        "    candidates = similarity_cosine_df[(similarity_cosine_df[\"id_proposal\"] == pid) & (~similarity_cosine_df[\"id_dosen\"].isin(used_dosen))]\n",
        "    candidates = candidates.sort_values(by=\"similarity_score\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "    for idx, (_, row) in enumerate(candidates.iterrows(), start=2):\n",
        "        if idx > 17:\n",
        "            break\n",
        "        row_data = row.to_dict()\n",
        "        row_data[\"rank\"] = idx\n",
        "        row_data[\"beban\"] = rank1_count[row_data[\"id_dosen\"]]  # Beban hanya dihitung dari rank 1\n",
        "        other_ranks.append(row_data)\n",
        "\n",
        "# 5. Gabungkan rank1 dan other ranks\n",
        "rank_all_df = pd.concat([rank1_df, pd.DataFrame(other_ranks)], ignore_index=True)\n",
        "rank_all_df = rank_all_df.sort_values(by=[\"id_proposal\", \"rank\"])\n",
        "\n",
        "# 6. Tampilkan hasil\n",
        "# print(rank_all_df[[\"id_proposal\", \"mahasiswa\", \"id_dosen\", \"dosen\", \"similarity_score\",\"similarity_score_akhir\", \"rank\", \"beban\"]])\n",
        "# rank_all_df.to_csv(\"/content/drive/MyDrive/Skripsi4/topik/cosine/14_baru/beban_cosine_topik.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Urutkan berdasarkan id_proposal, similarity_score_akhir (descending), dan author_position (ascending)\n",
        "similarity_cosine_df_baru = similarity_cosine_df.sort_values(\n",
        "    by=[\"id_proposal\", \"similarity_score\", \"author_position\"],\n",
        "    ascending=[True, False, True]\n",
        ")\n",
        "\n",
        "# Tambahkan kolom rank untuk setiap id_proposal\n",
        "similarity_cosine_df_baru[\"rank\"] = similarity_cosine_df_baru.groupby(\"id_proposal\").cumcount() + 1\n",
        "\n",
        "print(similarity_cosine_df_baru)\n",
        "\n"
      ],
      "metadata": {
        "id": "pCDHrPFiPzuX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9f17450-822e-448b-bc01-a2cae067e613"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      id_proposal mahasiswa id_dosen id_penelitian  tahun_proposal  \\\n",
            "411            P1        S1       D6          R249            2021   \n",
            "412            P1        S1      D14          R249            2021   \n",
            "382            P1        S1       D2          R232            2021   \n",
            "45             P1        S1       D9           R26            2021   \n",
            "46             P1        S1      D10           R26            2021   \n",
            "...           ...       ...      ...           ...             ...   \n",
            "74794         P99       S99      D15          R193            2024   \n",
            "75121         P99       S99       D7          R394            2024   \n",
            "75235         P99       S99       D3          R464            2024   \n",
            "75076         P99       S99       D4          R374            2024   \n",
            "75004         P99       S99      D10          R335            2024   \n",
            "\n",
            "       tahun_penelitian  selisih_tahun               dosen  author_position  \\\n",
            "411                2019              2       Ristu Saptono                1   \n",
            "412                2019              2     Haryono Setiadi                2   \n",
            "382                2017              4             Wiranto                2   \n",
            "45                 2018              3    Sari Widya Sihwi                1   \n",
            "46                 2018              3      Afrizal Doewes                2   \n",
            "...                 ...            ...                 ...              ...   \n",
            "74794              2021              3       Heri Prasetyo                3   \n",
            "75121              2021              3      Wisnu Widiarto                2   \n",
            "75235              2022              2         Umi Salamah                1   \n",
            "75076              2022              2  Dewi Wisnu Wardani                1   \n",
            "75004              2022              2      Afrizal Doewes                1   \n",
            "\n",
            "       similarity_score  rank  \n",
            "411            0.998706     1  \n",
            "412            0.998706     2  \n",
            "382            0.994274     3  \n",
            "45             0.973844     4  \n",
            "46             0.973844     5  \n",
            "...                 ...   ...  \n",
            "74794          0.518658    12  \n",
            "75121          0.513496    13  \n",
            "75235          0.338699    14  \n",
            "75076          0.165232    15  \n",
            "75004          0.159676    16  \n",
            "\n",
            "[2248 rows x 11 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDpaTPt7VlSU"
      },
      "source": [
        "# Evaluasi Cosine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "RyEdj1o1Szkf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cce5d20-4a7f-44fb-c297-275caaed69ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Top-N  Mean_Recall_Existence  Recall_Pos_1_Ordered  Recall_Pos_2_Ordered  \\\n",
            "0      3               0.345070              0.260563              0.105634   \n",
            "1      5               0.460094              0.260563              0.105634   \n",
            "2      7               0.593897              0.260563              0.105634   \n",
            "3     10               0.753521              0.260563              0.105634   \n",
            "\n",
            "   Recall_Pos_3_Ordered  Avg_Normalized_Euclidean  \n",
            "0              0.077465                  0.807783  \n",
            "1              0.077465                  0.734154  \n",
            "2              0.077465                  0.659702  \n",
            "3              0.077465                  0.554564  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def evaluate_ordered_recommendation_cosine(rank_all_df, true_label_df, top_ns=[3, 5, 7, 10]):\n",
        "    summary = []\n",
        "\n",
        "    for TOP_N in top_ns:\n",
        "        # Filter Top-N dan urutkan\n",
        "        top_n_df = rank_all_df[rank_all_df[\"rank\"] <= TOP_N]\n",
        "        rec_df = top_n_df.sort_values(by=[\"id_proposal\", \"rank\", \"similarity_score\"], ascending=[True, True, False])\n",
        "        rec_pivot = rec_df.pivot(index=\"id_proposal\", columns=\"rank\", values=\"dosen\").reset_index()\n",
        "        rec_pivot.columns.name = None\n",
        "        rec_pivot.columns = [\"id_proposal\"] + [f\"rec_{i}\" for i in range(1, len(rec_pivot.columns))]\n",
        "\n",
        "        # Gabungkan dengan ground truth\n",
        "        merged_df = pd.merge(\n",
        "            rec_pivot,\n",
        "            true_label_df.rename(columns={\"proposal_id\": \"id_proposal\"}),\n",
        "            on=\"id_proposal\",\n",
        "            how=\"left\"\n",
        "        )\n",
        "\n",
        "        # Recall keberadaan (tidak memperhatikan urutan)\n",
        "        def recall_of_existence(row):\n",
        "            true_set = {row.get(\"author1\"), row.get(\"author2\"), row.get(\"author3\")}\n",
        "            pred_set = {row.get(f\"rec_{i}\") for i in range(1, TOP_N + 1) if row.get(f\"rec_{i}\")}\n",
        "            return len(true_set.intersection(pred_set)) / 3\n",
        "\n",
        "        merged_df[f'recall_of_existence@{TOP_N}'] = merged_df.apply(recall_of_existence, axis=1)\n",
        "\n",
        "        # Recall per posisi dengan urutan diperhatikan (rec_i harus sama dengan author_i)\n",
        "        recall_pos = {1: [], 2: [], 3: []}\n",
        "        for _, row in merged_df.iterrows():\n",
        "            for pos in [1, 2, 3]:\n",
        "                examiner = row.get(f'author{pos}')\n",
        "                rec = row.get(f'rec_{pos}') if pos <= TOP_N else None\n",
        "                hit = int(pd.notna(examiner) and pd.notna(rec) and examiner == rec)\n",
        "                recall_pos[pos].append(hit)\n",
        "\n",
        "        # Tambahkan recall ke DataFrame\n",
        "        for pos in [1, 2, 3]:\n",
        "            merged_df[f'recall_pos{pos}_ordered@{TOP_N}'] = recall_pos[pos]\n",
        "\n",
        "        recall_pos_mean = {pos: np.mean(recall_pos[pos]) for pos in [1, 2, 3]}\n",
        "\n",
        "        # Euclidean distance antar posisi (penalti posisi meleset)\n",
        "        distances = []\n",
        "        for _, row in merged_df.iterrows():\n",
        "            true_authors = [row.get(f'author{i}') for i in [1, 2, 3]]\n",
        "            pred_authors = [row.get(f'rec_{i}', None) for i in range(1, TOP_N + 1)]\n",
        "            distance = 0\n",
        "            max_penalty = TOP_N\n",
        "            for i, true_author in enumerate(true_authors):\n",
        "                if pd.isna(true_author) or true_author == '':\n",
        "                    continue\n",
        "                try:\n",
        "                    pred_pos = pred_authors.index(true_author)\n",
        "                    pos_diff = pred_pos - i\n",
        "                    distance += pos_diff ** 2\n",
        "                except ValueError:\n",
        "                    distance += max_penalty ** 2\n",
        "            distances.append(np.sqrt(distance))\n",
        "\n",
        "        scaler = MinMaxScaler()\n",
        "        norm_dists = scaler.fit_transform(np.array(distances).reshape(-1, 1)).flatten()\n",
        "        merged_df[f'norm_euclidean@{TOP_N}'] = norm_dists\n",
        "\n",
        "        # Ringkasan metrik\n",
        "        summary.append({\n",
        "            'Top-N': TOP_N,\n",
        "            'Mean_Recall_Existence': merged_df[f'recall_of_existence@{TOP_N}'].mean(),\n",
        "            'Recall_Pos_1_Ordered': recall_pos_mean[1],\n",
        "            'Recall_Pos_2_Ordered': recall_pos_mean[2],\n",
        "            'Recall_Pos_3_Ordered': recall_pos_mean[3],\n",
        "            'Avg_Normalized_Euclidean': np.mean(norm_dists)\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(summary)\n",
        "\n",
        "result_df = evaluate_ordered_recommendation_cosine(similarity_cosine_df, true_label_df)\n",
        "print(result_df)\n",
        "# result_df.to_csv(\"/content/drive/MyDrive/Skripsi4/topik/cosine/14_baru/result_df.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiyEGakTZn8P"
      },
      "source": [
        "## per proposal baru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "vZoVKOZGDJFx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def evaluate_per_proposal_cosine(rank_all_df, true_label_df, top_n=3):\n",
        "    # Filter dan urutkan\n",
        "    top_n_df = rank_all_df[rank_all_df[\"rank\"] <= top_n]\n",
        "    rec_df = top_n_df.sort_values(by=[\"id_proposal\", \"rank\", \"similarity_score\"], ascending=[True, True, False])\n",
        "    rec_pivot = rec_df.pivot(index=\"id_proposal\", columns=\"rank\", values=\"dosen\").reset_index()\n",
        "    rec_pivot.columns.name = None\n",
        "    rec_pivot.columns = [\"id_proposal\"] + [f\"rec_{i}\" for i in range(1, len(rec_pivot.columns))]\n",
        "\n",
        "    # Gabung dengan label kebenaran\n",
        "    merged_df = pd.merge(\n",
        "        rec_pivot,\n",
        "        true_label_df.rename(columns={\"proposal_id\": \"id_proposal\"}),\n",
        "        on=\"id_proposal\",\n",
        "        how=\"left\"\n",
        "    )\n",
        "\n",
        "    # Recall of existence (abaikan urutan)\n",
        "    def recall_of_existence(row):\n",
        "        true_set = {row.get(\"author1\"), row.get(\"author2\"), row.get(\"author3\")}\n",
        "        pred_set = {row.get(f\"rec_{i}\") for i in range(1, top_n + 1) if row.get(f\"rec_{i}\")}\n",
        "        return len(true_set.intersection(pred_set)) / 3\n",
        "\n",
        "    merged_df[f'recall_of_existence@{top_n}'] = merged_df.apply(recall_of_existence, axis=1)\n",
        "\n",
        "    # Recall berdasarkan posisi (urutan harus sama)\n",
        "    for pos in [1, 2, 3]:\n",
        "        merged_df[f'recall_pos{pos}_ordered@{top_n}'] = merged_df.apply(\n",
        "            lambda row: int(\n",
        "                pd.notna(row.get(f'author{pos}')) and\n",
        "                pd.notna(row.get(f'rec_{pos}')) and\n",
        "                row.get(f'author{pos}') == row.get(f'rec_{pos}')\n",
        "            ) if pos <= top_n else 0,\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "    # Euclidean distance penalti posisi\n",
        "    distances = []\n",
        "    for _, row in merged_df.iterrows():\n",
        "        true_authors = [row.get(f'author{i}') for i in [1, 2, 3]]\n",
        "        pred_authors = [row.get(f'rec_{i}', None) for i in range(1, top_n + 1)]\n",
        "        distance = 0\n",
        "        max_penalty = top_n\n",
        "        for i, true_author in enumerate(true_authors):\n",
        "            if pd.isna(true_author) or true_author == '':\n",
        "                continue\n",
        "            try:\n",
        "                pred_pos = pred_authors.index(true_author)\n",
        "                pos_diff = pred_pos - i\n",
        "                distance += pos_diff ** 2\n",
        "            except ValueError:\n",
        "                distance += max_penalty ** 2\n",
        "        distances.append(np.sqrt(distance))\n",
        "\n",
        "    # Normalisasi jarak\n",
        "    scaler = MinMaxScaler()\n",
        "    norm_dists = scaler.fit_transform(np.array(distances).reshape(-1, 1)).flatten()\n",
        "    merged_df[f'norm_euclidean@{top_n}'] = norm_dists\n",
        "\n",
        "    # Ambil kolom evaluasi\n",
        "    result_df = merged_df[[\"id_proposal\",\n",
        "                           f'recall_of_existence@{top_n}',\n",
        "                           f'recall_pos1_ordered@{top_n}',\n",
        "                           f'recall_pos2_ordered@{top_n}',\n",
        "                           f'recall_pos3_ordered@{top_n}',\n",
        "                           f'norm_euclidean@{top_n}']].copy()\n",
        "\n",
        "    return result_df\n",
        "\n",
        "\n",
        "eval_per_proposal_cosine_3 = evaluate_per_proposal_cosine(similarity_cosine_df, true_label_df, top_n=3)\n",
        "eval_per_proposal_cosine_5 = evaluate_per_proposal_cosine(similarity_cosine_df, true_label_df, top_n=5)\n",
        "eval_per_proposal_cosine_7 = evaluate_per_proposal_cosine(similarity_cosine_df, true_label_df, top_n=7)\n",
        "eval_per_proposal_cosine_10 = evaluate_per_proposal_cosine(similarity_cosine_df, true_label_df, top_n=10)\n",
        "\n",
        "# eval_per_proposal_cosine_3.to_csv(\"/content/drive/MyDrive/Skripsi4/topik/cosine/14_baru/hasil_eval_3_cosine_topik.csv\", index=False)\n",
        "# eval_per_proposal_cosine_5.to_csv(\"/content/drive/MyDrive/Skripsi4/topik/cosine/14_baru/hasil_eval_5_cosine_topik.csv\", index=False)\n",
        "# eval_per_proposal_cosine_7.to_csv(\"/content/drive/MyDrive/Skripsi4/topik/cosine/14_baru/hasil_eval_7_cosine_topik.csv\", index=False)\n",
        "# eval_per_proposal_cosine_10.to_csv(\"/content/drive/MyDrive/Skripsi4/topik/cosine/14_baru/hasil_eval_10_cosine_topik.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMLheFWI72K96qJ4ufBAINH",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}